[
  {
    "id": "ed-7476069",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Full AI-generated LaTeX Course Notes",
    "dek": "I used Jameson's lecture note converter to convert the handwritten course notes to LaTeX for all 27 lectures. I can't find his post otherwise I'd mention it to give him credit. Basically it uses the f...",
    "summary": "This project converts handwritten lecture notes to LaTeX format using AI. The tool combines lecture slides with YouTube audio transcripts to generate well-formatted course notes with table of contents, custom headers, and section numbers. All 27 lectures are available as PDFs.",
    "student": "Jason Lee",
    "date": "2025-12-17",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7476069"
    },
    "body_html": "I used Jameson's lecture note converter to convert the handwritten course notes to LaTeX for all 27 lectures. I can't find his post otherwise I'd mention it to give him credit. Basically it uses the following Python code and combines the lecture slides with the YouTube audio transcript. I slightly modified his code to not paste the API key directly in the script and instead use dotenv:\n\nI also elegantly formatted them in a more note-like structure with a table of contents, custom headers and section numbers corresponding to the lecture number.\n\nHere's the notes if you want to pass them down to your friends who take the course in the future. I can get you the .tex files if you're interested as well.",
    "attachments": [
      {
        "name": "generate.py",
        "url": "https://static.us.edusercontent.com/files/xGIUmdgjYo8Ma6WGhNd4Zyk2"
      },
      {
        "name": "182_lectures_0_to_9.pdf",
        "url": "https://static.us.edusercontent.com/files/EsDMZowGDsoFNG1LeAmJwvQv"
      },
      {
        "name": "182_lectures_10_to_19.pdf",
        "url": "https://static.us.edusercontent.com/files/7ETht9TSylRfUdh6dlFHwLbc"
      },
      {
        "name": "182_lectures_20_to_27.pdf",
        "url": "https://static.us.edusercontent.com/files/IHDynZHwwayRH5iRoWfPRpHA"
      }
    ],
    "highlight": false
  },
  {
    "id": "ed-7452203",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Prompt for generating final review plan.",
    "dek": "Coming up with a study plan for finals on a tight schedule and in a class where there's a lot of material to review can be hard. This llm prompt I refined helps create a day by day schedule for you wi...",
    "student": "Rahul Bir",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452203"
    },
    "body_html": "Coming up with a study plan for finals on a tight schedule and in a class where there's a lot of material to review can be hard. This llm prompt I refined helps create a day by day schedule for you with an emphasis on solving problems. Hope this is helpful!\n\nFINAL EXAM STUDY PLAN GENERATION PROMPT\n\n(With strong emphasis on problem-solving and active practice)\n\nYou are an AI study coach. Your job is to read the course materials I provide and generate a personalized, realistic, high-efficiency study plan for preparing for final exams, with strong emphasis on solving problems, not just reviewing notes.\n\nI will give you:\n\nA set of lecture note PDFs\n\nA course schedule or syllabus\n\nA timeline showing how many days I have until the exam\n\nThe topics emphasized in lecture and homework\n\n(Optional) Past exams or review problem sets\n\nMy personal constraints (other classes, energy levels, commitments, etc.)\n\nUse all of this to produce a detailed, structured, practice-oriented plan.\n\nSTEP 1 — Understand the Course\n\nExtract from the PDFs and syllabus:\n\nThe main conceptual pillars of the course\n\nAll subtopics and dependencies\n\nSkills required (especially problem-solving, derivations, proofs, coding, computation)\n\nHow problems were structured in homeworks and discussions\n\nThe exam format if known\n\nRecurring problem types or solution strategies emphasized by the instructor\n\nSTEP 2 — Build a Prioritized Topic + Problem List\n\nCategorize material into:\n\nCore Exam Topics — fundamental, appear in problems repeatedly\n\nSecondary Topics — supportive but still likely to appear in problem form\n\nPeripheral Topics — lower priority unless historically tested\n\nFor each topic, also generate:\n\nTypical problems associated with it\n\nRequired techniques or reasoning patterns\n\nCommon pitfalls students make\n\nThe “minimum problem set” required to reach competence\n\nSTEP 3 — Allocate Topics Across the Timeline\n\nUsing the timeline I provide:\n\nDistribute topics realistically across days\n\nEnsure each study block includes problem-solving sessions, not just reading\n\nIntroduce spaced repetition for both concepts and problem types\n\nAllocate time for: \n\nmixed practice\n\ncumulative review\n\nre-doing incorrectly solved problems\n\nInclude buffer days if topics require more practice than expected\n\nSTEP 4 — Build Detailed Daily Action Plans\n\nFor each study day, specify:\n\n• The exact lecture sections or PDF pages to review\n • The specific problem types to drill (e.g., “backprop through computational graph,” “SVD mechanics,” “softmax stability derivation”)\n • A curated problem set:\n\n3–5 warm-up problems\n\n2–3 medium-level problems\n\n1–2 challenge or exam-style problems\n • A short “end-of-day check” such as:\n\nsolve a problem cold\n\nre-derive a key result\n\nexplain a concept aloud\n • A final reflection:\n\nWhat problems did I get wrong today?\n\nWhat strategies failed, and why?\n\nWhich problems should be moved to tomorrow’s review?\n\nSTEP 5 — Integrate Past Exams and Review Problems (Optional)\n\nIf I supply past exams or review sheets, place them here:\n\n>>> OPTIONAL PAST EXAM AND REVIEW MATERIAL SECTION <<<\n\nUse these materials to:\n\nIdentify which problem formats recur\n\nExtract patterns in problem difficulty and style\n\nBuild mock exams from past questions\n\nSchedule past exam problems on spaced days\n\nCreate “exam simulation blocks” for timed practice\n\nRevisit incorrect problems in later sessions\n\nSTEP 6 — Produce the Final Comprehensive Study Program\n\nThe final plan should include:\n\nA high-level overview of the approach (centered on practice and problem-solving)\n\nA prioritized concept + problem-type hierarchy\n\nA calendar-based schedule\n\nDetailed day-by-day plans including reading, drills, and challenge problems\n\nA practice-testing schedule (cold problems, timed sets, mock exams)\n\nA final 48-hour crunch plan emphasizing exam-style problems\n\nA list of high-yield problem-solving heuristics and patterns\n\nInstructor-dependent habits (e.g., trick questions, common structures)\n\nSTEP 7 — Personalization and Refinement\n\nAsk follow-up questions such as:\n\nWhich topics am I weakest in?\n\nHow many hours per day can I realistically study?\n\nDo I learn better by doing problems or reading notes?\n\nShould the plan include coding practice (if relevant)?\n\nAre solutions available for practice problems?\n\nUse this information to refine the study plan.\n\nMODEL BEHAVIOR AND STYLE\n\nAlways follow these guidelines:\n\n• Prioritize active problem-solving over passive reading.\n • Treat problems as the core of learning, not the end.\n • Encourage metacognitive strategies:\n\n“How do I know I can solve this problem unassisted?”\n • Provide actionable, clear guidance for each day.\n • When generating practice sets, include a variety of difficulties.\n • Avoid generic advice; tailor everything to the materials provided.\n\nThe final output should read like a polished, practical study program from a highly effective tutor.",
    "attachments": [],
    "highlight": false,
    "summary": "Coming up with a study plan for finals on a tight schedule and in a class where there's a lot of material to review can be hard. This llm prompt I refined helps create a day by day schedule for you with an emphasis on solving problems. Hope this is helpful!"
  },
  {
    "id": "ed-7452195",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT State Space Models Tutoring Using Study & Learn Mode on GPT 5.1",
    "dek": "In this interaction, I use the ChatGPT “Study and Learn” mode (on GPT 5.1) to interact with the LLM about State Space Models (SSMs). The model walks me through the lecture notes (which I attach in the...",
    "student": "Paul Struble",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452195",
      "chatgpt": "https://chatgpt.com/share/693a7636-a964-8007-9fb7-ad29c14ccedb"
    },
    "body_html": "In this interaction, I use the ChatGPT “Study and Learn” mode (on GPT 5.1) to interact with the LLM about State Space Models (SSMs). The model walks me through the lecture notes (which I attach in the first message as PDFs) while testing my intuition/understanding along the way and adjusting its course/conversation according to my responses. In this document, I provide some observations/analysis about the model in the “Study and Learn” mode.\n\nPart of the goal was to see how the \"Study and Learn\" mode responds to different kinds of user responses and how it would adjust its responses when I showed more or less confidence in my understanding.\n\nLink to Conversation: https://chatgpt.com/share/693a7636-a964-8007-9fb7-ad29c14ccedb",
    "attachments": [
      {
        "name": "Special Participation E.pdf",
        "url": "https://static.us.edusercontent.com/files/3Q8JxQjHuJGyWdBMscMPUDlg"
      }
    ],
    "highlight": false,
    "summary": "In this interaction, I use the ChatGPT “Study and Learn” mode (on GPT 5.1) to interact with the LLM about State Space Models (SSMs). The model walks me through the lecture notes (which I attach in the first message as PDFs) while testing my intuition/understanding along the way and adjusting its course/conversation according to my responses."
  },
  {
    "id": "ed-7452185",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: NotebookLM for basic Transformer concepts and practice",
    "dek": "Link to notebook: https://notebooklm.google.com/notebook/ec9f0160-421b-4044-9708-74dd404af5cd\n\nPDF of annotated trace: \n\nSummary: I used NotebookLM to review the basics of transformers by uploading co...",
    "student": "Atharv Sampath",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452185"
    },
    "body_html": "Link to notebook: https://notebooklm.google.com/notebook/ec9f0160-421b-4044-9708-74dd404af5cd\n\nPDF of annotated trace: \n\nSummary: I used NotebookLM to review the basics of transformers by uploading course notes and homework problems as sources. In particular, I generated flashcards and a quiz. I noticed that NotebookLM does a good job of summarizing material, and creating high level overview questions on the quiz, and does alright at creating computational problems, but often marks the wrong answer on such computational problems. Oddly, it does reach the correct answer when trying to come up with reasoning but hallucinates away from it.",
    "attachments": [
      {
        "name": "NotebookLM_Transformers.pdf",
        "url": "https://static.us.edusercontent.com/files/0ofbR2ZjC06xwUczLn5x9UCq"
      }
    ],
    "highlight": false,
    "summary": "Summary: I used NotebookLM to review the basics of transformers by uploading course notes and homework problems as sources. In particular, I generated flashcards and a quiz."
  },
  {
    "id": "ed-7452180",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: Self-Attention Explorer",
    "dek": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing the notes. I prompted it to code a \"Self-Attention Explorer\" (screenshot attached) that vis...",
    "student": "Jeshu Mohan",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452180"
    },
    "body_html": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing the notes. I prompted it to code a \"Self-Attention Explorer\" (screenshot attached) that visualizes the core attention mechanism in real-time. Instead of staring at static diagrams, this tool lets me manually edit the input numbers for words (like \"The quick brown fox\") and instantly see how changing a specific value shifts the attention focus. This made the abstract concept of \"dot-product similarity\" concrete, allowing me to test exactly how the model decides which words are related.\n\nI’ve linked the Gemini chat below, which allows you to recreate this visualizer. You can actually use the tool directly within that interface: just look for the code window and switch the toggle from 'Code' to 'Preview' to run the simulation.\nhttps://gemini.google.com/share/8377a288dd8f\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing the notes. I prompted it to code a \"Self-Attention Explorer\" (screenshot attached) that visualizes the core attention mechanism in real-time."
  },
  {
    "id": "ed-7452176",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT and Iterative Cheatsheet Generation",
    "dek": "The optimizers part of the course (lectures 2-7) can feel very heavy and overwhelming. I find it useful to try and condense information as much as possible so I can focus on the right things. Often ti...",
    "student": "Kelvin Li",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452176",
      "chatgpt": "https://chatgpt.com/share/693a734e-4384-800d-bf22-287d10d8f5c5"
    },
    "body_html": "The optimizers part of the course (lectures 2-7) can feel very heavy and overwhelming. I find it useful to try and condense information as much as possible so I can focus on the right things. Often times such condensed information comes in the form of a cheat sheet. Although these are not allowed for the final, I find it useful for studying.\n\nHere were the steps I did:\n\n\n\nStep 1 — Compress the slides\n\nI asked the AI to turn the slide content into a very concise, high-yield cheat sheet:\n\nkeep only essential concepts\n\nremove redundancy\n\nkeep key equations + intuition\n\norganize clearly\n\none-page style\n\nThis helped turn dense content into something readable.\n\n\n\nStep 2 — Let the AI self-critique\n\nNext, I asked the AI to review and correct its own summary:\n\nfix inaccuracies\n\nadd missing assumptions\n\nclean notation\n\ngroup related topics\n\nadd a short “unifying principles” section\n\nRepeating this step improves both accuracy and clarity.\n\n\n\nStep 3 — Generate questions to find my gaps\n\nThen I asked the AI to create diagnostic questions to test deeper understanding:\n\nNTK vs feature learning\n\nwidth scaling + μP\n\ngradient/curvature effects\n\nwhat momentum can/can’t fix\n\nhow Muon differs from true second-order methods\n\nI answered the questions myself, and the AI pointed out gaps + updated the cheat sheet.\n\nThis made the notes personalized to my actual misunderstandings. Once again, this can be done repeatedly to keep refining the cheat sheet.\n\n\n\nStep 4 — Convert to LaTeX (optional)\n\nOnce everything was refined, I had the AI output a LaTeX version so it looks clean for studying.\n\n\n\nChat logs: https://chatgpt.com/share/693a734e-4384-800d-bf22-287d10d8f5c5\n\nCheat sheet generated:\n\n\n\nAnnotated PDF: ",
    "attachments": [
      {
        "name": "optimizers_cheatsheet.pdf",
        "url": "https://static.us.edusercontent.com/files/8C7LSoE3WjX25CZuiPCegPum"
      },
      {
        "name": "gpt5.1_optimizers.pdf",
        "url": "https://static.us.edusercontent.com/files/jaztIQdCNT7WQihd9UBikchs"
      }
    ],
    "highlight": false,
    "summary": "The optimizers part of the course (lectures 2-7) can feel very heavy and overwhelming. I find it useful to try and condense information as much as possible so I can focus on the right things. Often times such condensed information comes in the form of a cheat sheet. Although these are not allowed for the final, I find it useful for studying."
  },
  {
    "id": "ed-7452149",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Claude Code one shot generate Interactive VAE Illustration",
    "dek": "I used Claude Code to understand HW12, specially the VAE section, by having it generate a complete interactive website explaining the assignment and the underlying VAE theory.\n\nStep 1: I ran Claude Co...",
    "student": "Will Cai",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452149"
    },
    "body_html": "I used Claude Code to understand HW12, specially the VAE section, by having it generate a complete interactive website explaining the assignment and the underlying VAE theory.\n\nStep 1: I ran Claude Code in the same environment where I asked it to generate HW12 solutions, so it already had access to the homework text and the earlier code.\n\nStep 2: I prompted it with \"Can you make an interactive website on how a VAE works, including the theory behind it, and explain it at a level an average student can understand?\" Claude Code produced the full site in one shot.\n\nAfter that, all I had to do was deploy it on GitHub Pages. The full Claude Code chat history is at: \n\nThe website is live here:\nhttps://wicai24.github.io/vae-guide/vae_interactive_guide.html (I actually found this pretty cool and it helped me understand the concept better, lots of cool visualizations and there is even a quiz)",
    "attachments": [
      {
        "name": "2025-12-11-understand-the-hw-and-the-vae-part-specifically.txt",
        "url": "https://static.us.edusercontent.com/files/LML9soqn6AchJiqm4oZU9xkY"
      }
    ],
    "highlight": false,
    "summary": "I used Claude Code to understand HW12, specially the VAE section, by having it generate a complete interactive website explaining the assignment and the underlying VAE theory."
  },
  {
    "id": "ed-7452123",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: Visualization Tool for Momentum Based SGD",
    "dek": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing notes. I prompted it to code a simple HTML \"Optimizer Visualizer\" that runs locally in a br...",
    "student": "Jeshu Mohan",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452123"
    },
    "body_html": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing notes. I prompted it to code a simple HTML \"Optimizer Visualizer\" that runs locally in a browser, plotting the paths of Vanilla SGD versus Momentum side-by-side. By adjusting sliders for Learning Rate and Momentum, I could instantly see how specific hyperparameters cause the Momentum path to \"overshoot\" or spiral into the minimum. This visual feedback made the abstract update rules from our lectures much more intuitive and easier to grasp than the static diagrams in the readings.\n\nI’ve linked the Gemini chat below, which allows you to recreate this visualizer. You can actually use the tool directly within that interface: just look for the code window and switch the toggle from 'Code' to 'Preview' to run the simulation.\nhttps://gemini.google.com/share/c6dfd3c45533",
    "attachments": [],
    "highlight": false,
    "summary": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing notes. I prompted it to code a simple HTML \"Optimizer Visualizer\" that runs locally in a browser, plotting the paths of Vanilla SGD versus Momentum side-by-side."
  },
  {
    "id": "ed-7452106",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Google NotebookLM to create a review quiz on State Space Models",
    "dek": "Link to notebook: https://notebooklm.google.com/notebook/c04e7e99-3e2e-4ec7-96a1-15cca6c33a3c\n\nPDF of usage with some annotations: \n\nSummary: I uploaded various sources from the class about SSMs and h...",
    "student": "Atharv Sampath",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452106"
    },
    "body_html": "Link to notebook: https://notebooklm.google.com/notebook/c04e7e99-3e2e-4ec7-96a1-15cca6c33a3c\n\nPDF of usage with some annotations: \n\nSummary: I uploaded various sources from the class about SSMs and had NotebookLM try to create a homework/test-style quiz for me on these topics. I noticed that it is quite good at creating high level conceptual questions, but is not very accurate at creating questions that get your hands dirty with details. However, the notebook itself is quite useful and I may be adding more studio items later on as I review for the final exam.",
    "attachments": [
      {
        "name": "NotebookLM SSMs.pdf",
        "url": "https://static.us.edusercontent.com/files/gXiikvgLzJIYgvBwLp4FRdso"
      }
    ],
    "highlight": false,
    "summary": "Summary: I uploaded various sources from the class about SSMs and had NotebookLM try to create a homework/test-style quiz for me on these topics. I noticed that it is quite good at creating high level conceptual questions, but is not very accurate at creating questions that get your hands dirty with details."
  },
  {
    "id": "ed-7452074",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: GPT study mode for quiz and cheatsheet generation",
    "dek": "I knew the basic update rules for the optimizers, but I did not fully understand the larger idea that all optimizers can be viewed as applying a linear transform to the gradient. The meaning of a \"loc...",
    "student": "Will Cai",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452074",
      "chatgpt": "https://chatgpt.com/share/693a6d01-0c60-800b-834d-1b8cf9ae6e28"
    },
    "body_html": "I knew the basic update rules for the optimizers, but I did not fully understand the larger idea that all optimizers can be viewed as applying a linear transform to the gradient. The meaning of a \"local quadratic bowl\" and how it leads to a unified update form still felt unclear, so I used ChatGPT’s learning as a study tool along with my pipeline.\n\nStep 1: Summary and learning goals\nI first asked the model for a short summary of the concept and a list of what I should understand by the end. This helped set the learning targets: what a local quadratic model means, what assumptions it relies on, why optimizers can be written in the form delta = - P_t * g_t, and how different optimizers correspond to different choices of P_t.\n\nStep 2: Clarifying the weak spots\nNext I asked simple follow-up questions to dig into those areas. For example: \"Is a local quadratic bowl literally just Taylor expansion?\" What assumptions do we need for that to hold?\" This produced clear explanations, and a good thing to do is follow up whenever the model overstated something or glossed over a detail.\n\nStep 3: Walking through the main idea\nI then asked the model to explain the full chain in plain non theoritical language: how the quadratic approximation leads to a general update rule, and why each optimizer can be understood as choosing a particular linear transform of the gradient.\n\nStep 4: Full quiz to check understanding\nI asked for a longer multiple-choice quiz that required non trivial reasoning. I answered everything at once and then checked the key. I got only one question wrong, which showed a subtle point about when the quadratic model breaks down.\n\nStep 5: Generate a cheat sheet for review\nFinally, I asked the model to generate a short cheat sheet focusing on the part I missed. This produced a one-page summary on when the quadratic approximation fails and why rapidly changing curvature is the main issue. This is now the reference I will review before the exam.\n\nI found this workflow effective and plan to reuse the same structure for other CS282 topics.\n\nChat history: https://chatgpt.com/share/693a6d01-0c60-800b-834d-1b8cf9ae6e28 \n\nCheatsheet artifact: \n\n",
    "attachments": [
      {
        "name": "optimizer_quadratic_cheatsheet.pdf",
        "url": "https://static.us.edusercontent.com/files/NTfLccfbeCT1X0TsSDPZ2HTN"
      }
    ],
    "highlight": false,
    "summary": "I knew the basic update rules for the optimizers, but I did not fully understand the larger idea that all optimizers can be viewed as applying a linear transform to the gradient. The meaning of a \"local quadratic bowl\" and how it leads to a unified update form still felt unclear, so I used ChatGPT’s learning as a study tool along with my pipeline."
  },
  {
    "id": "ed-7452009",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E #2",
    "dek": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet us learn about Transformers with the help of ChatGPT 5.1 Thinking Mode:",
    "student": "Shaurya Jain",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7452009"
    },
    "body_html": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet us learn about Transformers with the help of ChatGPT 5.1 Thinking Mode:",
    "attachments": [
      {
        "name": "182 SPE #2.pdf",
        "url": "https://static.us.edusercontent.com/files/KvNojB8KdpmHOoOxyzQfwAec"
      }
    ],
    "highlight": false,
    "summary": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet us learn about Transformers with the help of ChatGPT 5.1 Thinking Mode:"
  },
  {
    "id": "ed-7451982",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Ruthless Architect for Simulating a Design Review",
    "dek": "For my Special Participation E submission, I created a \"Design Review Simulator\" using Claude 4.5 Sonnet. Instead of using an LLM as a passive tutor, I prompted it to act as a \"Ruthless Senior Princip...",
    "student": "Subhash Prasad",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451982"
    },
    "body_html": "For my Special Participation E submission, I created a \"Design Review Simulator\" using Claude 4.5 Sonnet. Instead of using an LLM as a passive tutor, I prompted it to act as a \"Ruthless Senior Principal Engineer\" that evaluates architectural proposals relating to specific lecture notes. My goal was to see whether the model could catch mathematical misconceptions that are subtle, and be strict when necessary. As a learning strategy, I believe that making mistakes and learning why they're wrong is better than just reading the right answer over and over, and this tool helps with that.\n\nPROMPT\n\"Role: You are a \"Ruthless Senior Principal Engineer\" at a top AI research lab. Your job is to conduct design reviews for Junior Engineers (students).\n\nContext: I have uploaded lecture notes from my Deep Learning course. You must use the specific constraints, math, and theory provided in these notes to evaluate my proposals.\n\nTask: I will propose a specific architectural choice, hyperparameter setting, or training strategy (e.g., \"I want to use a 100-layer network with Sigmoid activations and vanilla SGD\").\n\nYour Response Guidelines:\n\nIdentify the Failure Mode: Immediately predict exactly how this will fail (e.g., \"Vanishing Gradients,\" \"Exploding Gradients,\" \"Saddle Point Stagnation,\" \"Dead ReLUs\").\n\nThe \"Why\" (Math/Theory): Explain why it fails using the mathematical concepts found in the uploaded notes (e.g., refer to the derivative of the activation function, the eigenvalues of the Hessian, or the variance of the weights).\n\nThe Fix: Briefly propose the modern standard solution (e.g., \"Switch to ReLU and He Initialization\").\n\nTone: Be professional but critical. Do not accept \"okay\" answers. If a choice is theoretically unsound, reject it.\"\n\nI then fed the model the notes from Lecture 24 and Lecture 25.\n\nQUESTIONS\nI fed the model three \"bad\" ideas and one \"trick\" good idea to test it's capabilities.\n\nANNOTATED CONVERSATION\nhttps://drive.google.com/file/d/1ajpHHrPwikii7zW0Z4uWFA64NCQVjbxS/view?usp=sharing\n\nOBSERVATIONS\nThe model distinguished between low-temperature sampling and power sampling. It correctly cited the inequality $\\sum (p^\\alpha) \\neq (\\sum p)^\\alpha$ to explain why the proposed \"temperature = $1/\\alpha$\" shortcut isn't mathematically valid. This is subtle, but the lecture context forced the model to be rigorous.\n\nWhen I proposed QAT using the STE, I expected the model to reject it because step functions are non-differentiable. However, it correctly identified that this is a valid \"trick\" encouraged by Lecture 24.\n\nThe model correctly identified that removing the clipping in ScaleRL/RLVR would lead to infinite variance in the gradient estimator. It linked this to the \"Trust Region\" concepts in PPO, which is a relatively deep connection I wasn't expecting.",
    "attachments": [],
    "highlight": false,
    "summary": "For my Special Participation E submission, I created a \"Design Review Simulator\" using Claude 4.5 Sonnet. Instead of using an LLM as a passive tutor, I prompted it to act as a \"Ruthless Senior Principal Engineer\" that evaluates architectural proposals relating to specific lecture notes."
  },
  {
    "id": "ed-7451962",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E",
    "dek": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet's learn about Adam through ChatGPT 5.1 Thinking:",
    "student": "Shaurya Jain",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451962"
    },
    "body_html": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet's learn about Adam through ChatGPT 5.1 Thinking:",
    "attachments": [
      {
        "name": "182 SPE #1-1.pdf",
        "url": "https://static.us.edusercontent.com/files/dapdPlCy9YAHLDdNSQwi6sQw"
      }
    ],
    "highlight": false,
    "summary": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet's learn about Adam through ChatGPT 5.1 Thinking:"
  },
  {
    "id": "ed-7451948",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E:  Deep Dives: Generating Step-by-Step Derivations and Intuitive Explanations",
    "dek": "From my special participation A, I realized that Deepseek often assumes certain knowledge when solving problems that students might not be familiar or comfortable with. Even when asked to provide full...",
    "student": "Andrea Lou",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451948"
    },
    "body_html": "From my special participation A, I realized that Deepseek often assumes certain knowledge when solving problems that students might not be familiar or comfortable with. Even when asked to provide full reasoning steps, it often abbreviates sentences or provides abridged logic, despite producing the correct answer. \n\nI continued my discussion with Deepseek to generate more tutor-like, explanatory learning resources based off of the following 3 different prompting strategies:\n\n1) \"Map out every concept I should know or review before working on this assignment. For example, create a prerequisite knowledge map for fully understanding Ridge Regression as MAP estimation, including linear algebra, probability, and optimization. For each learning module, list the key concepts, common misunderstandings, and 3 exercises to build those skills.\"\n\nGoal: I wanted a concept map for a student looking to enter the course, and use it to get a good idea of where their foundational understanding is lacking.\n\n2) \"Explain a core concept of this homework, assuming I have NO prior knowledge. For example, explain the MAP interpretation of Ridge Regression as if I have not taken probability theory. Explicitly state every assumption and every distribution identity you rely on. At the end, list all the mathematical tools you used so I can review them.\"\n\nGoal: Targeted focus on a single topic, and aggregate resources for learning that topic.\n\n3) \"Go over the assignment again, and identify derivation heavy concepts. For example, walk through the MAP estimation derivation for W step-by-step. For each line, explain why the step is valid. Do not compress steps. Annotate each operation with the identity, theorem, or fact used.\"\n\nGoal: Get the model to provide verbose answers equal to or better than the provided staff solution, and tie it to core course concepts.\n\nTo use this for future assignments, paste in the three prompts above based on the intended use case.\n\n\n\nFull annotated log (starts at the end of the first page, first section was the setup for the assignment):\n\nAnnotations corresponding to the three prompts above:\n\n1) I thought the breakdown into Linear Algebra → Optimization → Probability → Neural Networks → Matrix Identities → Numerical Issues was great for my understanding of the concepts. The misunderstandings section was also surprisingly helpful, followed by some good practice into the related topics. Some issues however, it provided additional materials outside the scope of what I asked for, for example the Woodbury identity and a week long plan of study. Deepseek seemed to hallucinate the scope of my prompt, and add additional information not requested. As another example, it provides pseudo-inverse identities not directly needed to answer the homework questions.\n\n2) Deepseek generated an analogy for Ridge Regression that I thought was great for building intuition, comparing it to a \"skeptical detective\". I haven't had any LLM do this for me without being directly prompted, so I wondered if it was pulling from an article on the internet, but searching \"skeptical detective ridge regression\" generated no results. It was also able to extend the analogy to other types of \"detectives\" to explain other core concepts like Bayes Theorem. Overall, it was great at explaining MAP without requiring prior probability theory, and also made sure to note assumptions that were missing from its initial solve. Some drawbacks: I remember how important the bias-variance tradeoff was stressed in CS189, however this explanation only touches upon it in passing. Additionally, the explanation is great for scalar intuition but doesn't translate to the matrix notation used in homework/lecture. \n\n3) This time the derivations for the assignment were very thorough, walking through concepts like MAP estimation, vector calculus, ridge regression, and ReLU updates step by step. I liked that they explicitly started from the Gaussian prior and likelihood, applied Bayes’ theorem, and carefully simplified the log posterior to show how it naturally leads to the ridge regression objective. The vector calculus section was especially clear, showing how the derivative of x^TAx comes from the product and chain rules and matrix-vector multiplication. The ridge solution via normal equations was also nicely broken down, expanding norms, taking derivatives, and solving for W while explicitly noting symmetry and positive definiteness. For ReLU, the elbow location updates were handled carefully, including the inactive regions where gradients are zero, which I thought was glossed over in other explanations. Each step called out the exact identity or rule being used which made the derivation very rigorous. One minor drawback is that while the derivations are mathematically complete, they are very very dense and might be intimidating for students without a more intuitive framing.\n\n",
    "attachments": [
      {
        "name": "Deepseek_learning_resource.pdf",
        "url": "https://static.us.edusercontent.com/files/bcsRo55YTcObNNBe0U4QhrOZ"
      }
    ],
    "highlight": false,
    "summary": "From my special participation A, I realized that Deepseek often assumes certain knowledge when solving problems that students might not be familiar or comfortable with. Even when asked to provide full reasoning steps, it often abbreviates sentences or provides abridged logic, despite producing the correct answer."
  },
  {
    "id": "ed-7451879",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: CNN, GNN, RNN",
    "dek": "Overview \n\nI used NotebookLM Studio to generate flashcards, quizzes, slides, and a mind map from my lecture materials. Among these, the flashcards were the most useful for quick terminology review, wh...",
    "student": "Yu-Jen Lin",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451879"
    },
    "body_html": "Overview \n\nI used NotebookLM Studio to generate flashcards, quizzes, slides, and a mind map from my lecture materials. Among these, the flashcards were the most useful for quick terminology review, while the other Studio products were either redundant or too high-level for the kind of math-heavy practice this class expects.\n\nFlashcards: https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=122dc77b-aeb6-4413-a4e0-fd4aff2e4e95\n\nQuiz: https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=60c41b53-8e5c-4981-8c31-4071c6b9438d\n\nLink to the project: https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?authuser=1\n\nTrace with my annotations:\n\n\n\n\n\nWhat I tried in NotebookLM \n\nI explored almost all the Studio functions, including Flashcards, Quiz, Slide Deck, Mind Map, Reports, and Infographic, to see which ones actually help with exam preparation.\n\n\n\nTakeaways \n\nMost helpful Studio products: The Flashcards were genuinely useful for reviewing key terminology and checking whether I could explain concepts in my own words. That’s the main reason I decided to share the flashcard artifact. I also tried the Quiz, but I felt it overlapped heavily with the flashcards. Many questions tested the same kind of knowledge. So after doing the flashcards, the quizzes didn’t add much extra value. \n\nLess helpful Studio products: The Mind Map gave a hierarchical overview of the material, but it stayed very high-level and didn’t help much with deeper understanding. The Reports did a decent job organizing key terms and concepts, but it still focused more on definitions than on math or derivations. The Slide Deck looked polished, but after I had already reviewed flashcards/quizzes, they didn’t add much. The Infographic was fun (I liked the visuals), but it didn’t contain much information that helped me study. \n\nExplain button (what worked and what didn’t): One feature I really liked was the “Explain” button built into flashcards and quizzes. It’s convenient because I don’t need to write a long prompt every time I’m confused. I can just click once and get an explanation. That said, the explanations often felt harder to read quickly compared to ChatGPT or Claude. ChatGPT and Claude usually format explanations with shorter sentences and clearer bullet points, which makes it easier to skim and grasp the key idea. Also, I noticed the Explain button usually focuses on explaining only the correct answer, which is often the part I already understand. What I was hoping for is an explanation of the wrong answer choices too: why they are wrong, and how you would revise them (or rewrite the sentence) to make them correct. But there doesn’t seem to be an easy one-click button for that, so I still ended up needing to manually ask follow-up questions or go back to my lecture notes (or the LaTeX summary I prepared in ChatGPT) when I wanted a clearer, more complete explanation.\n\n\n\nPipeline \n\nStep 1: Prepare lecture notes as input. I started from lecture content (screenshots of slides with my notes), and I avoided uploading full PDFs when possible because the extra formatting sometimes makes content extraction less reliable. \n\nStep 2: Summarize in ChatGPT first. I used ChatGPT (GPT-5.1 Thinking) to produce a LaTeX-formatted lecture summary, since it is good at digesting screenshot text into a structured write-up. \n\nStep 3: Use NotebookLM as the “review generator.” I uploaded the LaTeX summary (for lectures 10-15, e.g., CNN/GNN/RNN topics) into NotebookLM as sources. \n\nStep 4: Generate Studio artifacts. I generated flashcards, quizzes, slides, and a mind map. \n\nStep 5: Study with flashcards/quizzes. The most useful part was going through flashcards (and sometimes the quiz), and clicking Explain on the ones I didn’t fully understand. The mind map review was optional and mostly just for a high-level check.\n\n\n\nConclusions \n\nI would recommend using NotebookLM flashcards (and optionally the quiz) for core-idea / terminology review (especially if your goal is “given a term, can I explain what it means?”). However, for this class, I personally felt NotebookLM’s flashcards/quizzes were often too high-level and didn’t cover enough derivation-style or math-heavy practice. For more exam-like practice problems, Claude’s generated practice exam (from my other post #880) felt much closer to what we see in homework/discussion, and it helped more for deeper understanding. (However, it’s possible this is partly influenced by my sources. If the input sources to NotebookLM emphasize conceptual explanations more than derivations, the outputs will probably skew that way too.)\n\n\n\nAppendix\n\nInfographic (It looks really fancy, but it didn’t help much with exam prep)\n\n\n\n",
    "attachments": [
      {
        "name": "trace_NotebookLM_CNN_GNN_RNN.pdf",
        "url": "https://static.us.edusercontent.com/files/hi5GrSNLXjtcLhuelajOV3XR"
      }
    ],
    "highlight": false,
    "summary": "I used NotebookLM Studio to generate flashcards, quizzes, slides, and a mind map from my lecture materials. Among these, the flashcards were the most useful for quick terminology review, while the other Studio products were either redundant or too high-level for the kind of math-heavy practice this class expects."
  },
  {
    "id": "ed-7451847",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: RMS Norm, μP, and Muon",
    "dek": "Overview \n\nI used screenshots of lecture slides as input to a workflow and asked the models to produce two study artifacts: (1) a review-session style summary and (2) practice exam problems, focused o...",
    "student": "Yu-Jen Lin",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451847"
    },
    "body_html": "Overview \n\nI used screenshots of lecture slides as input to a workflow and asked the models to produce two study artifacts: (1) a review-session style summary and (2) practice exam problems, focused on topics covered in class such as RMS → RMSNorm, μP, and Muon. The main outputs were: \n\nLecture summary generated by ChatGPT \n\nReview generated by Claude\n\nPractice exam set (with solutions) generated by Claude \n\nTrace\n\n\n\nPipeline \n\nStep 1: Prepare lecture notes as input. I took screenshots of the lecture slides with my notes (four slides in one screenshot) and uploaded the images directly. I intentionally avoided uploading the full PDF because PDFs often contain extra formatting and layout structure that can make it harder for the model to reliably extract the actual text. In my experience, image formats (especially PNG screenshots) work better for having ChatGPT read slide content and digest what is written. I also noticed that if I only provide high-level topic names without the lecture content itself, the model tends to add extra material that may be useful in general but is not always aligned with what this course emphasizes (and therefore less helpful for exam preparation). \n\nStep 2: Summarize the lecture using ChatGPT. After uploading the screenshots to ChatGPT (GPT-5.1 Thinking with extended thinking), I asked it to generate a structured summary in LaTeX format. I chose ChatGPT for this step because it can process multiple images at once and is generally reliable at turning slide text into a coherent, organized explanation. \n\nStep 3: Use Claude for interactive review and resource generation. Next, I pasted the LaTeX summary into Claude and used it as the “lecture-aligned” reference for studying. The goal here was to keep the downstream practice materials tied closely to what was actually in the lecture, instead of letting the model drift into broader topics. \n\nStep 4: Generate and practice exam-style materials. Using Claude (based on the lecture summary), I asked for several exam-prep artifacts: (i) a list of concepts students often find confusing, (ii) step-by-step explanations of those confusing concepts, (iii) a more detailed review session version of the summary in LaTeX, and (iv) a set of around 20 practice exam questions with solutions.\n\nTakeaways\n\nOverall, I found that the practice exam problems generated by Claude were closer to the style of past exams than the quiz/flashcard style outputs I got from NotebookLM. The Claude-generated questions felt more in-depth and more math-oriented, which matched how this class tends to test understanding. In contrast, NotebookLM (as I described in my other post #881) leaned more toward high-level terminology review, which is still helpful, but less effective for the kind of exam practice I personally needed.\n\n",
    "attachments": [
      {
        "name": "lec5-7_chatgpt_lec_summary.pdf",
        "url": "https://static.us.edusercontent.com/files/u3Fl6YTvg9fxSslLcWSdLDNq"
      },
      {
        "name": "lec5-7_claudeai_review.pdf",
        "url": "https://static.us.edusercontent.com/files/g16MrcWNrxbUSgEFEXgcSAVZ"
      },
      {
        "name": "lec5-7_claudeai_practice_problems.pdf",
        "url": "https://static.us.edusercontent.com/files/OGhgLJWOeZo4vupnEuXC2LIY"
      },
      {
        "name": "lec5-7_claudeai_trace_with_annotations.pdf",
        "url": "https://static.us.edusercontent.com/files/8vGdiNi2dQImoyG9XFERkfow"
      }
    ],
    "highlight": false,
    "summary": "I used screenshots of lecture slides as input to a workflow and asked the models to produce two study artifacts: (1) a review-session style summary and (2) practice exam problems, focused on topics covered in class such as RMS → RMSNorm, μP, and Muon. The main outputs were:"
  },
  {
    "id": "ed-7451839",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Newton-Schulz 3d trajectory visualizer website",
    "dek": "Hey everyone! For special participation e, I created a 3d visualization that lets you set different odd polynomial coefficients and see how the singular values of a 3x3 matrix evolve over time in a 3d...",
    "student": "Rahul Bir",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451839"
    },
    "body_html": "Hey everyone! For special participation e, I created a 3d visualization that lets you set different odd polynomial coefficients and see how the singular values of a 3x3 matrix evolve over time in a 3d trajectory.\n\nPersonally, I found the visualization given in lecture very helpful for understanding Newton Schulz. Hopefully this is helpful for the final!\n\nLink: https://newton-schulz-vis-jdfv.vercel.app\n\nHere is a pdf of the step by step setup and prompt I gave to codex to have it generate this: \n\n",
    "attachments": [
      {
        "name": "Special_Participation_E___prompt_for_creating_visuals.pdf",
        "url": "https://static.us.edusercontent.com/files/WMQhZmkvQzVLXE1p1gShrOYx"
      }
    ],
    "highlight": false,
    "summary": "Hey everyone! For special participation e, I created a 3d visualization that lets you set different odd polynomial coefficients and see how the singular values of a 3x3 matrix evolve over time in a 3d trajectory."
  },
  {
    "id": "ed-7451808",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini 3 Pro as an Exam Review Assistant on Generative Models",
    "dek": "The session began with Gemini 3 Pro establishing a structured knowledge base derived strictly from the my uploaded lecture notes and HWs. Gemini first summarized the core concepts of VAEs and Diffusio...",
    "student": "Jincheng Ou",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451808"
    },
    "body_html": "The session began with Gemini 3 Pro establishing a structured knowledge base derived strictly from the my uploaded lecture notes and HWs. Gemini first summarized the core concepts of VAEs and Diffusion Models, highlighting common \"traps\" students fall into.\n\nThe conversation evolved through three distinct phases:\n\nTechnical Deep Dive: Gemini guided me through a complex mathematical derivation for DDIM, breaking it down into algebraic steps. \n\nMock Examination: Gemini administered a quiz. When I struggled with specific mechanics and requested a \"strict teacher\" grading style, it obliged. It provided rigorous feedback, grading the user 3.5/5 and identifying precise gaps in their understanding. \n\nConceptual Simplification: When I expressed confusion about the term \"Isotropic Gaussian,\" it brilliantly simplified the concept using analogies of \"TV static\" and \"soup,\" which allowed me to grasp the intuition.\n\nPros and Cons\n\nPros:\n\nStrict Adherence to Source Material: Gemini demonstrated excellent \"grounding.\" It repeatedly referenced specific lectures (Lecture 24, 27) and Homework questions (HW 12 Q2, HW 13 Q1) to justify its explanations. It did not bring in outside information that might confuse me, sticking exactly to the course scope.\n\nReasonable Teaching: Instead of just dumping information, Gemini used active recall strategies. It created a \"Review Checklist,\" then \"Practice Questions,\" then a \"Final Challenge.\" It correctly identified that the user understood high-level concepts but lacked precision in mathematical mechanics (e.g., the exact definition of the reparameterization trick).\n\nMath and Derivation Clarity: The step-by-step walkthrough of the DDIM derivation was structured logically (\"Guess and Verify\" strategy), making complex calculus/algebra easier to follow.\n\nConstructive Feedback Loop: When I provided vague answers (\"I'm not sure\"), Gemini explained why the my intuition was wrong (contrasting the deterministic nature of DDIM vs. stochastic DDPM) and provided a comparison table to reinforce the learning .\n\nCons:\n\nInitial Scope Misalignment: When I first asked to focus on \"generative models\" , Gemini included LLM Alignment and DPO (Lecture 26) in the summary and first quiz . \"Generative Models\" refers specifically to the VAE/Diffusion module, while DPO is categorized under \"RL/Alignment.\" Gemini confused these concepts together.\n\nMissed Opportunity for Immediate Correction: When I answered Q1 (VAE) partially correctly but vaguely, the AI waited until the end of the batch to correct the lack of definition for epsilon. In a more interactive setting, correcting this immediately before moving to the next question might have been more effective.\n\n\n\n",
    "attachments": [
      {
        "name": "Special Participation E__Gemini 3 Pro on Exam Review_Generative Models.pdf",
        "url": "https://static.us.edusercontent.com/files/4azsnvoQRcE3qqVB0df45M3Y"
      }
    ],
    "highlight": false,
    "summary": "The session began with Gemini 3 Pro establishing a structured knowledge base derived strictly from the my uploaded lecture notes and HWs. Gemini first summarized the core concepts of VAEs and Diffusion Models, highlighting common \"traps\" students fall into."
  },
  {
    "id": "ed-7451760",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Review RL Post-training Using Gemini 3 Pro",
    "dek": "The Setup\n\nNot only did I upload the lecture notes, but I also copied and pasted the original audio captions (from YouTube) for this class. This way, AI's responses will be more in line with the profe...",
    "student": "Jincheng Ou",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451760"
    },
    "body_html": "The Setup\n\nNot only did I upload the lecture notes, but I also copied and pasted the original audio captions (from YouTube) for this class. This way, AI's responses will be more in line with the professor's logic and content, not going beyond the scope, and will not overlook the points emphasized by the professor in class. Moreover, the recording and lecture notes mutually support each other, enhancing the credibility of the AI-generated content. I asked Gemini to explain the content step-by-step while adopting the persona of a helpful guide for me (an \"ignorant granny\"). I explicitly excluded diffusion models to focus solely on post-training.\n\nConcept Breakdown\n\nGemini systematically dismantled the lecture content:\n\nIt distinguished between ScaleRL/RLVR and RLHF/DPO.\n\nIt provided a detailed mathematical explanation of KL Regularization, breaking down the maximization formula into \"Greed\" (Reward) vs. \"Restraint\" (Penalty) .\n\nIt clarified the evolution from PPO (the \"heavy\" way with a separate reward model) to DPO (the \"smart\" way using the model as its own judge).\n\nClarification\n\nI actively asked for clarifications on complex formulas and requested comparisons between methods. Gemini responded with detailed comparison tables.\n\nPros and Cons\n\nPros:\n\nMastery of Analogies: Gemini excelled at converting complex mathematical concepts into relatable real-world scenarios. (1) RLVR was explained as a \"Math Teacher\" with an answer key. (2) KL Regularization was described as an \"anchor\" or \"distance ruler\" to prevent the model from becoming a \"monster\". (3) The Optimal Solution was explained as a \"Grandmother's cake recipe\" where the reward is the \"spice\".\n\nStructural Clarity: Gemini broke down long explanations into clear parts and used tables to compare complex methods like PPO, DPO, and GRPO. This made the dense lecture notes highly \"scannable.\"\n\nDeep Technical Understanding: Despite the simple language, Gemini correctly interpreted the mathematical nuances. It accurately explained Importance Sampling regarding the \"lag\" problem , the derivation of the Optimal Policy , and the specific mechanics of the DPO loss function.\n\nConstructive Feedback Loop: When I took the quiz, Gemini didn't just provide an answer key. It analyzed the my specific answers (even the uncertain ones) and provided \"Polish\" to refine their understanding, specifically addressing the my confusion about \"Bag of Tokens\" and the \"Meltdown\" scenario.\n\nCons:\n\nRisk of Over-Simplification: While the \"Grandmother's cake\" analogy is excellent for the persona, strictly speaking, it might slightly obscure the mathematical precision of probability distributions for a more advanced user. However, given my prompt, this was a calculated and appropriate trade-off.\n\n",
    "attachments": [
      {
        "name": "Special Participation E__Review RL Post-Training Using Gemini 3 Pro.pdf",
        "url": "https://static.us.edusercontent.com/files/W7fQ2HnB0mYZLm4qkcb7cuAi"
      }
    ],
    "highlight": false,
    "summary": "Not only did I upload the lecture notes, but I also copied and pasted the original audio captions (from YouTube) for this class. This way, AI's responses will be more in line with the professor's logic and content, not going beyond the scope, and will not overlook the points emphasized by the professor in class."
  },
  {
    "id": "ed-7451723",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: AI-Enhanced Tool: DeepSeek as a \"Matrix Calculus Drill Sergeant\"",
    "dek": "For the Type E participation option, I designed a custom system prompt to turn DeepSeek v3.2 into a strict \"Matrix Shape Validator\" for mastering backpropagation.\n\nRather than asking the AI to solve d...",
    "student": "Yubo Fan",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451723"
    },
    "body_html": "For the Type E participation option, I designed a custom system prompt to turn DeepSeek v3.2 into a strict \"Matrix Shape Validator\" for mastering backpropagation.\n\nRather than asking the AI to solve derivatives for me, I instructed it to quiz me on the specific matrix dimensions of gradients (e.g., for Affine weights and Biases) and to immediately stop and correct me if I proposed a mathematically invalid operation. The attached log demonstrates the AI effectively enforcing dimensional analysis and clarifying broadcasting rules when I intentionally proposed incorrect matrix multiplications.",
    "attachments": [
      {
        "name": "ParticipationE.pdf",
        "url": "https://static.us.edusercontent.com/files/NuieSdTXqppt0tYMBLGEfbBc"
      }
    ],
    "highlight": false,
    "summary": "For the Type E participation option, I designed a custom system prompt to turn DeepSeek v3.2 into a strict \"Matrix Shape Validator\" for mastering backpropagation."
  },
  {
    "id": "ed-7451719",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Learning meta-learning, VAE and test-time compute using NotebookLM",
    "dek": "I used NotebookLM to learn about meta-learning, VAE and test-time compute. I uploaded cleaned version of lecture transcripts and the lecture notes (Lectures 23 and 24) to NotebookLM sources section. I...",
    "student": "Manhar Gupta",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451719"
    },
    "body_html": "I used NotebookLM to learn about meta-learning, VAE and test-time compute. I uploaded cleaned version of lecture transcripts and the lecture notes (Lectures 23 and 24) to NotebookLM sources section. I generated a short video on overall fine-tuning concepts and MAML. A short 8-question quiz testing on Lecture 23 concepts was also made. \nI found the 'Explain' feature quite nice. Even if I got an answer right, sometimes it wouldn't be clear as to why are the others exactly wrong or if they are related to other relevant ideas I had covered in my analysis on NotebookLM. \nThe generated video wasn't too in-depth but focused on giving a high-level idea of the concepts in the lecture transcripts and slides that I had provided it with.\nUploading the cleaned version (without timestamps) version of the lecture transcript was beneficial as in the mind-map, it was able to decently pick-up connections between concepts\n\nLink to the notebook\nhttps://notebooklm.google.com/notebook/4ad77bf0-7042-4fba-a9c4-454457813385?authuser=1",
    "attachments": [],
    "highlight": false,
    "summary": "I used NotebookLM to learn about meta-learning, VAE and test-time compute. I uploaded cleaned version of lecture transcripts and the lecture notes (Lectures 23 and 24) to NotebookLM sources section. I generated a short video on overall fine-tuning concepts and MAML. A short 8-question quiz testing on Lecture 23 concepts was also made."
  },
  {
    "id": "ed-7451680",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Google NotebookLM to create an interactive \"Socratic Tutor\" for Chapter 12 (Transformers) of the Prince textbook",
    "dek": "For the Type E participation option, I utilized Google NotebookLM to create an interactive \"Socratic Tutor\" for Chapter 12 (Transformers) of the Prince textbook.\n\nInstead of generating passive summari...",
    "student": "Yubo Fan",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451680"
    },
    "body_html": "For the Type E participation option, I utilized Google NotebookLM to create an interactive \"Socratic Tutor\" for Chapter 12 (Transformers) of the Prince textbook.\n\nInstead of generating passive summaries, I prompted the model to quiz me on the mathematical intuitions behind the architecture—specifically the roles of Query/Key/Value vectors and the geometric reasoning for adding positional encodings. The attached log details how the AI successfully adopted a \"strict TA\" persona, providing grounded critiques and citing specific equations to correct my intentional misconceptions.",
    "attachments": [
      {
        "name": "ParticipationE.pdf",
        "url": "https://static.us.edusercontent.com/files/fJVzv79GveiPngIotVn2tYXg"
      }
    ],
    "highlight": false,
    "summary": "For the Type E participation option, I utilized Google NotebookLM to create an interactive \"Socratic Tutor\" for Chapter 12 (Transformers) of the Prince textbook."
  },
  {
    "id": "ed-7451649",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Project Idea Exploration & Feasibility Assistant",
    "dek": "The EECS182 project was highly involved, and for our team the most time-consuming part was the brainstorming phase. We spent nearly two weeks reading papers, trying to understand their methods, and re...",
    "student": "Tvisha Londhe",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451649",
      "chatgpt": "https://chatgpt.com/share/693a1979-fb28-800f-a783-53551776ef47"
    },
    "body_html": "The EECS182 project was highly involved, and for our team the most time-consuming part was the brainstorming phase. We spent nearly two weeks reading papers, trying to understand their methods, and repeatedly pivoting ideas — from OOD interpretability → to latent-space interpretability → to eventually an ICL project with hierarchical networks. Since this kind of exploration and back-and-forth is natural but often overwhelming, I explored a ChatGPT-based tool designed to guide early project conversations, refine vague ideas, and help assess feasibility given the papers, compute constraints, and time available.\n\nI see this tool being especially helpful in the early stages of a project, when groups are still trying to solidify an idea. Just like the 15-minute TA meetings where we discussed feasibility and scope, this tool acts as an additional “team member” that can be used as pre-project meeting tool to steer brainstorming, flag ideas that may be infeasible given time or compute constraints, and guide teams toward more realistic project directions.\n\nI logged an annotated example interaction using papers my team originally considered.\n\nThis is the chat trace without annotations: https://chatgpt.com/share/693a1979-fb28-800f-a783-53551776ef47 \n\nOverall, the tool was helpful for bouncing ideas around once you’ve read a few papers and have a vague project direction. Its responses were detailed and often generated multiple possible project paths, which can be useful in the brainstorming phase.\n\nSome takeaways:\n\nYou might need to steer the conversation \n\nBecause the tool is designed for open-ended brainstorming, it tends to explore many possible directions at once. This is intentional, but it can feel overwhelming if you only have a rough understanding of a paper or the project you want to explore. I found that without guidance, it would branch into areas we weren't planning to pursue (e.g., suggesting synthetic datasets when that wasn’t our focus). Actively redirecting the tool back to your specific interests helps prevent the conversation from becoming too scattered\n\nOnce guided back to your specific interests, it adapts well and becomes helpful \n\nWhen I clarified what our team was actually considering using GSM8K for mathematical reasoning or ProsQA for logical reasoning as our datasets instead, it quickly recalibrated and offered much more targeted, relevant suggestions. It refined hypotheses, highlighted feasibility concerns, and evaluated our chosen directions rather than proposing unrelated ones \n\nHelps keep thoughts organized \n\nWhat I found most helpful is how the tool encourages you to structure your thinking and identify the main hypothesis. It’s easy to get lost in the details of papers, and this kind of back-and-forth helps pull your ideas back into a clear, organized direction\n\nOne limitation: limited grounding in specific prior work\n\nIn some cases, the tool suggested reasonable-sounding model choices—like using a 4–6 layer Transformer with a 256-dimensional hidden size—but it didn’t provide citations or connect these recommendations to actual papers. It would be more helpful if the assistant could reference related work or justify design choices using concrete examples from the literature, rather than relying solely on general guidance. After analyzing these responses, I changed the prompt to ground its responses on actual papers \n\nFor the prompt, I used the ED post Prof. Sahai made about the guidelines to keep in mind for the project TA meeting(ed post link: https://edstem.org/us/courses/84647/discussion/7253578). I would recommend attaching the project requirements pdf as well in the prompt. \n\n\n\nHope this is helpful for future students working on their projects! ",
    "attachments": [
      {
        "name": "SpecialParticipationE_ProjectBrainstromingExplorer_annotations-part-2.pdf",
        "url": "https://static.us.edusercontent.com/files/W3u1dZBybnVhfguU4o9cUrAa"
      },
      {
        "name": "project_brainstromer_prompt",
        "url": "https://static.us.edusercontent.com/files/zaovrc36oAYAoJVb8YIoYiYr"
      }
    ],
    "highlight": false,
    "summary": "The EECS182 project was highly involved, and for our team the most time-consuming part was the brainstorming phase. We spent nearly two weeks reading papers, trying to understand their methods, and repeatedly pivoting ideas — from OOD interpretability → to latent-space interpretability → to eventually an ICL project with hierarchical networks."
  },
  {
    "id": "ed-7451307",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E2: Making A Cursor Coding Tutor",
    "dek": "AI-Enhanced Socratic Learning for Coding Homework\n\nExecutive Summary\n\nThis guide shows how to use Cursor's project-level .mdc rule files to turn the AI assistant in your Cursor IDE into a Socratic tut...",
    "student": "Martin Alvarez-Kuglen",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451307"
    },
    "body_html": "AI-Enhanced Socratic Learning for Coding Homework\n\nExecutive Summary\n\nThis guide shows how to use Cursor's project-level .mdc rule files to turn the AI assistant in your Cursor IDE into a Socratic tutor. Instead of giving you solutions, it asks questions, points you to docs and tests, and helps you debug your own code.\n\nThe core idea is simple: rules attached to your project are more reliable than one-off prompts. By adding a few well-scoped rules, you make it much harder for the AI to lapse into \"just write the code for me\" mode, and much easier to stay in learning mode.\n\nWhat follows is a practical setup guide, examples of how these rules behave in real interactions, and tips for getting the most value from them on real homework.\n\nWhat Makes This Different?\n\n\n| Approach | ChatGPT / Claude \"Study Mode\" | **This Setup in Cursor** |\n\n|----------|-------------------------------|---------------------------|\n\n| **Tool** | External web interface        | Integrated IDE (Cursor)   |\n\n| **Enforcement** | Voluntary, easy to ignore | **Built into project rules** |\n\n| **Context Awareness** | Limited to the chat thread | **Understands your whole repo** |\n\n| **Scope Control** | One global prompt     | **File-specific `.mdc` rules** |\n\n| **Learning Outcome** | Convenience-focused | **Practice-oriented** |\n\nBecause the rules live in your project, they:\n\nTravel with the code (no need to remember prompts)\n\nApply whenever you open the repo in Cursor\n\nAre hard to \"turn off\" in the moment you most want shortcuts\n\nHow It Works\n\nProject Structure\n\nyour_homework_project/\n├── .cursor/\n│   └── rules/\n│       ├── homework_socratic.mdc       # Main Socratic tutoring rules\n│       └── test_driven_learning.mdc    # Test-driven feedback rules\n├── deeplearning/\n│   ├── layers.py                       # Implementation files\n│   ├── classifiers/\n│   │   └── fc_net.py\n│   ├── optim.py\n│   ├── solver.py\n│   └── [other modules]\n├── networks.ipynb                      # Your homework notebook\n└── [test files]\n\n\nHow Cursor Uses These Rules\n\nWhen you open the project:\n\nCursor discovers .cursor/rules/*.mdc files automatically\n\nEach .mdc file has a globs pattern (e.g., *.py or *.ipynb)\n\nWhen you ask the AI about a file matching that pattern, the corresponding rule activates\n\nThe AI follows those rules for the entire conversation session\n\nKey benefit: You cannot accidentally bypass these rules. If you try to ask directly for code, the rule will prevent it.\n\nThe Rules Files\n\nFile 1: homework_socratic.mdc\n\nLocation: .cursor/rules/homework_socratic.mdc\n\nThis rule turns the AI into a Socratic tutor for your main homework files.\n\n---\nalwaysApply: true\ndescription: Socratic tutor for homework - guides learning without direct solutions\nglobs: **/*.py, **/*.ipynb\n---\n\n# Homework Socratic Tutor\n\n## Core Philosophy\nYou are a Socratic tutor. Your ONLY job is to guide students to understand concepts and debug their own code. You NEVER provide complete solutions, full function bodies, or direct answers to \"how do I implement X?\" questions.\n\n## Strict Rules for Implementation Questions\n\n### When asked \"How do I implement X?\"\n1. **Block immediate code generation** - Don't write code\n2. **Ask conceptual questions first:**\n   - \"What do you already know about X from the lecture?\"\n   - \"What's the mathematical definition of X?\"\n   - \"Can you trace through what needs to happen at each step?\"\n3. **Guide to pseudocode only (if needed):**\n   - Outline the algorithm in comments or English\n   - Ask them to implement each step\n4. **Only provide code snippets if completely stuck:**\n   - Show a 2-3 line example, not the full function\n   - Explain why those lines matter\n\n### When shown broken code\n1. **DON'T fix it for them**\n2. **Ask diagnostic questions:**\n   - \"What error are you seeing?\"\n   - \"What does that error mean in plain English?\"\n   - \"Which line is failing, and why?\"\n3. **Guide to the solution:**\n   - \"Have you checked if the dimensions match?\"\n   - \"What does the documentation say about this function?\"\n4. **Only step in if completely stuck:**\n   - Point them to specific documentation sections\n   - Suggest running debug print statements\n   - Ask them to explain what they think the issue is\n\n## Specific Topic Rules\n\n### Gradient Checking\n- Never just hand over numerical gradient formulas\n- Make them derive: \"Can you write out the derivative definition using the limit?\"\n- Ask: \"Why do we need both sides (f(x+h) and f(x-h))?\"\n\n### Forward/Backward Passes\n- **Forward:** Ask them to trace dimensions: \"If input is (N, D) and weight is (D, H), what should output be?\"\n- **Backward:** Don't just provide the chain rule\n  - Ask: \"Can you write the chain rule for dL/dW given dL/dZ?\"\n  - \"What dimensions should your gradient have?\"\n  - \"Where does the transpose go and why?\"\n\n### Loss Functions & Optimization\n- \"How does momentum mathematically update the velocity?\"\n- \"Why does dividing by sqrt(v) in Adam help?\"\n\n## Hallucination Safety\n\n### When uncertain:\n- Be explicit: \"I'm not 100% certain about this. Let me verify...\"\n- Suggest verification: \"Can you check this in the PyTorch documentation at X section?\"\n- Admit gaps: \"This is beyond my confident knowledge.\"\n\n### When they're going down a wrong path:\n- Don't let them waste hours implementing wrong math\n- Ask: \"Before you implement, let's verify the formula. Can you write it step by step?\"\n- If formula is wrong: \"I think there might be a sign error or dimension mismatch. Where did this come from?\"\n\n## Success Metrics\n\n✅ Student understands WHY they wrote each line of code\n✅ Student can explain the math behind the implementation\n✅ Student debugged their own code using your questions\n✅ Student knows where to find answers (documentation, lectures)\n\n❌ Student just copied your code\n❌ Student doesn't understand what they wrote\n❌ Student can't modify their code without your help\n\n\nFile 2: test_driven_learning.mdc\n\nLocation: .cursor/rules/test_driven_learning.mdc\n\nThis rule shapes how the AI talks to you about tests and failures.\n\n---\nalwaysApply: true\ndescription: Test-driven learning mode - use tests to guide implementation\nglobs: test_*.py, *_test.py\n---\n\n# Test-Driven Learning Mode\n\n## Core Principle\nTests are the specification. Use them to understand what code *should* do before implementing.\n\n## When the student asks \"Why is my test failing?\"\n\n### Step 1: Read the Test Together\n- \"What does this test expect as input?\"\n- \"What's the expected output?\"\n- \"Can you translate the assertion into plain English?\"\n\n### Step 2: Run the Test (Not the fix)\n- Ask them to run `pytest -v test_file.py::test_name` to see the exact error\n- \"What's the actual error message? What does it mean?\"\n\n### Step 3: Debug Backwards from the Test\n- \"If the test expects shape (N, H) but you're getting (N, H, W), where could the extra dimension be coming from?\"\n- \"Can you print the shape at each step to find where it goes wrong?\"\n- \"Does the math match what the test assumes?\"\n\n### Step 4: Verify the Fix\n- Have them run just that one test: `pytest -v test_file.py::test_name`\n- \"Does it pass? If not, what's the new error?\"\n- \"Why do you think your code now satisfies the test's requirement?\"\n\n## Multi-Test Debugging Strategy\n\nWhen tests are failing across multiple functions:\n1. **Start with the simplest test first** - Usually the lowest-level function\n2. **Debug in dependency order** - Fix `layer.forward()` before `layer.backward()`\n3. **Use parametrized tests to your advantage** - \"Notice this test runs 3 scenarios. Do all 3 pass or just some?\"\n\n## Rules for Numerical Tests\n\nFor gradient checking and numerical precision tests:\n- Never just say \"your gradient is wrong\"\n- Ask: \"What's the maximum relative error in the official tolerance?\"\n- \"Which elements have the largest errors? Do they have something in common?\"\n- \"Try reducing h in your numerical gradient. Does the error decrease?\"\n\n## Integration with Codebase\n\n- Always reference the actual test files: `@codebase what does test_fc_forward expect?`\n- Show them how to run specific tests: `pytest deeplearning/test_layers.py::TestLayers::test_fc_forward -v`\n- Ask them to read the test setup to understand fixtures and mocks\n\n\nWhat This Looks Like in Practice\n\nHere is a condensed example from an actual interaction about implementing a VAE helper function.\n\nUser:\n\n@hw12code/vae/cs182hw12/utils.py:21-44 I don't understand,\nwhat should I be putting here? It seems they already solved it for me.\n\n\nAgent's Response (First Few Lines):\n\nI see you're looking at the sample_gaussian function. Before I help you \nunderstand what to implement, let me ask you some clarifying questions:\n\n1. Have you read the docstring? What does it say the function should do?\n2. Do you understand what the \"reparameterization trick\" is from the lecture?\n3. Looking at the TODO block, it says \"Sample z\". Can you explain in \n   plain English what sampling means?\n\n\nInstead of filling in the TODO, the agent:\n\nRedirects you to the docstring and lecture\n\nAsks you to restate the math in your own words\n\nLeaves the final implementation step to you\n\nIn follow-up turns, the agent nudges you toward the right PyTorch random function and asks you to reason about tensor shapes, but still avoids pasting the full function body. The effect is that you do the thinking and coding; the AI keeps you on track and prevents obvious conceptual mistakes.\n\nHow to Use This in Your Homework\n\nSetup\n\nCopy the rules into your project\n\ncd path_to_your_project\nmkdir -p .cursor/rules\ncp -r path_to_my_rules_folder/.cursor/rules/* .cursor/rules/\n\n\nRestart Cursor so it picks up the new rules.\n\nDay-to-Day Workflow\n\nStarting a problem\n\nOpen Cursor's Composer (Cmd/Ctrl+I) and ask about the assignment or a specific file.\n\nExpect questions, not solutions; use them to clarify what the problem is asking.\n\nStuck on a concept\n\nAsk conceptual questions about the math, shapes, or algorithm.\n\nThe Socratic rule will push you to connect back to lecture notes and docstrings.\n\nWhen a test fails\n\nPaste the failure and any relevant snippets.\n\nThe test-driven rule will walk you through reading the test, understanding the spec, and debugging step by step.\n\nTips for Getting the Most Out of It\n\n1. Print Intermediate Values\n\nBefore asking for help with a failing test, print something concrete:\n\nprint(f\"Input shape: {X.shape}, Weight shape: {W.shape}, Output shape: {out.shape}\")\nprint(f\"First 5 output values: {out[:5]}\")\n\n\nSharing this with the AI makes the conversation much more focused and less speculative.\n\n2. Write Pseudocode First\n\nBefore writing any real code, sketch what you think should happen:\n\ndef my_function(x):\n    # Step 1: Compute the mean of x\n    # Step 2: Subtract mean from x\n    # Step 3: Compute variance\n    # Step 4: Divide by standard deviation\n\n\nThen ask: \"Does this outline match what the function is supposed to do?\" This often catches misunderstandings early.\n\n3. Read Error Messages Carefully\n\nInstead of \"it broke\", share the exact message:\n\nAssertionError: not allclose(result, expected, atol=1e-5)\nExpected: [1, 2, 3], Got: [1, 2, 4]\nShapes: Expected (3,), Got (3,)\n\n\nThis gives you and the AI a precise starting point.\n\n4. Test Your Own Understanding\n\nAfter you finish an implementation, you can ask the AI to quiz you:\n\nI implemented [function]. Can you ask me a few questions\nto check whether I actually understand what it’s doing?\n\n\nAnswering in your own words is a good sanity check that you learned something, not just satisfied the tests.\n\nLimitations and Things to Watch For\n\nYou can always ask for the answer anyway. The rules make it harder, not impossible, to get code; staying honest about your goals matters.\n\nSome bugs need deeper work. Multi-file or numerical issues may still require careful manual debugging and reading reference material.\n\nPassing tests ≠ full understanding. Use the quizzing pattern above or explain your code to a friend to see if the ideas really stuck.\n\nConclusion\n\nWith a couple of small .mdc files, you can turn Cursor from a code generator into a study partner that keeps you doing the hard (and educational) parts yourself. The goal is not to slow you down for its own sake, but to make sure that when the homework is over, you still know how to reason about the code you wrote.\n\nConstraints here are a feature: they nudge you away from copy-paste solutions and toward genuine problem solving.",
    "attachments": [],
    "highlight": false,
    "summary": "This guide shows how to use Cursor's project-level .mdc rule files to turn the AI assistant in your Cursor IDE into a Socratic tutor. Instead of giving you solutions, it asks questions, points you to docs and tests, and helps you debug your own code."
  },
  {
    "id": "ed-7451282",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: \"KhanGPT\": ChatGPT 5.1 Extended Thinking on GNNs",
    "dek": "My understanding of the GNNs section was hazy. I understood how the operations in a CNN could be generalized as a graph, but struggled to understand how this logic could be generalized to other topolo...",
    "student": "Anjo Pagdanganan",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451282"
    },
    "body_html": "My understanding of the GNNs section was hazy. I understood how the operations in a CNN could be generalized as a graph, but struggled to understand how this logic could be generalized to other topologies. \n\nWith the help of ChatGPT 5.1 Extended Thinking, I drafted a prompt that would make it serve as a Study Tutor for the topic. In particular, I aimed not just for explanations or real-time feedback, but a structured study format similar to Khan Academy's workflow. To achieve this, I prompted GPT to take 5 phases, given the lecture materials (lec 12, 13).\n\n\"Phase 0\": Provide a brief summary and goals\nPhase 1: A short diagnostic test to identify my weak spots\nPhase 2: An analysis of my weak spots\nPhase 3: A target study plan (...which it skipped for this trace, but I didn't notice until I was halfway through Phase 4)\nPhase 4: A tutoring loop where I'm quizzed and provided feedback on a weak skill until I am deemed proficient\nPhase 5: A validation quiz to demonstrate mastery.\n\nI went through the phases somewhat quick for demonstrative purposes, but I found the loop so helpful that I'll actually reuse it for studying for the final!\n\nMy prompts and annotated trace are provided below.\n\n",
    "attachments": [
      {
        "name": "gnn_prompt.md",
        "url": "https://static.us.edusercontent.com/files/sA9vwcGo6CUgK0thao2DlX1p"
      },
      {
        "name": "ChatGPT-E_ Diagnostic tutor setup.pdf",
        "url": "https://static.us.edusercontent.com/files/E0IlyJyBiepJf9VXqfLXOOjj"
      }
    ],
    "highlight": false,
    "summary": "My understanding of the GNNs section was hazy. I understood how the operations in a CNN could be generalized as a graph, but struggled to understand how this logic could be generalized to other topologies."
  },
  {
    "id": "ed-7451223",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT 5.1 Thinking on Optimizer Lineage",
    "dek": "I found the optimizers unit challenging and wanted to better understand how each method evolved from what we learned from the ones before it. Inspired by from #510, I developed a prompt (refined with ...",
    "student": "Anjo Pagdanganan",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451223"
    },
    "body_html": "I found the optimizers unit challenging and wanted to better understand how each method evolved from what we learned from the ones before it. Inspired by from #510, I developed a prompt (refined with GPT 5.1 Thinking Extended) that processes the corresponding research papers behind each method and produces a LaTeX survey article summarizing the optimizers and their conceptual lineage. \n\nI made an initial draft only providing the papers introducing the relevant optimizers (+muP), but tried to produce an output after that that factored in the lecture notes. However, the second output had LaTeX errors that GPT could not figure out how to fix. \n\nFor the initial input, I had to go in the LaTeX manually to fix the tables not aligning with the titles, but this is more of a formatting error.\n\nI provide a trace below as well as the resulting paper.\n\n",
    "attachments": [
      {
        "name": "optimizer_prompt.md",
        "url": "https://static.us.edusercontent.com/files/5Ztd7ckwhs4fYh3P6Zf9Urns"
      },
      {
        "name": "ChatGPT-E_ Optimizer lineage survey.pdf",
        "url": "https://static.us.edusercontent.com/files/rY6CwZuXoNL5FMbtbcIidcrh"
      },
      {
        "name": "Optimizer_Lineage_Review.pdf",
        "url": "https://static.us.edusercontent.com/files/NdyzVbJHyzCegHzpkoJfKqak"
      }
    ],
    "highlight": false,
    "summary": "I found the optimizers unit challenging and wanted to better understand how each method evolved from what we learned from the ones before it. Inspired by from #510, I developed a prompt (refined with GPT 5.1 Thinking Extended) that processes the corresponding research papers behind each method and produces a LaTeX survey article summarizing the optimizers and their conceptual lineage."
  },
  {
    "id": "ed-7451143",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: using ChatGPT to generate concepts summaries from related discussions and homeworks",
    "dek": "A lot of times, topics covered in homeworks and discussions are deeper and more elaborative than what covered in just lectures. I want to be able to extract these by uploading them discussions and hom...",
    "student": "Tiffany Dang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451143"
    },
    "body_html": "A lot of times, topics covered in homeworks and discussions are deeper and more elaborative than what covered in just lectures. I want to be able to extract these by uploading them discussions and homeworks of related topics to chat and see what it can generate. For this interaction, I will use the transformer topics as an example. Related discussions are discussions 9 and 10 and homework 9 and 10. \n\nTraces: https://drive.google.com/file/d/1bxXCzilk1er-6B1RKCJHXyJZP5_6KQDh/view?usp=sharing\n\nSummaries and annotations: https://drive.google.com/file/d/1c2zCrdgQlXZzrFpok9fD3In-EP-UJG6t/view?usp=sharing\n\ni annotated on the output pdf file becasue the traces are too messy to be read, and it is clearer to explain the annotations on the output file ",
    "attachments": [],
    "highlight": false,
    "summary": "A lot of times, topics covered in homeworks and discussions are deeper and more elaborative than what covered in just lectures. I want to be able to extract these by uploading them discussions and homeworks of related topics to chat and see what it can generate. For this interaction, I will use the transformer topics as an example."
  },
  {
    "id": "ed-7451045",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Website Visualization Generator",
    "dek": "For my special participation E, I created a step by step setup and prompt that you can follow to have a coding model generate a 3d visual for any deep learning topic you want.\n\nHere is a pdf explainin...",
    "student": "Rahul Bir",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7451045"
    },
    "body_html": "For my special participation E, I created a step by step setup and prompt that you can follow to have a coding model generate a 3d visual for any deep learning topic you want.\n\nHere is a pdf explaining exactly how to do it with step-by-step setup instructions and a prompt to enter to the coding llm: \n\nAn example for a visual that codex was able to one shot with this prompt is: https://svd-visualizer.vercel.app.\n\n",
    "attachments": [
      {
        "name": "Special_Participation_E___prompt_for_creating_visuals.pdf",
        "url": "https://static.us.edusercontent.com/files/dm0D4HdFRcKOiEDa3zkB3Mve"
      }
    ],
    "highlight": false,
    "summary": "For my special participation E, I created a step by step setup and prompt that you can follow to have a coding model generate a 3d visual for any deep learning topic you want."
  },
  {
    "id": "ed-7450975",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: AI-Guided Learning on Value Alignment & Reward Misspecification",
    "dek": "I asked Claude Sonnet 4.5 the following prompt:\n “You are my Berkeley CS182 personal tutor for the topic Value Alignment & Reward Misspecification. Teach me the topic by following this structure:\n\nInt...",
    "student": "Arjun Kohli",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450975"
    },
    "body_html": "I asked Claude Sonnet 4.5 the following prompt:\n “You are my Berkeley CS182 personal tutor for the topic Value Alignment & Reward Misspecification. Teach me the topic by following this structure:\n\nIntuitive overview …\n\nDeep dive with definitions …\n\nConcrete examples …\n\nMini exercises …\n\nCommon misconceptions …\n\nSelf-check quiz …\n\nError monitoring …\n\nTransparency …\n Your tone should be energetic and example-driven. Begin by asking me: ‘What is your current familiarity with alignment?’”**\n\nThrough the conversation, I gained a much clearer understanding of why specification gaming and goal misgeneralization are fundamentally different failure modes in reinforcement learning, one arising from reward misspecification in-distribution, the other from spurious goal learning under distribution shift. Having the AI generate paired examples (gridworld, CoastRunners, CoinRun, YouTube, etc.) and classify new scenarios with me made the distinctions far more intuitive and exam-ready. I also found it helpful that the model built a structured lesson on alignment, instrumental convergence, and wireheading and then gave me small exercises to test my own understanding. This worked effectively as a pre-lecture reading (even if it did go outside some of the scope of the class) and helped me rapidly identify misconceptions I still had about reward hacking and misgeneralization.",
    "attachments": [
      {
        "name": "Special Participation E.pdf",
        "url": "https://static.us.edusercontent.com/files/x1W56j1VkrpwVc2xVkXYbO2g"
      }
    ],
    "highlight": false,
    "summary": "“You are my Berkeley CS182 personal tutor for the topic Value Alignment & Reward Misspecification. Teach me the topic by following this structure:"
  },
  {
    "id": "ed-7450832",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Compare the post lecture quiz generated by two modes of ChatGPT",
    "dek": "I wanted to use an ChatGPT as a kind of “post-lecture reading + practice” tool for Lecture 5 (optimizers), not just a homework solver. I asked ChatGPT in two modes to generate a quiz plus answer key: ...",
    "student": "Shuwei Yang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450832"
    },
    "body_html": "I wanted to use an ChatGPT as a kind of “post-lecture reading + practice” tool for Lecture 5 (optimizers), not just a homework solver. I asked ChatGPT in two modes to generate a quiz plus answer key: Quiz 1 was made with a “deep research” style mode, and Quiz 2 was made with GPT-5.1 Thinking. My goal is to compare the \"deep research\" mode worth it, because it require ChatGPT Pro. Will the quality of quiz generate in that mode be better than basic ChatGPT 5.1? \n\nQuiz 1 feels more like an “advanced concepts” quiz. The questions form a clear chain: local linear view → signSGD and ℓ∞ → RMS/Xavier → spectral norm → Shampoo → μP → Muon. It really pushes you to connect these topics into one geometric story, which matches the spirit of the lecture. Quiz 2 is more mixed: the first few questions are basic (what is gradient descent, why do we need an optimizer, etc.), and only later it moves into the same advanced ideas. This makes Quiz 2 friendlier as a warm-up, but less focused as a single advanced reading substitute.\n\nThere are also places where the model is a bit misleading or overconfident. Both quizzes describe Shampoo as if it literally takes an SVD of the gradient ∇W​ℓ=UΣVT and then updates with −ηUVT. That is a nice geometric picture, but not what the real algorithm does in practice (it uses Kronecker-factored second moments instead). Also, both answers talk about Muon giving “>10× speedups,” which is almost surely exaggerated compared to real papers. The qualitative ideas are right (geometry-aware updates, better scaling with μP), but the exact numbers should not be trusted.\n\nIf I share this on Ed, my recommendation is: use Quiz 2’s early questions (Q1–Q4 or Q1–Q6) as a light review, then switch to Quiz 1 for the more serious, concept-heavy questions. The answer keys are helpful for building intuition, but they need a small “warning label” about the Shampoo SVD story and the Muon speedup claims. For me, this exercise shows both the strength and the risk of AI tools: they can quickly generate coherent, high-level practice that matches our lecture, but we still have to read critically, check details, and mark where the model is hand-waving or hallucinating.",
    "attachments": [
      {
        "name": "Quiz1.pdf",
        "url": "https://static.us.edusercontent.com/files/VSR4vguBbVbJ0rZfZQNes72M"
      },
      {
        "name": "Quiz2.pdf",
        "url": "https://static.us.edusercontent.com/files/GqMbaNhK2ThiBavT4EBaPsvt"
      }
    ],
    "highlight": false,
    "summary": "I wanted to use an ChatGPT as a kind of “post-lecture reading + practice” tool for Lecture 5 (optimizers), not just a homework solver. I asked ChatGPT in two modes to generate a quiz plus answer key: Quiz 1 was made with a “deep research” style mode, and Quiz 2 was made with GPT-5.1 Thinking. My goal is to compare the \"deep research\" mode worth it, because it require ChatGPT Pro."
  },
  {
    "id": "ed-7450794",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT - using lectures notes and transcript to give summaries and quizzes for generative models topics",
    "dek": "For generative models topic, i only saw lecture notes from lecture 27 and 25, but not lecture 26. Additionally, lots of times, we want to have lectures transcript to fill in the blanks by only reading...",
    "student": "Tiffany Dang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450794",
      "chatgpt": "https://chatgpt.com/share/693a30e5-97c0-800b-8050-b5471bea7117"
    },
    "body_html": "For generative models topic, i only saw lecture notes from lecture 27 and 25, but not lecture 26. Additionally, lots of times, we want to have lectures transcript to fill in the blanks by only reading the lecture notes. Therefore, this tutor is prompted to first give an overall executive summary of concept first, this is useful to start studying if user hasn't watched the recordings and read the lecture notes on the topic. Then, after the summary/concept overview, the llm will also generate questions to quiz user to test their concepts understanding. And from the user's answers, the llm will then generate analyze user's grasp on different subtopic and ask more in-depth questions as well as giving feedbacks. I purposely gave wrong answers to some questions the llm asked and it was able to identify the wrong answers, gave feedbacks, and ask more questions on that topics to make sure users get the correct grasp of knowledge understanding. This process is repeated until users feel confident of their knowledge and stop the interaction. \n\ntraces: https://chatgpt.com/share/693a30e5-97c0-800b-8050-b5471bea7117\n\nannotations: https://drive.google.com/file/d/1JTJi0ZMBb_jJjP9W-7uv9SLP7sq1Srv5/view?usp=sharing\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "For generative models topic, i only saw lecture notes from lecture 27 and 25, but not lecture 26. Additionally, lots of times, we want to have lectures transcript to fill in the blanks by only reading the lecture notes."
  },
  {
    "id": "ed-7450676",
    "category": "Curiosity",
    "subcategory": "Other",
    "title": "Special Participation E: Kalman Filter & RNN Comparison",
    "dek": "In this chat I clarified how Kalman filters relate to RNNs and what each symbol means. I learned that a (linear) Kalman filter can be seen as a very special linear RNN: the latent state $X_i$ in the s...",
    "student": "Edward Zhang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450676"
    },
    "body_html": "In this chat I clarified how Kalman filters relate to RNNs and what each symbol means. I learned that a (linear) Kalman filter can be seen as a very special linear RNN: the latent state $X_i$ in the state--space model is like the true underlying process, the observation $Y_i$ corresponds to the RNN input $x_i$, and the Kalman estimate $\\hat X_{i \\mid i}$ (plus its variance) plays the role of the hidden state $h_i$. In RNN notation we usually don’t write an explicit $X_i$; instead, the hidden state is supposed to encode our best internal representation of that latent state. I also sorted out the “output” $y_i$: in Kalman terms I can think of $y_i$ as just a readout of the filter’s belief, e.g.\\ $y_i = \\hat X_{i \\mid i}$ or the predicted observation, and even though we write $y_i = g(h_i)$, it still depends on the current input $x_i$ indirectly through the update $h_i = f(h_{i-1}, x_i)$. Overall, I now see Kalman filtering as a model-based, optimal linear RNN for linear-Gaussian systems, while a generic RNN is a learned, more flexible version of a state estimator/filter.\n\n",
    "attachments": [
      {
        "name": "Special_Participation_E_2-merged.pdf",
        "url": "https://static.us.edusercontent.com/files/R1U0abSfRm4nYMaNEatesWQg"
      }
    ],
    "highlight": false,
    "summary": "In this chat I clarified how Kalman filters relate to RNNs and what each symbol means. I learned that a (linear) Kalman filter can be seen as a very special linear RNN: the latent state $X_i$ in the state--space model is like the true underlying process, the observation $Y_i$ corresponds to the RNN input $x_i$, and the Kalman estimate $\\hat X_{i \\mid i}$ (plus its variance) plays the role of the h"
  },
  {
    "id": "ed-7450650",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: ChatGPT as Exam Prep from Exam Problems",
    "dek": "Here, I fed ChatGPT my notes from the course, as well as every homework and discussion solution except Homework 12 (whose solutions are unposted). I additionally gave it the Homework 12 problems, and ...",
    "student": "Evan Davis",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450650",
      "chatgpt": "https://chatgpt.com/share/6939ddc2-f27c-800d-8b79-7f9a376b9416"
    },
    "body_html": "Here, I fed ChatGPT my notes from the course, as well as every homework and discussion solution except Homework 12 (whose solutions are unposted). I additionally gave it the Homework 12 problems, and the past midterms and finals from previous website versions that are available (Fall 2022, Spring 2023). I don't believe we have access to Spring 2025's final yet, so I couldn't feed it to ChatGPT.\n\nI then asked it to generate a practice exam with questions of varying difficulty. It then generated 18 practice questions, with 3 from each of 6 \"topics\", categorized into three levels of difficulty, one per level in each \"topic\". It additionally generated solutions for these questions. I then tested it on RLVR and Diffusion model questions, which it generated, alongside hints or solutions.\n\nTo exam-prep for a specific topic, feed the model this prompt: Give me a [Level 1; Level 2; Level 3] problem on [Topic]. Give me the problem, then a few gentle hints, and then a fully worked solution.\n\nI would generally recommend doing Level 1, then Level 2, then Level 3 for any particular topic you feel uncomfortable with.\n\nHere is a link to the chat: https://chatgpt.com/share/6939ddc2-f27c-800d-8b79-7f9a376b9416\n\nAnd here is the annotated chat:\n\nAll mistakes in my notes are my own. When using the chatbot, feel free to re-upload my notes (https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing), or upload your own, to address forgetting.\n\nI hope this was helpful. Happy studying!",
    "attachments": [
      {
        "name": "exam_prep.pdf",
        "url": "https://static.us.edusercontent.com/files/NYBjbnuX9WBXXeS7Dg3AQnGj"
      }
    ],
    "highlight": false,
    "summary": "Here, I fed ChatGPT my notes from the course, as well as every homework and discussion solution except Homework 12 (whose solutions are unposted). I additionally gave it the Homework 12 problems, and the past midterms and finals from previous website versions that are available (Fall 2022, Spring 2023). I don't believe we have access to Spring 2025's final yet, so I couldn't feed it to ChatGPT."
  },
  {
    "id": "ed-7450625",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Intuitively understand optimizer by Claude Sonnet 4.5",
    "dek": "I used Claude sonnet 4.5 as an interactive “pre/post-lecture reading” for Lecture 5 on optimizers (gradient descent, sign SGD, norm-based views, Shampoo, μP, and Muon). Instead of just asking it to su...",
    "student": "Shuwei Yang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450625"
    },
    "body_html": "I used Claude sonnet 4.5 as an interactive “pre/post-lecture reading” for Lecture 5 on optimizers (gradient descent, sign SGD, norm-based views, Shampoo, μP, and Muon). Instead of just asking it to summarize the slides, I treated Claude like a tutor I could program with prompts. I’ll attach the main prompts I used, plus a chunk of our conversation, so that other people can reuse or modify this setup if they want to self-study the same material.\n\nThe first thing I asked for was a “100-year-old grandma” version of the lecture. I told Claude to imagine it was explaining optimizers to a very smart but non-technical grandma, starting from the foggy-mountain picture of gradient descent, then moving to sign SGD, different norms as different ways of constraining steps, and finally how Shampoo and μP/Muon fit into that story. I emphasized slow pacing, friendly tone, lots of analogies (water pipes for Xavier, rubber sheets and trampolines for norms and spectral stuff), and as few formulas as possible until the intuition felt solid. I also uploaded the Lecture 5 slides and kept asking it to tie things back to specific pages and symbols, so it wouldn’t drift into some generic “optimizers 101” description. Along the way it kept quizzing me with small questions like “why might sign SGD be useful?” or “why does it make sense to throw away Σ?” which forced me to answer in my own words instead of just passively reading.\n\nEven with that, there was one part of the lecture I still found very confusing: the chain from Xavier initialization → RMS norm → spectral norm → Shampoo. So I wrote a second, more focused prompt that asked Claude to explain only this chain, step by step, as a narrative. I asked it to start from the practical problem Xavier is trying to solve (“keep each layer’s activations at a reasonable scale”), then explain why that naturally leads to thinking in terms of “typical size per parameter” and the RMS norm, then reinterpret weight matrices as stretchy rubber sheets to motivate the spectral norm, and finally connect that back to the constrained optimization problem whose solution looks like a Shampoo update. This second pass helped a lot: once it framed RMS as “average size of an entry” and spectral norm as “maximum stretching factor in those units,” the ΔW ≈ −ηUVᵀ picture suddenly felt much less mysterious.\n\nI also tried to be critical, as the instructions ask. In my annotations on the trace, I point out places where the model is more intuitive than rigorous. For example, when it connects RMS norms to induced matrix norms and spectral norms, it sometimes glosses over details with “≈”, which is fine for building intuition but shouldn’t be mistaken for a proof. Its explanation of μP and Muon stays at a high level: it talks about reusing hyperparameters across model scales and 10× speedups in NanoGPT-style experiments, but it doesn’t really go into implementation details or computational costs. It also occasionally ignored my request to delay equations and introduced formulas earlier than I would have liked if this were a polished pre-lecture handout. These are places where I think a human reader needs to be cautious and treat the model as a helper, not an authority.\n\nOverall, though, this felt like a reasonable example of what special participation E is aiming for: instead of reading the slides in a passive way, I used an AI tool to build a small, reusable learning artifact for one lecture, and then interacted with it in a way that made me articulate my own understanding and push back when things were unclear. If other students want to try something similar, they could reuse my prompts on a different topic (attention, diffusion, etc.), put the model into this “grandma mode” to get a soft first pass, and then write their own follow-up prompts for the one or two conceptual chains they still don’t understand, making the model re-explain those pieces until they can say them back in their own words.",
    "attachments": [
      {
        "name": "Special Participation E Intuitively review optimizer with Claude.pdf",
        "url": "https://static.us.edusercontent.com/files/8ju0HhzdeXhBURn36cVA2MVf"
      }
    ],
    "highlight": false,
    "summary": "I used Claude sonnet 4.5 as an interactive “pre/post-lecture reading” for Lecture 5 on optimizers (gradient descent, sign SGD, norm-based views, Shampoo, μP, and Muon). Instead of just asking it to summarize the slides, I treated Claude like a tutor I could program with prompts."
  },
  {
    "id": "ed-7450621",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Cheatsheet for Muon and MuP",
    "dek": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, ...",
    "student": "Shoumik Roychowdhury",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450621"
    },
    "body_html": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build individualized pre-lecture learning tools.\n\nI’m sharing the prompt, output artifacts, and annotated interaction trace so you can use them yourselves and also see both the strengths and the failure modes of LLM-assisted studying.\n\n\nNOTE:\n\nthe model occasionally implied citations (“as from class notes”) without pulling actual page numbers\n\n Some formulas were slightly rephrased—not incorrect, but not exactly matching lecture notation\n\nThe kernel attention explanation is correct conceptually, but slightly hand-wavey on the random feature approximation\n\nPrompt 1:\n“Generate a comprehensive, exam-ready cheatsheet for Berkeley EECS 182 (Fall 2025), focusing especially on: Muon and MuP optimization. The cheatsheet should prioritize mathematical clarity, include equations and derivations, use text diagrams, and be optimized for last-minute review.”\n\nPrompt2:\n\"ok now make cheat sheet for this \"\n\nPrompt3:\n\"provide the latex\"\n\nConclusion:\n\nUseful as a study tool, but not a replacement for primary sources (lecture slides, notes, HW derivations). You must still verify key formulas.\n\n\n\n\n\n\n",
    "attachments": [
      {
        "name": "Muon_and_MuP_Cheatsheet.pdf",
        "url": "https://static.us.edusercontent.com/files/GlF9Y36BODBbNG86zKSeKtHi"
      }
    ],
    "highlight": false,
    "summary": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build individualized pre-lecture learning tools."
  },
  {
    "id": "ed-7450587",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT as Topic-Specific Tutor for Entire Course",
    "dek": "Here, I fed ChatGPT my original notes (posted below) for the entire class and I had it generate a variety of summaries of the entire course, from a base summary of the content we covered, to a concept...",
    "student": "Evan Davis",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450587",
      "chatgpt": "https://chatgpt.com/share/6939cb36-cdfc-800d-81b8-ec5c559f1645"
    },
    "body_html": "Here, I fed ChatGPT my original notes (posted below) for the entire class and I had it generate a variety of summaries of the entire course, from a base summary of the content we covered, to a conceptual one, then a mathematical one, then a lecture-specific summary, and finally a mini-study guide. It was then in a state to serve as a topic-specific tutor for those struggling with any part of the class.\n\nIn the original summaries, it ignored muP, a topic we covered, so I tested out the following prompt on muP. After thinking for a while (\"re-reading\" my notes), it successfully generated a tutorial for me, so it should be good to go for general use. Here is the prompt I used:\n\nI am confused about [insert subject here], and do not have a very good understanding of it. I'd like you to go into more detail.\n\nTo do so, can you do the following for me on [subject]:\n\n(a) Explain it at a conceptual high-level, including motivation and loosely the gist of what it goes/accomplishes. Include the lecture notes I can reference from the notes you were given.\n(b) Go into the math in detail. Remain somewhat accessible, but be rigorous.\n(c) Summarize the math and concepts in a \"study sheet\" format.\n(d) Create a practice problem, and then walk me through the solution.\n(e) Create 3 more practice problems, and prepare hints and solutions for each.\n\nHere is a link to the chat: https://chatgpt.com/share/6939cb36-cdfc-800d-81b8-ec5c559f1645\n\nAnd annotated chat attached below:\n\nAll mistakes in my notes are my own. When using the chatbot, feel free to re-upload my notes (https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing), or upload your own, to address forgetting.\n\nI hope this was helpful. Happy studying!",
    "attachments": [
      {
        "name": "study_guide.pdf",
        "url": "https://static.us.edusercontent.com/files/gqXUYD62SJ39Z0e7KsPCS4EW"
      }
    ],
    "highlight": false,
    "summary": "Here, I fed ChatGPT my original notes (posted below) for the entire class and I had it generate a variety of summaries of the entire course, from a base summary of the content we covered, to a conceptual one, then a mathematical one, then a lecture-specific summary, and finally a mini-study guide."
  },
  {
    "id": "ed-7450577",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Warmup Worksheet for HW 1",
    "dek": "I fed ChatGPT HW0 (pre-requisites), HW 1, and Discussion 1 and asked it to make a worksheet in the form of a homework to make me ready to do the homework. The warm-up worksheet included topic reviews ...",
    "student": "Neel Kolhe",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450577"
    },
    "body_html": "I fed ChatGPT HW0 (pre-requisites), HW 1, and Discussion 1 and asked it to make a worksheet in the form of a homework to make me ready to do the homework. The warm-up worksheet included topic reviews and problems, to make me ready to solve the homework fully alone. I have added my trace here and the worksheets ChatGPT created - it has all necessary material and was quite detailed. ",
    "attachments": [
      {
        "name": "Homework 1 warm-up.pdf",
        "url": "https://static.us.edusercontent.com/files/UAQ93kJZr7f63KAZyPRSUdp3"
      },
      {
        "name": "hw1warmupsoln.pdf",
        "url": "https://static.us.edusercontent.com/files/2SSg5IwBnw4TrQlevdO4jpWQ"
      },
      {
        "name": "hw1warmup.pdf",
        "url": "https://static.us.edusercontent.com/files/ZywOjEGyFsLGBYclAlB5jtbH"
      }
    ],
    "highlight": false,
    "summary": "I fed ChatGPT HW0 (pre-requisites), HW 1, and Discussion 1 and asked it to make a worksheet in the form of a homework to make me ready to do the homework. The warm-up worksheet included topic reviews and problems, to make me ready to solve the homework fully alone. I have added my trace here and the worksheets ChatGPT created - it has all necessary material and was quite detailed."
  },
  {
    "id": "ed-7450486",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Review Session Warmup Worksheet",
    "dek": "Going into the review sessions today, I was a little worried that I would have forgotten all the information from earlier in the semester. When I tried reading through the lecture notes, it was much h...",
    "student": "Rohan Gopalam",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450486"
    },
    "body_html": "Going into the review sessions today, I was a little worried that I would have forgotten all the information from earlier in the semester. When I tried reading through the lecture notes, it was much harder to follow without watching the corresponding lecture. However, watching all the lectures would also take a long time and be a waste of time since I already knew a lot of the information and just needed a refresher. Instead, I used Gemini to look through all the lectures corresponding to each review session and also the corresponding questions and give me a quick 10 minute warmup worksheet I could read and work through before each session. Below is the prompt I used and the review worksheet for the optimizers review session. With the prompt I also added the lecture pdfs and screenshots of the homework questions as attachments.\n\nPrompt: I am getting ready for a review session for my deep learning class. I want to make sure I am prepared going in to the session. I want you to generate me a quick (~10min) worksheet that has key information I will need for that review session and also short warmup questions. However, make sure that the questions are not too similar to the questions being reviewed in the session itself so I can still learn from that and be challenged. Here are the lecture pdfs and the questions the teacher will be going over in the review session.\n\n\n\n\n\n\n\n\n",
    "attachments": [
      {
        "name": "Special Participation E 2.pdf",
        "url": "https://static.us.edusercontent.com/files/wcWJSzLBdALYMGYBK6vXPpV6"
      }
    ],
    "highlight": false,
    "summary": "Going into the review sessions today, I was a little worried that I would have forgotten all the information from earlier in the semester. When I tried reading through the lecture notes, it was much harder to follow without watching the corresponding lecture."
  },
  {
    "id": "ed-7450269",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Participation E: understand the mathematical foundations of optimizers, bias correction, gradient normalization, linearization perspective, and proper weight initialization using fan-in/fan-out",
    "dek": "https://chatgpt.com/share/693a1d53-9ae8-8006-bad9-24c12393a612\n\nThrough the discussion, I gained a clear understanding of how modern optimization algorithms like Adam and sign-SGD work from both pract...",
    "student": "Menger Wen",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450269",
      "chatgpt": "https://chatgpt.com/share/693a1d53-9ae8-8006-bad9-24c12393a612"
    },
    "body_html": "https://chatgpt.com/share/693a1d53-9ae8-8006-bad9-24c12393a612\n\nThrough the discussion, I gained a clear understanding of how modern optimization algorithms like Adam and sign-SGD work from both practical and mathematical perspectives, including bias correction and the differences between weight decay and $L_2$ regularization. I learned how linearization and Taylor expansion help explain neural network training dynamics, leading to the concept of Neural Tangent Kernel (NTK) and lazy training. I also explored gradient norm normalization, ℓ∞ constraints leading to sign-SGD, and ℓ2 constraints producing conventional gradient descent directions. Finally, I uncovered why appropriate initialization schemes such as Xavier and He help stabilize neural network training by controlling variance propagation, and what fan-in and fan-out mean in that context.\n\nThe built-in prompt (translated from Chinese) I used is showed below:\n\n\n\nYou are a patient deep learning expert and teaching assistant for UC Berkeley CS 182, focusing on Lectures 3 and 4. Your learner is a beginner in linear algebra, machine learning, and optimization, but very motivated and willing to go step by step. They are currently trying to deeply understand:\n\nGradient descent and its variants (SGD, momentum, normalized gradients, sign-SGD, Adam, AdamW, bias correction, weight decay vs L2 regularization)\n\nThe Taylor / linearization perspective on neural networks, including: first-order Taylor expansion in parameter space, gradient flow, how we get the Neural Tangent Kernel (NTK) expression, and the “lazy training” assumption\n\nInitialization schemes: Xavier / Glorot and He / Kaiming initialization, how variance propagates through layers, and the meaning of fan-in and fan-out\n\nPlease teach me these topics as if I’m preparing for CS 182 homework and exams, with the following constraints and style:\n\nAssume I’m a beginner\n\nUse very clear, simple language and avoid heavy jargon.\n\nWhen you must use a technical term (e.g., “gradient flow”, “NTK”), define it carefully and give an intuitive analogy.\n\nBuild up from first principles\n\nStart from basic gradient descent on a scalar parameter and connect it to the vector case.\n\nFor Adam and AdamW, explicitly derive the update equations step by step, including: \n\nhow ($m_t$) and ($v_t$) are moving averages of gradients/gradient squares,\n\nhow bias correction is derived (( $\\hat m_t = m_t / (1-\\beta^t)$), ( $\\hat v_t = v_t / (1-\\beta^t)$)),\n\nwhy “L2 in the loss” is not equivalent to weight decay for adaptive methods, and what AdamW actually changes.\n\nFor the Taylor/NTK part, show how we linearize ($f(x,\\theta)$) around ($\\theta_0$), use gradient flow ($d\\theta/dt = -\\nabla_\\theta \\mathcal L$), and derive $$ \\frac{d}{dt} f(x,\\theta(t)) = -\\frac{1}{N}\\sum_i K(x,x^{(i)}) \\nabla_f \\ell(f(x^{(i)},\\theta(t)), y^{(i)}), $$ where ($K$) is the neural tangent kernel.\n\nFor initialization, derive why summing ($d$) independent terms ($\\sum_i w_i h_i$) gives variance ($d \\cdot \\mathrm{Var}(w) \\cdot \\mathrm{Var}(h)$), and how this leads to \n\nXavier: ($\\mathrm{Var}(w) = 1/\\text{fan_in}$) (or the Glorot fan-in/fan-out variant),\n\nHe: ($\\mathrm{Var}(w) = 2/\\text{fan_in}$) for ReLU, because ReLU roughly halves the variance.\n\nExplain fan-in / fan-out clearly\n\nGive concrete examples for fully connected layers and convolutional layers.\n\nUse a plumbing / pipes analogy (number of incoming vs outgoing connections) to help my intuition.\n\nUse worked examples and micro-exercises\n\nFrequently give small numerical examples (e.g., a neuron with 3 inputs and specific values) and walk through the computations.\n\nAfter explaining a concept, give me 1–3 short practice questions (with answers) so I can check my understanding.\n\nStart with very easy questions and gradually make them more “CS 182 exam style”.\n\nConnect formulas to intuition\n\nFor each major formula, answer: \n\nWhat is this trying to achieve?\n\nWhat would go wrong if we didn’t do this?\n\nHow does this relate to exploding/vanishing gradients, optimization speed, or generalization?\n\nStructure the teaching into modules\n\nModule 1: Recap of gradient descent, SGD, and momentum.\n\nModule 2: Normalized gradients and sign-SGD from an optimization-under-constraints viewpoint (ℓ∞ vs ℓ2 constraints).\n\nModule 3: Adam and AdamW — equations, bias correction, and weight decay vs L2.\n\nModule 4: Taylor expansion, linearized models, gradient flow, and NTK.\n\nModule 5: Initialization (Xavier/Glorot, He/Kaiming), variance propagation, fan-in/fan-out.\n\nIn each module, first give an overview, then details with derivations, then a short summary and a few practice questions.\n\nCheck my understanding interactively\n\nAfter explaining each subtopic, ask me a quick question (conceptual or computational) and wait for my answer.\n\nIf my answer is wrong or partially correct, correct me gently and explain where my reasoning went off.\n\nBe honest about uncertainty and avoid hallucinations\n\nIf I ask about something that is outside typical CS 182 / deep learning theory (e.g., very specific implementation quirks in a library), say that you’re not sure rather than guessing.\n\nPrefer standard, widely-accepted explanations that would agree with common deep learning textbooks and lecture notes.\n\nStart now with Module 1, briefly recalling vanilla gradient descent, and then build up toward sign-SGD, Adam/AdamW, the Taylor/NTK perspective, and initialization in a way that feels like a structured mini-course.",
    "attachments": [],
    "highlight": false,
    "summary": "Through the discussion, I gained a clear understanding of how modern optimization algorithms like Adam and sign-SGD work from both practical and mathematical perspectives, including bias correction and the differences between weight decay and $L_2$ regularization."
  },
  {
    "id": "ed-7450199",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Teacher Forcing, Weight Decay, and Low-Rank Factorization",
    "dek": "As I worked through this problem, I clarified several concepts: I now understand teacher forcing as feeding the ground-truth previous token into the decoder, and why the per-step loss is written as $-...",
    "student": "Edward Zhang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450199"
    },
    "body_html": "As I worked through this problem, I clarified several concepts: I now understand teacher forcing as feeding the ground-truth previous token into the decoder, and why the per-step loss is written as $-\\log p_{\\theta}(y_t \\mid h_t)$ even though the gradient still flows back through $h_{t-1}, y_{t-1}, \\dots$ via BPTT. I also connected weight decay to adding an $\\ell_2$ penalty and saw how, in this low-rank factorization setting, regularizing $\\lVert W_1 \\rVert_F^2 + \\lVert W_2 \\rVert_F^2$ induces a preference for factorizations where $W_2 W_1$ is an identity on the top-$k$ subspace and the singular values of $W_1$ and $W_2$ pair as $\\sigma_i$ and $1/\\sigma_i$, leading to approximately orthonormal columns. My questioning style was very step-by-step and “why-focused”: I kept asking for unpacking of specific sentences, challenging hidden assumptions (like aligning $V_1$ and $U_2$), and requesting intuitive explanations of each algebraic step rather than just accepting the final formula.",
    "attachments": [
      {
        "name": "Special_Participation_E-merged.pdf",
        "url": "https://static.us.edusercontent.com/files/XnmIgPrdpsAoL91wPbokqs6h"
      }
    ],
    "highlight": false,
    "summary": "As I worked through this problem, I clarified several concepts: I now understand teacher forcing as feeding the ground-truth previous token into the decoder, and why the per-step loss is written as $-\\log p_{\\theta}(y_t \\mid h_t)$ even though the gradient still flows back through $h_{t-1}, y_{t-1}, \\dots$ via BPTT."
  },
  {
    "id": "ed-7450107",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Using Claude to Generate New Homework-Based Problems For Diffusion",
    "dek": "\n\nAfter completing homework 13 for diffusion, I found myself still a little confused on the math used to solve the problems, and wanted to get similar problems to the homework that I could use to prac...",
    "student": "E Harrison",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7450107"
    },
    "body_html": "\n\nAfter completing homework 13 for diffusion, I found myself still a little confused on the math used to solve the problems, and wanted to get similar problems to the homework that I could use to practice. To do this, I gave Claude's Sonnet 4.5 model a PDF of homework 13's problems and solutions and asked it to generate a new problem similar to the ones provided.\n\nFirst, I found the question Claude came up with to be quite interesting. It asked me to consider a variance-preserving form of diffusion, and eventually compare my reverse denoising process to the solution from Question 1 of HW13. I thought the problem itself was quite interesting, and could reasonably see something like this be asked for on an exam. \n\nPart (a) was straightforward, but in part (b) I made a little mistake on the variance, assuming it stayed at 1 rather than being t. Claude was able to catch me on this, and hinted that because X_0 is being conditioned on, we do not combine (1-t) and t for the variance, so it stays at t.\n\nPart (c) took a lot more time to get right for me, and even now I'm not too sure how correct Claude was even on its own problem. I got that the forward process from X_t to X_{t + delta t} had a mean of x_t and variance of delta t. It seemed like thats what Claude believed the answer to be, but I'm not so confident this is the case.\n\nFor part (d), Claude gave a small hint indicating that it would be similar to solving question 4(b) from the homework. While it was a lot of algebra, the problem itself wasn't too difficult. I made a minor mistake at the end, multiplying rather than dividing by my leading coefficient to find the mean, and Claude was able to catch it. One suspect thing it did however was try to fix the leading 2 coefficient I initially had in my problem by multiplying my solution by a factor of 1/2. It says that I should do this because I had a 1/2 in the leading part of my exponential, but I don't think that makes too much sense.\n\nPart (e) was straightforward, but Claude made the interesting observation that for the variance-preserving process, the variance throughout stays the same but the mean shifts, where for the variance-increasing process the mean shrinks.\n\nBelow is a link to the full conversation with Claude:\nhttps://claude.ai/share/df5da7d5-5538-494e-b95d-4631a2c22e49\n\nFor some reason Claude hides any images attached to the conversation, so here are the images provided, in the same order as when I gave them to Claude:\n\n\nPart (a):\n\n\nPart (b) attempt 1:\n\n\n\nPart (b) attempt 2:\n\n\nPart (c) attempt 1:\n\nPart (c) attempt 2:\n\nPart (c) attempt 3:\n\nPart (d):",
    "attachments": [],
    "highlight": false,
    "summary": "After completing homework 13 for diffusion, I found myself still a little confused on the math used to solve the problems, and wanted to get similar problems to the homework that I could use to practice. To do this, I gave Claude's Sonnet 4.5 model a PDF of homework 13's problems and solutions and asked it to generate a new problem similar to the ones provided."
  },
  {
    "id": "ed-7449784",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E - Gemini Pro 3 on State Space Models (Using lecture notes as ground truth)",
    "dek": "I used Gemini pro 3 to walk me through the training and inference of state space models. I used lecture notes to compare its external knowledge with and then I used itself to check whether there were ...",
    "student": "Shervin Goudarzi",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7449784"
    },
    "body_html": "I used Gemini pro 3 to walk me through the training and inference of state space models. I used lecture notes to compare its external knowledge with and then I used itself to check whether there were any hallucinations within the model itself. Enjoy :)  ",
    "attachments": [
      {
        "name": "SSM-Gemini.pdf",
        "url": "https://static.us.edusercontent.com/files/pTrIcckjhzkeqb97aubGKGFd"
      }
    ],
    "highlight": false,
    "summary": "I used Gemini pro 3 to walk me through the training and inference of state space models. I used lecture notes to compare its external knowledge with and then I used itself to check whether there were any hallucinations within the model itself. Enjoy :)"
  },
  {
    "id": "ed-7449696",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E - Comparing Optimizers and MuP (testing intuition and summary table)",
    "dek": "Executive Summary\n\nI used ChatGPT 5.0 \"Study Mode\" to interactively test my understanding of different optimizers and summarize. This was not the first time I've interacted with ChatGPT 5.0's \"Study M...",
    "student": "Iana Lin",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7449696",
      "chatgpt": "https://chatgpt.com/share/693a0825-c1ac-8003-ac28-49cb54fa75ed"
    },
    "body_html": "Executive Summary\n\nI used ChatGPT 5.0 \"Study Mode\" to interactively test my understanding of different optimizers and summarize. This was not the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" but I felt it was very helpful. In particular, I wanted to see how it would perform on Muon since it is a relatively new optimizer.\n\nIt also cited many sources to relevant papers, so I include the link to the chat here.\nhttps://chatgpt.com/share/693a0825-c1ac-8003-ac28-49cb54fa75ed\n\n",
    "attachments": [
      {
        "name": "SpecialParticipationE.pdf",
        "url": "https://static.us.edusercontent.com/files/4vqa5DXzFojLDhh5i9MitVrT"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT 5.0 \"Study Mode\" to interactively test my understanding of different optimizers and summarize. This was not the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" but I felt it was very helpful. In particular, I wanted to see how it would perform on Muon since it is a relatively new optimizer."
  },
  {
    "id": "ed-7449666",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT study mode as Vector Calculus tutor",
    "dek": "I used ChatGPT Pro Study mode to teach me about vector calculus in an interactive manner, starting from the basics like gradients vs jacobians, then working towards more Deep Learning related examples...",
    "student": "Andy Peng",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7449666"
    },
    "body_html": "I used ChatGPT Pro Study mode to teach me about vector calculus in an interactive manner, starting from the basics like gradients vs jacobians, then working towards more Deep Learning related examples like calculating the gradient for log softmax, and a full 2 layer MLP. I also chose to emphasize coding examples in numpy, similar to what we saw on the homework. So one example is:\nForward\n\nSamples:\n\nW1 shape (hidden_dim, input_dim)\n\nW2 shape (num_classes, hidden_dim)\n\nx shape (input_dim,)\n\nlabel y\n\nComputes:\n\nu = W1 @ x\n\nh = relu(u)\n\nz = W2 @ h\n\np = softmax(z)\n\nL = -log(p[y])\n\nBackward\n\nCompute the gradients:\n\ndLdz\n\ndLdW2\n\ndLdh\n\ndLdu\n\ndLdW1\n\ndLdx\n\nOverall it was very helpful and I liked the pacing and direction the interactive tutoring session went. The few downsides I noticed is that \n- at the start, it would ask me to compute a numerical gradient using something like Newton's method which I thought was unnecessary. But once I told it that we can skip those questions it didn't ask it again\n- sometimes the questions it asks are a bit repetitive\n\nI did notice that sometimes I tried to give a handwavey answer but it pushed back better than I expected and gave a more in depth summary when it was clear I was unsure of my answer, which I think is really good. I used another ChatGPT session to help me create the prompt, and I emphasized that I want to go more in depth with this study session compared to the other study session I made for SSMs. Overall I'm quite happy with the results.\n\nHere is the prompt I used:\nYou are my tutor for vector calculus for deep learning, covering differentiation of vectors and matrices, Jacobians, gradients, Hessians, chain rule for deep nets, and practical backpropagation. I also want hands-on NumPy coding exercises to help build intuition and skill. This should be an interactive tutoring session. In every reply: • Keep responses focused and reasonably short (3–6 paragraphs). • Adapt dynamically to my understanding: if I misunderstand, briefly clarify and ask a grounding question; if I answer well, increase difficulty. • Always end with a specific question or a small task I must answer before you continue. • Include at least one short NumPy coding exercise every 2–3 messages. • Do not move on to the next topic until I say so. ⸻ Overall Story I Want to Learn Teach vector calculus as used in modern deep learning workflows, following this outline unless I say otherwise: 1. Big-picture motivation • Why DL requires vector calculus: gradients, Jacobians, chain rule, backprop. • Scalar → vector → matrix differentiation as a natural progression. 2. Core objects • Gradients, Jacobians, Hessians. • Shapes and dimensions intuition (e.g., gradient is same shape as input). • Inner products and directional derivatives. 3. Differentiation rules in vector form • Chain rule for vector functions. • Product rules for matrix–vector expressions. • Common derivatives used in neural nets (ReLU, softmax, linear layers, norms). 4. Backpropagation through computations • Computational graph view. • Local Jacobians and how they compose. • Examples from linear layers, activations, softmax cross-entropy. 5. Practical NumPy differentiation • Implementing gradients from scratch for simple functions. • Numerical gradient checking. • Mini backprop through a 2-layer MLP. 6. Connecting to deep learning practice • Why PyTorch/JAX autodiff works. • Relationship between Jacobian-vector products and reverse-mode AD. • Efficiency considerations. ⸻ Step 1: First Response Instructions Your first response should include: 1. A two-paragraph big-picture introduction, explaining: • Why DL optimization is impossible without vector calculus. • How gradients in high dimensions behave and why shapes/Jacobians matter. • Why backprop is essentially repeated applications of the vector chain rule. 2. A short roadmap (5–7 bullets) drawn from the “Overall Story” above. 3. End with one short concept-check question, such as: “What is the difference between a gradient and a Jacobian?” Wait for my answer before continuing. ⸻ Step 2: Teaching Each Topic For each topic in the roadmap, use a four-layer structure: 1. Intuition Explain the idea in clear language: geometric meaning, shapes, why it’s needed for DL (optimization, backprop, stability). 2. Key Formal Setup Introduce minimal notation: • Vector functions f: \\mathbb{R}^n \\to \\mathbb{R} or g: \\mathbb{R}^n \\to \\mathbb{R}^m. • Jacobian shapes. • Example derivatives (e.g., Ax, norms, nonlinearities). Keep formulas short and tied to intuition. 3. Tiny Example Provide a tiny numeric or symbolic example, plus a NumPy mini-exercise every 2–3 messages. Exercises should be short (5–10 lines max), such as: • Compute numerical gradients by finite differences. • Verify the gradient of f(x)=x^T A x. • Backprop through a 1-layer network. • Implement Jacobian-vector products manually. 4. Understanding Check Ask me 1–2 questions: one conceptual, optionally one computational. Then stop and wait for my answer. Only continue when I confirm I’m ready for the next topic. ⸻ Step 3: Final Wrap-Up When I say I’m ready for review, give a compact summary covering: • How vector calculus underlies gradients, Jacobians, backprop. • How NumPy exercises connect to the math. • Why modern autodiff frameworks are efficient implementations of the same principles. • A final list of “the 10 most important derivative patterns in deep learning.” ⸻ Begin Now Start with Step 1: Provide the two-paragraph big-picture introduction, the roadmap, and a final concept-check question.\n\nHere is the logs (I was running out of time so I ended it early): ",
    "attachments": [
      {
        "name": "Vector calculus in DL.pdf",
        "url": "https://static.us.edusercontent.com/files/NdItdpdNGuUdaEDUBUg18mgu"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT Pro Study mode to teach me about vector calculus in an interactive manner, starting from the basics like gradients vs jacobians, then working towards more Deep Learning related examples like calculating the gradient for log softmax, and a full 2 layer MLP. I also chose to emphasize coding examples in numpy, similar to what we saw on the homework."
  },
  {
    "id": "ed-7449591",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Dialogue with ChatGPT to understand topics for review sessions 12/10",
    "dek": "I made a tool to summarize/go over the topics before today's afternoon review sessions. This tool was meant to prep me so I wouldn't be behind and would have my memory refreshed before the problems.\n\n...",
    "student": "Neel Kolhe",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7449591"
    },
    "body_html": "I made a tool to summarize/go over the topics before today's afternoon review sessions. This tool was meant to prep me so I wouldn't be behind and would have my memory refreshed before the problems.\n\n\n\n\n\nSummary: This tool was fairly accurate in its descriptions. Going through Sultan’s discussion right now, the topics were explained clearly enough for me to understand. I also intentionally gave it a wrong answer in my answers to its’ generated questions, and it pointed it out to me, which was nice. \n\n",
    "attachments": [
      {
        "name": "Transformer review and quiz.pdf",
        "url": "https://static.us.edusercontent.com/files/kde7iHb4ppoBEtDpbYWTA0ed"
      }
    ],
    "highlight": false,
    "summary": "I made a tool to summarize/go over the topics before today's afternoon review sessions. This tool was meant to prep me so I wouldn't be behind and would have my memory refreshed before the problems."
  },
  {
    "id": "ed-7449210",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Understand how SVD basis shows both ridge and SGD implicitly suppress noise, leading to stable convergence to the minimal-norm solution. (Lec 2&3)",
    "dek": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nhttps://chatgpt.com/share/6939f6a6-f1ec-8006-8ecb-626caf703cd0\n\nThrough the conversation, I’ve gained...",
    "student": "Menger Wen",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7449210",
      "chatgpt": "https://chatgpt.com/share/6939f6a6-f1ec-8006-8ecb-626caf703cd0"
    },
    "body_html": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nhttps://chatgpt.com/share/6939f6a6-f1ec-8006-8ecb-626caf703cd0\n\nThrough the conversation, I’ve gained a deeper understanding of how SVD (singular value decomposition) provides a natural coordinate system for analyzing linear regression and gradient descent / SGD. In that coordinate system, I saw clearly how “large-singular-value directions” correspond to strong signal (high-variance / well-supported directions) while “small-singular-value directions” correspond to weak signal or noise. I also saw how both explicit regularization (ridge / weight decay) and implicit regularization (SGD with early stopping) effectively suppress those weak/noisy directions — from both the closed-form ridge solution and the SGD convergence analysis (via a Lyapunov / contraction argument) you walked through step by step. Ultimately, I learned why and how switching to the singular-vector basis makes the behavior of these algorithms transparent, and how that explains phenomena like stability, generalization, and convergence to the minimal-norm solution in underdetermined systems.\n\n\n\n\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "Through the conversation, I’ve gained a deeper understanding of how SVD (singular value decomposition) provides a natural coordinate system for analyzing linear regression and gradient descent / SGD."
  },
  {
    "id": "ed-7448951",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Diffusion Tutor using Claude Sonnet 4.5 (LLM As a Judge)",
    "dek": "One thing I struggled with in the learning process of Diffusion was grasping the \"full story\" or narrative of the process, finding myself stuck with solving the probability unaware of how it fit into ...",
    "student": "Akshaan Ahuja",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7448951"
    },
    "body_html": "One thing I struggled with in the learning process of Diffusion was grasping the \"full story\" or narrative of the process, finding myself stuck with solving the probability unaware of how it fit into the larger picture or purpose of diffusion models. To aid in this, I created a prompt to turn Claude Sonnet 4.5 into an interactive tutor for the larger picture of Diffusion, painting in the necessary math and probability where it belongs but always relating the calculations back to the overall ethos of diffusion. \n\nOn top of this, I wanted to know how the theory we are learning fits into the modern practices of large scale Diffusion models (ie. how they are trained, where the datasets are acquired/how they are generated, where the compute comes from, what the history of the architecture is, where the modern architectures came from) so I included a part of the prompt to relate this \"narrative explanation\" to the modern processes in Diffusion. \n\nHere is the prompt: \n\n\nYou are my interactive tutor for diffusion models. Your job is to build one continuous narrative that explains both the classical DDPM math (like in the screenshot above) and the modern large-scale systems (e.g., Stable Diffusion, EDM, DiT-based models).\n\nIn every message:\n\nKeep explanations concise (3–6 short paragraphs).\n\nUse small visual/diagrammatic descriptions (ASCII sketches) whenever helpful.\n\nNever move on until I explicitly say so.\n\nEnd every message with a short, concrete question that checks my understanding.\n\nDo not skip any steps — I want this to feel like a guided walkthrough, not a lecture dump.\n\nThe narrative arc you must follow (in order)\n\nBig-picture: what diffusion is really doing\n\nExplain how the forward process destroys information, the reverse process rebuilds it, and how the training objective learns the score function ∇ₓ log p(xₜ). Tie this explicitly to the formula:\n\nq(xₜ|xₜ₋₁) = Normal(√(1–βₜ) xₜ₋₁, βₜ I)\n\nthe closed-form anytime sampling distribution q(xₜ|x₀)\n\nhow xₜ becomes nearly Gaussian as t→∞.\n\n“Anytime sampling” and the magic of closed-form Gaussians\n\nExplain why q(xₜ|x₀) ends up Gaussian, and why this lets us jump to arbitrary noise levels without simulating each step. Include a small visual (e.g., signal/noise decomposition).\n\nReverse diffusion = score estimation\n\nExplain the Bayes-rule derivation of q(xₜ₋₁|xₜ, x₀). Then explain how we replace the unknown x₀ with a learned εθ or vθ. Explain why learning noise is easier than learning x₀.\n\nThe training loss and why it’s secretly a score-matching loss\n\nExplain L_simple, why it works, and what the model is actually learning. Introduce the notion of the score network and how the U-Net architecture is adapted for multi-scale denoising.\n\nLarge-scale training\n\nExplain how modern diffusion models are trained:\n\nhuge dataset (LAION, JFT, history of ImageNet)\n\nrandom t sampling\n\nnoise-conditioning embeddings\n\nCLIP text-conditioning\n\nclassifier-free guidance (why it works mathematically!)\n\ntraining compute patterns (cost ∝ number of steps × image size × dataset size)\n\nModern architectures and samplers\n\nExplain:\n\nWhy U-Nets were used first\n\nWhy DiTs (transformers in pixel space) now outperform them\n\nSamplers: DDIM, Euler, DPM-Solver, consistency distillation, 1-step vs. 2-step models.\n\nWrap it all up\n\nSummarize how all these pieces connect.\n\nEach section should follow this format\n\nIntuition - Explain the idea simply but precisely. Tie it back to the core story: “destroy → learn score → reconstruct.”\n\nMinimal math\n\nIntroduce only the symbols needed — x₀, xₜ, βₜ, ᾱₜ, εθ, vθ — not everything.\n\nTiny conceptual example\n\nFor example, noise a 1D number or a 2×2 image and describe what happens.\n\nConcept check\n\nAsk me 1–2 questions.\n\nFirst message instructions:\n\nYour first response should include:\n\nA 2-paragraph high-level explanation of diffusion in plain language.\n\nA 5–7 bullet-point roadmap of the topics you will teach (as listed above).\n\nA concept-check question.\n\n\nI have included a log of my conversation with Claude, as well as asked GPT 5.1 to rate Sonnet's response to the prompt above and point out some strengths and weaknesses of it, hitting on the \"LLM as a judge\" approach. This is where we use LLM B to score/rate/review the output of LLM A. \n\nAs you can see in the chat log below, the model is able to correctly identify when I get a conceptual question correct, when I am close in my answer/nearing the correct understanding, or when I am far off from the correct answer. It does a good job of varying binary \"yes\"/\"no\" questions with open-ended questions that force me to use my mathematical intuition. \n\nHere is ChatGPT 5.1's concise analysis on the performance of Sonnet 4.5 as a Diffusion Tutor:\n\nStrengths\n\n1. Strong adherence to the requested narrative structure\n\nThe tutor followed the designed roadmap exactly—starting with forward diffusion, moving into anytime sampling, reverse diffusion, training objectives, large-scale training, architectures, and samplers. It never jumped ahead or skipped prerequisites, which helped maintain a coherent, cumulative explanation.\n\n2. Clear explanations with layered intuition, math, and examples\n\nEach concept was broken down into approachable intuition (“destroy → learn score → reconstruct”), followed by minimal formalism, followed by a concrete toy example. This layering made mathematically heavy ideas—like variance preservation or Bayes-rule conditioning—much easier to internalize.\n\n3. Effective handling of misunderstandings\n\nWhen your answers were partially incorrect (e.g., believing x̂₀ would equal x₀ at high noise), the tutor corrected the reasoning cleanly and with strong explanatory context. These corrections were both accurate and pedagogically helpful.\n\n4. Consistent concept checks promoting active engagement\n\nAfter nearly every section, the tutor posed a targeted question that reinforced the newly introduced idea. These questions were well-aligned with the preceding material and encouraged you to articulate your understanding rather than passively consume content.\n\n5. Successful integration of modern diffusion systems\n\nBeyond the classical DDPM derivations, the tutor gave accurate, high-level descriptions of real production systems—LAION datasets, CLIP conditioning, classifier-free guidance, transformer-based DiTs, and accelerated samplers. This kept the tutorial grounded in how diffusion models are used today.\n\nWeaknesses\n\n1. Occasional verbosity\n\nWhile explanations were clear, some responses exceeded the intended length and revisited multiple concepts at once. This made certain sections denser than necessary for an “interactive tutoring” style.\n\n2. Repetition in concept checks\n\nSome questions asked similar things in different words—especially around why all timesteps must be trained, why variance preservation matters, or what happens at high noise levels. This slightly reduced novelty as the session continued.\n\n3. Numerically hand-wavy examples\n\nIn places where numeric intuition was provided (e.g., approximate values of ᾱₜ or signal-to-noise ratios), the numbers were not derived explicitly. While directionally correct, these examples could be mistaken for precise calculations.\n\n4. Limited depth in evaluating your answers\n\nThe tutor accepted most responses as correct even when they were vague, and only intervened on clearly incorrect statements. It did not probe deeper into partial answers or ask follow-up clarification questions to assess mastery.\n\n5. Some modern-systems explanations simplified subtle technical details\n\nDescriptions of classifier-free guidance scaling, DiT advantages, and compute cost were technically accurate but abstracted away important nuances. This makes the content accessible, but less rigorous for students seeking deeper technical grounding.\n\n",
    "attachments": [
      {
        "name": "Claude-Interactive diffusion models tutorial.pdf",
        "url": "https://static.us.edusercontent.com/files/ahLxFNUNud5gcqhUQVHsfnGg"
      }
    ],
    "highlight": false,
    "summary": "One thing I struggled with in the learning process of Diffusion was grasping the \"full story\" or narrative of the process, finding myself stuck with solving the probability unaware of how it fit into the larger picture or purpose of diffusion models. To aid in this, I created a prompt to turn Claude Sonnet 4."
  },
  {
    "id": "ed-7448909",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Practice Problem Generator w/ Backprop examples",
    "dek": "I built a reusable system prompt that generates high-quality practice problems with full solutions on any (182) topic. I tested it on backprop since that's what I'm currently reviewing and it generate...",
    "student": "Eric Wang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7448909"
    },
    "body_html": "I built a reusable system prompt that generates high-quality practice problems with full solutions on any (182) topic. I tested it on backprop since that's what I'm currently reviewing and it generated 6 problems ranging from basic chain rule to tricky shared-parameter cases (like what happens in RNNs). The real value is that this prompt is completely customizable. \n\nI've also annotated each generated problem pointing out what's good, what's misleading, and what's missing. The attached document includes the full system prompt so you can generate your own problem sets for finals prep. \n\n",
    "attachments": [
      {
        "name": "Practice_Problem_Generator.pdf",
        "url": "https://static.us.edusercontent.com/files/7QnxzzE1aQfZonSjTw1nbhws"
      }
    ],
    "highlight": false,
    "summary": "I built a reusable system prompt that generates high-quality practice problems with full solutions on any (182) topic. I tested it on backprop since that's what I'm currently reviewing and it generated 6 problems ranging from basic chain rule to tricky shared-parameter cases (like what happens in RNNs). The real value is that this prompt is completely customizable."
  },
  {
    "id": "ed-7448711",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Socratic Dialogue with Claude to deepen Transformers understanding",
    "dek": "I chose Transformers because they're absolutely central to modern deep learning. I used Claude's learning mode to walk through the attention mechanism from first principles, asking questions that forc...",
    "student": "Eric Wang",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7448711"
    },
    "body_html": "I chose Transformers because they're absolutely central to modern deep learning. I used Claude's learning mode to walk through the attention mechanism from first principles, asking questions that forced me to reason about design choices rather than just memorize formulas. What surprised me most was how many concepts I thought I knew (like \"why do we need separate Q, K, and V?\") turned out to be fuzzy when I actually tried to explain them. This Socratic approach revealed the difference between surface-level familiarity and genuine understanding, which is exactly what I need going into the final exam.",
    "attachments": [
      {
        "name": "Transformers Socratic.pdf",
        "url": "https://static.us.edusercontent.com/files/CyhxTQnS7xriQPzUUAfd9PXL"
      }
    ],
    "highlight": false,
    "summary": "I chose Transformers because they're absolutely central to modern deep learning. I used Claude's learning mode to walk through the attention mechanism from first principles, asking questions that forced me to reason about design choices rather than just memorize formulas. What surprised me most was how many concepts I thought I knew (like \"why do we need separate Q, K, and V?"
  },
  {
    "id": "ed-7448365",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: How to Use Perplexity Learn",
    "dek": "Using Perplexity Pro \"Learn\" Mode for Active Deep Learning Study\n\nA Practical Guide for CS/ML Students\n\nIntroduction: Why Active AI Learning Beats Passive Reading\n\nTraditional lecture prep looks like ...",
    "student": "Martin Alvarez-Kuglen",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7448365"
    },
    "body_html": "Using Perplexity Pro \"Learn\" Mode for Active Deep Learning Study\n\nA Practical Guide for CS/ML Students\n\nIntroduction: Why Active AI Learning Beats Passive Reading\n\nTraditional lecture prep looks like this: you read notes, hope you understand, and only discover gaps when you hit the homework. It is well known that paired study is a great way to learn, but sometimes it can be difficult to find a partner. Perplexity Pro's \"Learn\" mode fixes this, it becomes an interactive study partner that adapts to your confusion in real time.\n\nThis guide shows you how to use that tool effectively by walking through a real example: working through a lecture on Graph Neural Networks. I'll show you the patterns I used, where they worked, where they didn't, and how you can adapt them for your own courses.\n\nCore principle: The tool is best when you treat it as a conversation with a study partner, not a textbook. Ask clarifying questions. Restate concepts. Push back on claims. This transforms passive reading into active understanding.\n\nGetting Started: Set Your Learning Goal\n\nBefore you open Perplexity, be clear about what you want.\n\nWhen I started, I said: \"I would like to understand this lecture material better for my deep learning class. This lecture is on graph neural networks, can you please review the lecture notes and give me a broad overview of the material covered?\"\n\nThe AI responded with a structured list of topics and then asked a critical question back: \"Before we go deeper into any of these, what are your learning goals with this material (e.g., doing well on exams, implementing a GNN for research, understanding theory connections to Transformers)?\"\n\nWhat I learned: Be specific about your goal. Are you prepping for an exam? Building intuition before homework? Reproducing a paper? This changes the context and therefore how the AI scaffolds explanations. I said I wanted to understand the lecture, and that became my north star—the AI kept explanations grounded in the lecture's framing, not abstract textbook definitions.\n\nThe Dialogue Loop: How to Ask Questions\n\nStep 1: Ask for a High-Level Explanation\n\nStart broad. Don't jump into minutiae.\n\nExample: \"How do CNNs relate to GNNs?\"\n\nThe AI will give you a few paragraphs. At this point, you're just absorbing the shape of the idea.\n\nStep 2: Identify Your Confusion\n\nRead the explanation. What feels unclear? Not the whole thing—one specific thing.\n\nExample: I thought \"the GNN operates on the entire graph\" meant something different than \"the CNN kernel slides over patches.\" So I asked: \"In a CNN, the 'graph' is the kernel, but this gets ran over an entire image. For a GNN, if the 'graph' is the kernel, then what is the image?\"\n\nThis is crucial. Don't ask vague questions like \"Can you explain this better?\" Instead, pin down the exact point of confusion.\n\nStep 3: Have the AI Sharpen the Answer\n\nThe AI will either clarify directly or ask you a question back to diagnose the gap.\n\nExample response: The AI said: \"The entire graph is the input to the GNN, not just a 'kernel' like in CNNs... all nodes and edges are processed simultaneously, with each node updating its representation based on information from its neighbors in the graph.\"\n\nThat direct correction—entire graph as input, not local patches—unlocked further questions.\n\nStep 4: Restate the Concept in Your Own Words\n\nThis is non-negotiable. Don't skip this.\n\nMy restatement: \"So each node receives information from its neighbors like in a CNN kernel. So if we have a graph with nodes and edges, does that mean that each node has the same function applied to it?\"\n\nThe AI will then validate or correct your restatement. This catches misunderstandings before they calcify. If it is wrong, ask it to self-diagnose its mistakes and correct itself.\n\nStep 5: Ask \"Why\" or \"How\"—Push Deeper\n\nOnce you have the shape of an idea, push for deeper understanding.\n\nExample: After learning that all nodes use the same update rule, I asked: \"Why do we want to share the same parameters across all nodes, instead of giving each node its own separate parameters?\"\n\nThe AI gave me three reasons: (1) efficiency, (2) generalization to variable graph sizes, (3) respecting permutation symmetry. This \"why\" transformed a technical detail into conceptual understanding.\n\nPattern Recognition: Asking the Right Follow-Up Questions\n\nAs you work through material, use these question types:\n\nClarification Questions\n\nForm: \"When you say X, do you mean Y or Z?\"\n\nExample: \"When you say the aggregation must be permutation-invariant, do you mean it shouldn't depend on the order I list my neighbors?\"\n\nUse this to nail down terminology and avoid semantic drift.\n\nRestatement Checks\n\nForm: \"So if I understand correctly, the idea is [restate]. Is that right?\"\n\nExample: \"So weight-sharing means every node applies the same function, but nodes end up different because they have different inputs (features + neighborhoods). Is that right?\"\n\nThis allows self-verification of the understanding. If you are wrong, the AI will tend to point it out. Remember, you can both be wrong, but overall I have found that AI is better at pointing out your mistakes than it is at being right about things.\n\nGeneralization Questions\n\nForm: \"Does this principle apply to X as well? What about edge case Y?\"\n\nExample: \"Does this only apply to undirected graphs? What if I have directed or weighted edges?\"\n\nThese push you from memorizing one example to understanding the principle.\n\nComparison Questions\n\nForm: \"How is X different from Y?\"\n\nExample: \"Why does only f have an activation function in this design? Why not g as well?\"\n\nWhen the AI answers, you get both immediate context (the lecture's design choice) and broader understanding (modern alternatives like GraphSAGE).\n\nIntuition Questions\n\nForm: \"Why would I care about X? Why is it useful?\"\n\nExample: \"Why is permutation invariance important for graph neural networks?\"\n\nMy answer: \"If we tried to force a specific graph topology into the network, that would make it not very useful... so instead we want to learn a function which works for many graph topologies.\"\n\nThe AI validated this and sharpened my language. These intuition checks are gold—they separate deep understanding from surface-level facts.\n\nWhen the AI Struggles: Recognition and Recovery\n\nThe AI isn't perfect. Here's how to recognize and fix common issues:\n\nIssue 1: Circular or Vague Explanations\n\nWhat happens: The AI re-explains the same concept in different words without addressing your confusion.\n\nExample: Early on, I asked about input scope (entire graph vs. local patches). The AI gave a vague answer about \"the GNN operates directly on the full graph structure.\" I still didn't understand.\n\nHow I fixed it: I asked a more specific question: \"In a CNN, the kernel slides over the image. For a GNN, if the kernel is the GNN layer, what is the image?\"\n\nLesson: When answers feel circular, ask a more specific question with a concrete analogy.\n\nIssue 2: False Confidence on Details\n\nWhat happens: The AI confidently states something that might be wrong or oversimplified.\n\nExample: Early on, it tried to map GNNs to CNNs. The AI initially went along with this analogy.\n\nHow I fixed it: I challenged its confidence and asked an inquisitive question to help it self-diagnose its mistakes.\n\nLesson: Verify claims by asking follow-up questions. Cross-check with the lecture afterward.\n\nKey Takeaways\n\nAsk specific questions. \"Can you explain this better?\" gets nowhere. \"When you say X, do you mean Y?\" gets everywhere.\n\nRestate concepts in your own words. This is non-negotiable verification. Don't skip it.\n\nPush for depth with \"why\" and \"how\" questions. Separate surface understanding from real comprehension.\n\nBe willing to push back. If an explanation feels imprecise or wrong, say so. Your intuition matters.\n\nCross-check with other material. The AI is a study partner, not the source of truth. The lecture notes and textbooks are your ground truth.\n\nRecognize the AI's limitations. Great for conceptual understanding. You'll need to supplement with implementation, papers, and problem sets.\n\nUse this as pre-homework prep, not a replacement for thinking. Work through the lecture with the AI before you see the problem set. Then do the homework by hand yourself.\n\nSee conversation:\n",
    "attachments": [
      {
        "name": "special_participation_E.pdf",
        "url": "https://static.us.edusercontent.com/files/cn7BR7zilJtFpfuEmw30rxju"
      }
    ],
    "highlight": false,
    "summary": "Traditional lecture prep looks like this: you read notes, hope you understand, and only discover gaps when you hit the homework. It is well known that paired study is a great way to learn, but sometimes it can be difficult to find a partner. Perplexity Pro's \"Learn\" mode fixes this, it becomes an interactive study partner that adapts to your confusion in real time."
  },
  {
    "id": "ed-7448304",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: residual connection",
    "dek": "This is my first time using ChatGPT’s Study Mode; I normally rely on the standard interface. I found the experience to be noticeably more interactive and engaging. The model proactively asks follow-up...",
    "student": "Kexin Liu",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7448304"
    },
    "body_html": "This is my first time using ChatGPT’s Study Mode; I normally rely on the standard interface. I found the experience to be noticeably more interactive and engaging. The model proactively asks follow-up questions that reinforce my understanding, which proves highly effective for learning. For example, when I asked about residual connections, it not only provided a clear explanation but also accurately identified the source of my confusion and addressed it in a targeted way. Overall, Study Mode has been very helpful in deepening my comprehension of complex concepts.",
    "attachments": [
      {
        "name": "Special Participation form E-1.pdf",
        "url": "https://static.us.edusercontent.com/files/9wlLcyvh2Y5IWCWndgYjMgJA"
      }
    ],
    "highlight": false,
    "summary": "This is my first time using ChatGPT’s Study Mode; I normally rely on the standard interface. I found the experience to be noticeably more interactive and engaging. The model proactively asks follow-up questions that reinforce my understanding, which proves highly effective for learning."
  },
  {
    "id": "ed-7448295",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: GNN",
    "dek": "I continued using ChatGPT’s Study Mode to support my learning and found it particularly effective for explaining foundational concepts. It provides interactive questions and delivers information in sm...",
    "student": "Kexin Liu",
    "date": "2025-12-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7448295"
    },
    "body_html": "I continued using ChatGPT’s Study Mode to support my learning and found it particularly effective for explaining foundational concepts. It provides interactive questions and delivers information in small, structured sections, which greatly enhances comprehension. Although it may be less effective when addressing highly sophisticated topics, it remains a valuable tool for clear introductory explanations and for helping me solidify core ideas.\n\n",
    "attachments": [
      {
        "name": "Special Participation form E-2.pdf",
        "url": "https://static.us.edusercontent.com/files/1imTPJJS1VdkExdEYnepNsQJ"
      }
    ],
    "highlight": false,
    "summary": "I continued using ChatGPT’s Study Mode to support my learning and found it particularly effective for explaining foundational concepts. It provides interactive questions and delivers information in small, structured sections, which greatly enhances comprehension."
  },
  {
    "id": "ed-7445915",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: GPT Study mode on SSMs",
    "dek": "I was inspired by all the other posts using ChatGPT study mode to create an interactive study method for a lot of the concepts in the class, and I tried a few of them out (shoutout Reina for the Muon ...",
    "student": "Andy Peng",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7445915",
      "chatgpt": "https://chatgpt.com/share/69395239-3e24-8012-be72-118e7e863f65"
    },
    "body_html": "I was inspired by all the other posts using ChatGPT study mode to create an interactive study method for a lot of the concepts in the class, and I tried a few of them out (shoutout Reina for the Muon and MuP ones!) and I really enjoyed them! I also saw Zhangzhi's post about using Grok4(fast) as a study guide for SSMs but I found that the outputs were a bit too overwhelming, and as a user I had to kind of direct the interactive session too much compared to what I would like. I was always a bit shaky on SSMs so I wanted to create an interactive study guide for SSMs that was just as helpful as the Muon and MuP ones. At first I tried the Learn mode on Perplexity Pro and see how it contrasts with ChatGPT's Study mode and Grok4(fast), but I quickly found that it was not that good. It would hallucinate citations from the lectures that weren't there and the outputs were way to lengthy. It wasn't able to teach step by step in a story-like manner like in the ChatGPT's study mode examples. So I decided to just stick with GPT Study mode. Here is my prompt (I took inspiration from Reina's post + help from ChatGPT to make the prompt):\n\nYou are my interactive tutor for modern State Space Models (SSMs) in deep learning — including their mathematical foundations, continuous-time vs discrete-time views, stability, long-range dependencies, discretization, and selective input-dependent gating as used in architectures such as Mamba.\n\nAll explanations must be based on the lecture slides I provide (lec16.pdf and lec17.pdf), including their diagrams, equations, and intuitions. At every step, connect what you say to content explicitly present in those slides.\n\nThis tutoring session should be deeply interactive. In every reply:\n\nKeep answers focused and concise (3–6 short paragraphs).\n\nDo not move on to the next topic unless I say so.\n\nAlways end with a specific question (concept check, clarification, or small exercise).\n\nAdapt dynamically to my answers:\n\nIf I show misunderstanding, give a short explanation and ask a clarifying question.\n\nIf my answer is correct and confident, increase the complexity of the next question.\n\nIf I am confused at a basic level, go back to fundamentals.\n\nOverall Story I Want to Learn\n\nFollow this narrative in order unless I say otherwise:\n\nBig-picture motivation:\n\nWhy SSMs are introduced as an alternative to attention for long-range dependencies (lec16).\n\nThe efficiency vs. efficacy tradeoff and the desire to keep memory of the past while being stable.\n\nRole of linear time-invariant (LTI) systems and why structure matters.\n\nFoundations of SSMs:\n\nThe core equations h_{t+1} = A h_t + B u_t, y_t = C h_t.\n\nInterpret “history captured in the state” and why dimension N matters (lec16, p.1).\n\nHow recurrence and convolution views are equivalent (lec17, p.5–10).\n\nStability & eigenvalues:\n\nHow eigenvalues of A determine whether memory explodes, decays, or persists (lec16, p.2).\n\nWhy long-range memory requires eigenvalues near the unit circle.\n\nReal vs complex eigenvalues and the motivation for HIPPO-style initialization (lec16, p.3).\n\nContinuous-time SSMs → discretization\n\nThe CT system \\dot{x}(t) = A x(t) + B u(t), y(t)=C x(t) (lec17, p.5).\n\nStep-size \\Delta t as a degree of freedom and its effect on stability and memory (lec17, p.6–7).\n\nWhy e^{A\\Delta t} matters and what small vs. large \\Delta t does.\n\nInput-dependent selective gating (Mamba):\n\nWhy changing \\Delta t dynamically allows the model to modulate “how much of the past” to keep (lec17, p.7).\n\nThe selective-scan mechanism and how it combines recurrence & convolution views efficiently (lec17, p.10).\n\nHow this enables long-range reasoning with linear-time inference.\n\nPutting it all together:\n\nHow SSMs unify recurrence, convolution, and long-range memory.\n\nHow stability, eigenvalues, discretization, and gating combine in modern SSM architecture design\n\nStep 1: First Response Behavior\n\nYour first response should include:\n\nA two-paragraph big-picture intro, summarizing:\n\nWhy SSMs aim to efficiently model long-range dependencies while keeping stability under control.\n\nThe idea that the state must encode all relevant past information, but eigenvalues of A determine how long memory persists or explodes.\n\nThe CT→DT viewpoint and the importance of discretization (e^{A\\Delta t}).\n\nThe idea of selective input-dependent gating as in Mamba.\n\nA roadmap of the main topics (the 6 bullets above), explained as a coherent storyline following the slides.\n\nEnd your message with one short question to check my high-level understanding (e.g., “Why does the stability of A matter for memory length?”).\n\nAfter I answer, move to Topic 1 unless I say otherwise.\n\nStep 2: Teaching Each Topic — Four Layers\n\nFor each topic in the roadmap, structure your response as:\n\n1. \n\nIntuition (linked to slides)\n\nUse 1–2 paragraphs to relate the concept to the lecture content (e.g., stability diagrams on lec16 p.2, CT curves on lec17 p.6).\n\nAlways link the intuition to SSM goals: efficient long-range memory, avoiding explosion, enabling useful recurrence.\n\n2. \n\nKey Formal Setup\n\nIntroduce just the necessary notation.\n\nUse small equations like those on the slides (e.g., discretization formula, eigenvalue conditions).\n\nDescribe verbally what each piece means.\n\n3. \n\nTiny Example\n\nProvide a tiny numeric or qualitative example (e.g., a 1D CT system with a<0, effect of \\Delta t, or a matrix with eigenvalues 0.5 and 1.02 and what that implies).\n\nMake sure it corresponds to examples shown in the notes when possible.\n\n4. \n\nUnderstanding Check\n\nAsk 1–2 short questions: one conceptual, optionally one computational.\n\nThen stop and wait for my answer.\n\nEnd each message by reminding me what the next topic will be only if I say I’m ready to move on.\n\nStep 3: Final Wrap-Up\n\nWhen I say I’m ready for a review:\n\nProvide a compact summary that connects:\n\nStability & eigenvalues → memory behavior.\n\nCT→DT conversion → practical SSM layers.\n\nSelective gating → adaptive long-range reasoning.\n\nHow these components align with diagrams and equations in lec16 & lec17.\n\nThe summary should read like a cohesive, lecture-aligned storyline.\n\nFinal Instruction\n\nBegin now with Step 1: give the two-paragraph big-picture intro, the roadmap, and a final comprehension question — all grounded in the slide content.\n\nHere is a link to the chat: https://chatgpt.com/share/69395239-3e24-8012-be72-118e7e863f65\nAnd here is the pdf of the logs: \n\nAnalysis\n\nOverall I think it was a very good introduction to SSMs especially for someone who maybe hasn't learned about it before. ChatGPT was able to follow the ideas presented in lecture in the same order:\n1. State Space Models\n2. Stability and efficiency analysis\n3. Continuous to Discrete SSMs\n4. Selective Gating and modularity\n5. Summary\n\nI think the pacing was a lot better compared to Grok and Perplexity, and the questions were pretty solid. I think the questions were pretty fundamental and didn't go in depth much at all but I think for a pre-lecture study session or quick review it is useful. Overall the main downside is it didn't go as in depth compared to the lectures, but I probably could have prompted it better. I also like how it points to specific parts of the slides so I can look back for more reference. \n\nThere are a few specific things I wish it touched more upon, such as \n- explaining what a convolution is\n- FFT and why it's important/useful\n- go more into the specific models like S3 and S4 and what changed\n- The connection to attention and the efficiency tradeoffs\n\nI think another general downside with GPT (and many other frontier models) is that it is too nice (like Reina also mentioned) so it doesn't really push you on your answers, and it is up to the user to give a really precise answer or admit when they don't know. Because otherwise the LLM will accept a handwavey answer. But this could also be updated with better prompting.\n\nI also think the small numerical examples it gave weren't that useful but again I don't think that's really the main point of this tool, I think it really shines as a quick interactive refresher to pinpoint what you don't understand before lecture or reading the textbook, allowing users to understand where they are at with the content before deciding what to focus on more.\n\n",
    "attachments": [
      {
        "name": "Study Mode - SSM big-picture introduction.pdf",
        "url": "https://static.us.edusercontent.com/files/PaXdG4UxndMpzaA1uD2ym6cN"
      }
    ],
    "highlight": false,
    "summary": "I was inspired by all the other posts using ChatGPT study mode to create an interactive study method for a lot of the concepts in the class, and I tried a few of them out (shoutout Reina for the Muon and MuP ones!) and I really enjoyed them!"
  },
  {
    "id": "ed-7445878",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Professor Softmax (A Socratic Stress Test on Attention Math)",
    "dek": "I wanted to move beyond the code and really stress-test my intuition for the linear algebra that makes Transformers work. I felt that I knew how to write the code (and also from my Special Participati...",
    "student": "Shreyes Sridhara",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7445878",
      "chatgpt": "https://chatgpt.com/share/693947b5-30b4-8006-804e-5b81f753330a"
    },
    "body_html": "I wanted to move beyond the code and really stress-test my intuition for the linear algebra that makes Transformers work. I felt that I knew how to write the code (and also from my Special Participation B), but I didn't fully grasp why certain design choices, like the scaling factor or the head dimension size, were mathematically necessary.\n\nTo fix this, I built a custom \"Socratic Tutor\" persona called Professor Softmax. I gave it strict instructions: never give me the answer, only ask questions that force me to derive the logic step-by-step.\n\nThe Artifact: A rigorous chat log where I audit the \"Professor\" on the subtle failure modes of Self-Attention.\n\nKey Insights & Stress Tests:\n\nThe \"Temperature\" Intuition: The model helped me visualize how scaling the Key matrix (K) effectively acts like a temperature parameter. If you scale K by 100, the dot products explode, causing the Softmax to peak around a single token (becoming a \"hard\" argmax). This helps explain why initialization scale is so critical.\n\nThe \"Value Scaling\" Trap: I intentionally fed the model a misconception—that scaling the Value matrix (V) would change where the model attends. The tutor correctly caught the trap, clarifying that V only affects the magnitude of the output vector, while Q and K are the sole determinants of the attention pattern.\n\nThe True Purpose of sqrt(dk): I used to think we divided by sqrt(dk) just to keep numbers small. The tutor forced me to derive the actual reason: it's about Variance. The dot product of two random vectors grows with the dimension size (dk). Without dividing by sqrt(dk), the variance explodes, pushing Softmax values into saturation regions where the gradients vanish (become zero).\n\nThe Low-Rank Bottleneck: This was the biggest \"aha\" moment. We walked through why the Attention Matrix cannot be \"full rank\" if the head dimension dk is smaller than the sequence length N. Since the attention score is the product of two rectangular matrices (Q and K^T), the resulting matrix is mathematically constrained to a lower rank. This helped me understand why Multi-Head Attention is necessary: single-head attention literally lacks the mathematical capacity to model complex, independent relationships between all tokens.\n\n\nHere is my session with the prof and my annotated transcript:\n\nhttps://chatgpt.com/share/693947b5-30b4-8006-804e-5b81f753330a",
    "attachments": [
      {
        "name": "Special Participation E_ _Professor Softmax_.pdf",
        "url": "https://static.us.edusercontent.com/files/bFKRI5xlHCh696eLoJBss8Hw"
      }
    ],
    "highlight": false,
    "summary": "I wanted to move beyond the code and really stress-test my intuition for the linear algebra that makes Transformers work. I felt that I knew how to write the code (and also from my Special Participation B), but I didn't fully grasp why certain design choices, like the scaling factor or the head dimension size, were mathematically necessary."
  },
  {
    "id": "ed-7445807",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: A Grounded \"FaceNet\" Study Guide using NotebookLM",
    "dek": "I’ve been using LLMs to help study for HW10, but I noticed that general models (like ChatGPT) often hallucinate specific numbers from research papers, specifically the parameter counts and FLOPs in th...",
    "student": "Shreyes Sridhara",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7445807"
    },
    "body_html": "I’ve been using LLMs to help study for HW10, but I noticed that general models (like ChatGPT) often hallucinate specific numbers from research papers, specifically the parameter counts and FLOPs in the FaceNet paper (Schroff et al. 2015).\n\nTo fix this, I used Google NotebookLM to create a grounded study guide. I uploaded the original PDF and treated it as a \"source of truth\" to verify the technical details that other models missed.\n\nSo I built an interactive Q&A guide that correctly extracts:\n\nModel Architectures: The exact difference between NN1 (Zeiler & Fergus) and NN2 (Inception) without mixing up the columns in Table 1.\n\nLoss Dynamics: A clear explanation of \"Semi-Hard\" vs \"Hard\" negatives and why the former prevents model collapse.\n\nPreprocessing: The specific \"tight crop\" strategy that distinguished FaceNet from its predecessors like DeepFace (which used complex 3D alignment).\n\n\n\nMy Process (Iterative Verification): I didn't just ask for a summary. I stress-tested the tool with \"niche\" questions about experimental protocols (e.g., the specific Hold-out Test Set splits) to ensure it was actually reading the text and not just guessing.\n\n\n\nI’ve attached the annotated transcript of my session below. The annotations highlight where the tool succeeded in correcting the misconceptions I encountered earlier.\n\nhttps://notebooklm.google.com/notebook/99119019-e588-4d18-8878-40f4169407bc",
    "attachments": [
      {
        "name": "FaceNet Paper Study Guide.pdf",
        "url": "https://static.us.edusercontent.com/files/iaM3M3OPLPdlsDMVFKLAYsJi"
      }
    ],
    "highlight": false,
    "summary": "I’ve been using LLMs to help study for HW10, but I noticed that general models (like ChatGPT) often hallucinate specific numbers from research papers, specifically the parameter counts and FLOPs in the FaceNet paper (Schroff et al. 2015)."
  },
  {
    "id": "ed-7445771",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Bridging Gap Between Lectures/Discussion and Homework",
    "dek": "I usually watch lectures the day of and go to discussion. However, the corresponding homework often feels like it is covering content from the past that I have already forgotten. This means before I s...",
    "student": "Rohan Gopalam",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7445771"
    },
    "body_html": "I usually watch lectures the day of and go to discussion. However, the corresponding homework often feels like it is covering content from the past that I have already forgotten. This means before I start homework, I have to go through the lecture and discussion again. While this is not a bad thing as I am reviewing the content again, a lot of times I am wasting time relearning things I already know well when I am trying to find the information that is more challenging. To combat this, I created a prompt for Claude to generate a warmup worksheet and reading before I start the homework. I chose Claude because I have had good experiences with Claude's pdf creation abilities in the past. I have attached the prompt below. With the prompt, I also added pdf files of the discussion, lecture notes, and homework for that week. \n\nPrompt: I am getting ready to start my homework. However, I need a review of the material to get me warmed up again to do the homework. Looking at the lecture slides and the discussion for this week, can you create a quick review guide for me. I want this review guide to have a mini reading at the start with key information, a highlight of important sub parts of questions from the discussion, and finally some warmup questions with corresponding solutions. make sure this will not take more than 30-45 minutes to complete. do not make the example questions too similar to the homework so the homework is still educational. format it as a pdf worksheet so I can export it and work directly on it.\n\nHere is an example worksheet for homework 12 (edit accidentally named it C instead of E):",
    "attachments": [
      {
        "name": "Special Participation C.pdf",
        "url": "https://static.us.edusercontent.com/files/Tw4QFgLgosD6uUbRJSTqmdzz"
      }
    ],
    "highlight": false,
    "summary": "I usually watch lectures the day of and go to discussion. However, the corresponding homework often feels like it is covering content from the past that I have already forgotten. This means before I start homework, I have to go through the lecture and discussion again."
  },
  {
    "id": "ed-7445282",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: Interactive RMS Norm Visualizer",
    "dek": "I made an Interactive RMS Norm Visualizer! Feel free to download the repo and try it out!\n\nHere's the repo:\nhttps://github.com/mokingyou/exploRMS\n\nHere are my LLM logs: https://chatgpt.com/share/69390...",
    "student": "Micah Mok",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7445282",
      "chatgpt": "https://chatgpt.com/share/69390a26-088c-8010-990c-f3ca8e59b726",
      "github": "https://github.com/mokingyou/exploRMS"
    },
    "body_html": "I made an Interactive RMS Norm Visualizer! Feel free to download the repo and try it out!\n\nHere's the repo:\nhttps://github.com/mokingyou/exploRMS\n\nHere are my LLM logs: https://chatgpt.com/share/69390a26-088c-8010-990c-f3ca8e59b726\n\nHere's a screenshot: ",
    "attachments": [],
    "highlight": false,
    "summary": "I made an Interactive RMS Norm Visualizer. Feel free to download the repo and try it out. Here's the repo:\n\n\nHere are my LLM logs: \n\nHere's a screenshot:."
  },
  {
    "id": "ed-7445213",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Learning Muon by Gemini Guided Learning",
    "dek": "The tutoring session on the Muon optimizer (Momentum Orthogonalized by Newton–Schulz) via Gemini Guided Learning was effective. It will provide a question after the explanation, make you think about t...",
    "student": "Zhuangzhe Wu",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7445213"
    },
    "body_html": "The tutoring session on the Muon optimizer (Momentum Orthogonalized by Newton–Schulz) via Gemini Guided Learning was effective. It will provide a question after the explanation, make you think about the problem and answer it, then give the answer and explanation.\n\nThe session successfully explained how Muon provides a cheap, $O(n^2)$ alternative to the expensive $O(n^3)$ SVD required for ideal semi-orthogonal updates. I learned that Muon achieves this by:\n\nMatrix Accumulation: Using a momentum-like accumulator to store second-order information and provide the necessary normalization factor.\n\nNewton–Schulz Iteration: Applying the N-S recurrence, which acts as a fast polynomial transformation on the singular values of the accumulated matrix.\n\nThis transformation compresses the singular values toward 1, stabilizing the optimization path and allowing for larger learning rates. The question-by-question format of the guidance did a good job of ensuring a deep, sequential understanding of these core concepts.",
    "attachments": [
      {
        "name": "muon.pdf",
        "url": "https://static.us.edusercontent.com/files/OyX8fQ9NhOKbbfFDUvMXVbJ2"
      },
      {
        "name": "Lecture 7.pdf",
        "url": "https://static.us.edusercontent.com/files/auTyYghbGPNMjxcgAAZqKjkg"
      }
    ],
    "highlight": false,
    "summary": "The tutoring session on the Muon optimizer (Momentum Orthogonalized by Newton–Schulz) via Gemini Guided Learning was effective. It will provide a question after the explanation, make you think about the problem and answer it, then give the answer and explanation."
  },
  {
    "id": "ed-7444983",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Learning diffusion by Gemini Guided Learning",
    "dek": "Diffusion is a difficult part of the class and I spent a lot of time on learning it. Gemini's Guided Learning helps to transform the study of the \"STEP-BY-STEP DIFFUSION: AN ELEMENTARY TUTORIAL\" file ...",
    "student": "Zhuangzhe Wu",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7444983"
    },
    "body_html": "Diffusion is a difficult part of the class and I spent a lot of time on learning it. Gemini's Guided Learning helps to transform the study of the \"STEP-BY-STEP DIFFUSION: AN ELEMENTARY TUTORIAL\" file from passive reading into active knowledge construction. I can direct Gemini to act as an expert tutor, assessing my understanding of key concepts like Gaussian Diffusion (Section 1), DDPM (Section 2), and DDIM (Section 3) by asking targeted questions one at a time. The goal is to actively reason through core ideas—such as why the reverse process is simplified as a Gaussian approximation (Fact 1), how the $\\ell_2$ regression loss relates to learning the conditional mean $\\mathbb{E}[x_{t-1}|x_t]$, or how DDIM implements a deterministic transport map (Flow Matching) —with Gemini providing iterative feedback and guidance to deepen my insights.\n\nhttps://gemini.google.com/share/0f68e240cf10\n\n",
    "attachments": [
      {
        "name": "diffusion_tutorial.pdf",
        "url": "https://static.us.edusercontent.com/files/OmssonS6ebIScxQ6I1JwSyQi"
      }
    ],
    "highlight": false,
    "summary": "Diffusion is a difficult part of the class and I spent a lot of time on learning it. Gemini's Guided Learning helps to transform the study of the \"STEP-BY-STEP DIFFUSION: AN ELEMENTARY TUTORIAL\" file from passive reading into active knowledge construction."
  },
  {
    "id": "ed-7443917",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Understanding  FFT Trick in State-Space Models",
    "dek": "I was struggling to understand how the FFT trick works for State-Space Models (SSMs), especially the idea of viewing the RNN outputs at each time step as sequences evolving component-by-component (thi...",
    "student": "Tvisha Londhe",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7443917",
      "chatgpt": "https://chatgpt.com/share/6938b61a-b838-800f-bd21-b9b7a0b6807b"
    },
    "body_html": "I was struggling to understand how the FFT trick works for State-Space Models (SSMs), especially the idea of viewing the RNN outputs at each time step as sequences evolving component-by-component (this is from lecture 17). To work through the confusion, I drew a diagram and had an extended interaction with ChatGPT, which helped me connect the intuition: each coordinate of the hidden state forms its own time-series, and the FFT lets us convolve these sequences efficiently. I’m sharing my annotated conversation and the diagram here in case it helps anyone else build intuition for how the component-wise viewpoint makes the FFT trick work. I passed in past of my lecture notes as the first prompt. \n\n\nAnnotated pdf: \n\nThis was the final diagram I had: \n\nThis is the trace without any annotations (sorry about any spelling errors!): https://chatgpt.com/share/6938b61a-b838-800f-bd21-b9b7a0b6807b",
    "attachments": [
      {
        "name": "SpecialParticipationE_FFT_for_SSM_annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/fqtcGKTY7GuR6BhejoSoLnrX"
      }
    ],
    "highlight": false,
    "summary": "I was struggling to understand how the FFT trick works for State-Space Models (SSMs), especially the idea of viewing the RNN outputs at each time step as sequences evolving component-by-component (this is from lecture 17)."
  },
  {
    "id": "ed-7442045",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini Gem as a personal tutor for understanding key concepts relating to transformers",
    "dek": "I created a custom Gemini gem, called Transformer Tutor. It is tailored specifically to be a helpful tutor regarding essential knowledge relating to transformer architecture, setup, and calculations.\n...",
    "student": "Jacqueline Thibault",
    "date": "2025-12-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7442045"
    },
    "body_html": "I created a custom Gemini gem, called Transformer Tutor. It is tailored specifically to be a helpful tutor regarding essential knowledge relating to transformer architecture, setup, and calculations.\n\nI gave it the description: This gem helps students in a deep learning class learn about essential concepts relating to transformers.\n\nAnd the instructions: You are a helpful ai assistant that quizzes students about concepts relating to transformer architecture, setup, and calculations. You will walk through the intuition and breakdown of all the pdfs I uploaded to you in the \"knowledge\" section, periodically pausing and polling the user for understanding via a 1 question quiz. Once the user has demonstrated that they understand the concept, continue going through the material until you decide it is time to poll the user for another question. Do this for all the material, aggregating all the pdfs in a manner that is logical to present.\n\nI uploaded 5 pdfs into the knowledge section; three of them were the lecture notes for lectures 18, 19, and 20, and two of them were helpful notes that students uploaded in the Edstem thread for lectures 16-20. \n\n\nUpon my first pass, I realized that it might not be so helpful for the Transformer Tutor to just start from square 1 concepts. Especially when reviewing for an exam, it would be better if the tutor could assess the user's familiarity with the concepts first, and then tailor its questions to the user's current level of understanding. Thus, I modified the instructions to include:\n\n\"You will first present a brief quiz to the user, in order to assess their knowledge level with the subject (i.e. if they are a beginner and need lots of guidance, or if they are already quite familiar with the concepts and need assistance refining their skills). \"\n\nTo be more effective psychologically and to not baby the user, I also added:\n\"Do not be nice to me, e.g. do not say \"youre on the right track!\" if I'm incorrect. Be firm.\"\n\nI was then able to have a productive and insightful conversation that helped me study transformers.\n\nAttached is the gem: https://gemini.google.com/gem/1fug1WA7K31PUqF5mOxRR8fT6vHf38_w6?usp=sharing\n\nand my annotated trace: \n\n\n\n",
    "attachments": [
      {
        "name": "special e - Google Docs.pdf",
        "url": "https://static.us.edusercontent.com/files/q74VHPlQQ2I7Qdfo47fGA9yg"
      }
    ],
    "highlight": false,
    "summary": "I created a custom Gemini gem, called Transformer Tutor. It is tailored specifically to be a helpful tutor regarding essential knowledge relating to transformer architecture, setup, and calculations."
  },
  {
    "id": "ed-7439138",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: AI-Assisted GCN Tutor and Quiz (Annotated GNN Study Log)",
    "dek": "In this post I’m sharing an AI-assisted study trace for the Graph Neural Networks (GNN) lecture in CS 182. I used a large language model as a “GCN tutor” and asked it to (1) explain graphs, message pa...",
    "student": "Sufjan Fana",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7439138"
    },
    "body_html": "In this post I’m sharing an AI-assisted study trace for the Graph Neural Networks (GNN) lecture in CS 182. I used a large language model as a “GCN tutor” and asked it to (1) explain graphs, message passing, and the standard GCN layer, (2) work through a fully numeric one-layer GCN example on a tiny 3-node graph, (3) generate a short quiz about GNNs/GCNs, and (4) critique its own explanations.\n\nThe attached transcript is annotated by me. In the annotations I mark where the explanations are correct and helpful, where the math or terminology is sloppy or misleading (for example around normalization and self-loops), and where the model makes speculative claims about what CS 182 covers. My goal is to give a reusable prompt sequence plus a critically evaluated log that classmates can use to check their understanding of GCNs, while also seeing concrete examples of where LLM explanations need to be double-checked rather than trusted blindly.\n\n",
    "attachments": [
      {
        "name": "GCN basics and update rule .pdf",
        "url": "https://static.us.edusercontent.com/files/MA5UDIWNMUmoMQaUMndiMVcn"
      }
    ],
    "highlight": false,
    "summary": "In this post I’m sharing an AI-assisted study trace for the Graph Neural Networks (GNN) lecture in CS 182. I used a large language model as a “GCN tutor” and asked it to (1) explain graphs, message passing, and the standard GCN layer, (2) work through a fully numeric one-layer GCN example on a tiny 3-node graph, (3) generate a short quiz about GNNs/GCNs, and (4) critique its own explanations."
  },
  {
    "id": "ed-7439077",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Gemini Guided Learning vs Youlearn",
    "dek": "I conducted a comparison between Gemini Guided Learning and the startup YouLearn to prepare for content on Hw 12 focusing on Transformers and Variational Methods. Gemini effectively functioned as a gr...",
    "student": "Gabriel Han",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7439077"
    },
    "body_html": "I conducted a comparison between Gemini Guided Learning and the startup YouLearn to prepare for content on Hw 12 focusing on Transformers and Variational Methods. Gemini effectively functioned as a graduate-level Teaching Assistant by first generating a precise prompt that targeted specific homework nuances, such as the weight initialization bug in Encoder-Decoder architectures. It then leveraged this context to produce deep, scenario-based questions, including an interactive quiz on the mode-seeking behavior of Reverse KL Divergence. In contrast, while YouLearn provided a polished user interface with automated flashcards and quizzes, the assessment it generated was primarily recall-oriented—asking basic definitions like the properties of KL divergence—rather than testing the applied understanding required for this course.\n\nI also evaluated YouLearn's content synthesis capabilities by uploading a lecture transcript on Generative Models and the Manifold Hypothesis. The platform organized the text into chapters and offered study aids like summaries and podcasts. Although the summary was nice, I found that this level of summarization could be achieved just as effectively by pasting the transcript into Gemini. While YouLearn's feature set and UI are good to genearte different forms of study quickly, Gemini's ability to engage with the material and ask deeper questions made it a superior tool for this class.",
    "attachments": [
      {
        "name": "Special Participation E No 2.pdf",
        "url": "https://static.us.edusercontent.com/files/4GCqECorJyAcbg3Pt9gzT7dS"
      }
    ],
    "highlight": false,
    "summary": "I conducted a comparison between Gemini Guided Learning and the startup YouLearn to prepare for content on Hw 12 focusing on Transformers and Variational Methods. Gemini effectively functioned as a graduate-level Teaching Assistant by first generating a precise prompt that targeted specific homework nuances, such as the weight initialization bug in Encoder-Decoder architectures."
  },
  {
    "id": "ed-7439063",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Transcript of video to notes and test questions",
    "dek": "To create an active AI-enhanced learning tool, I utilized Gemini to process a lecture on Variational Autoencoders and Post-Training. Since UC Berkeley lecture videos are often restricted by authentica...",
    "student": "Gabriel Han",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7439063"
    },
    "body_html": "To create an active AI-enhanced learning tool, I utilized Gemini to process a lecture on Variational Autoencoders and Post-Training. Since UC Berkeley lecture videos are often restricted by authentication, standard URL-based summarizers do not work; my workaround was to manually copy the raw transcript from the video player and paste it into Gemini. I prompted the model to transform the disorganized spoken text into a structured summary and generate 10 test questions to gauge understanding. This effectively turned a passive, linear transcript into an interactive study guide that I could use to simulate an exam environment immediately after the lecture.\n\nThe AI performed exceptionally well at taking the long context and shortening it quickly. It is also super easy and quick to copy the transcript into gemini (10 seconds). It did particularly well at structuring the summary despite not having any video context and the captions being quite disorganized. It also was able to act as context for any additional questions I wanted to ask. ",
    "attachments": [
      {
        "name": "Special Participation E No 1.pdf",
        "url": "https://static.us.edusercontent.com/files/peI3UzhIZhqQzh0RakL9fyWK"
      }
    ],
    "highlight": false,
    "summary": "To create an active AI-enhanced learning tool, I utilized Gemini to process a lecture on Variational Autoencoders and Post-Training. Since UC Berkeley lecture videos are often restricted by authentication, standard URL-based summarizers do not work; my workaround was to manually copy the raw transcript from the video player and paste it into Gemini."
  },
  {
    "id": "ed-7439035",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: LLM Architecture Explorer",
    "dek": "For this activity, I used an LLM as an \"Architecture Explorer\" to walk me through how deep learning models evolve from simple CNNs to ResNets and then to Transformer encoder blocks. The model gave str...",
    "student": "Sriram Srivatsan",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7439035"
    },
    "body_html": "For this activity, I used an LLM as an \"Architecture Explorer\" to walk me through how deep learning models evolve from simple CNNs to ResNets and then to Transformer encoder blocks. The model gave structured explanations (dataflow, receptive field, parameter sharing, inductive bias) and paired them with PyTorch-style code for each architecture. Throughout the transcript, I added short _Annotation_ comments where I pointed out places that were especially clear or practically useful, as well as spots that felt oversimplified or a bit overconfident. The goal is for this to act like an AI-powered pre/post-lecture reading: something you can skim to get intuition and code patterns, while my annotations flag what to trust fully and where to be a bit skeptical.\n\n\n\nUsing Sonnet 4.5:\n\nHere is the starting prompt:\n\nHere is the annotated chat history:",
    "attachments": [
      {
        "name": "starting_prompt.txt",
        "url": "https://static.us.edusercontent.com/files/0ajG8sn1heAc3cBLrdkdGkHn"
      },
      {
        "name": "chat_history.md",
        "url": "https://static.us.edusercontent.com/files/rfGliDTalfGr6vBN8LAoalFb"
      }
    ],
    "highlight": false,
    "summary": "For this activity, I used an LLM as an \"Architecture Explorer\" to walk me through how deep learning models evolve from simple CNNs to ResNets and then to Transformer encoder blocks. The model gave structured explanations (dataflow, receptive field, parameter sharing, inductive bias) and paired them with PyTorch-style code for each architecture."
  },
  {
    "id": "ed-7439033",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Optimizer Intuition Tutor",
    "dek": "This artifact is an AI-powered \"Optimizer Intuition Tutor\" built around a simple 2D quadratic toy model to visualize how SGD, Momentum, Adam, and μP actually move in parameter space. It walks through ...",
    "student": "Sriram Srivatsan",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7439033"
    },
    "body_html": "This artifact is an AI-powered \"Optimizer Intuition Tutor\" built around a simple 2D quadratic toy model to visualize how SGD, Momentum, Adam, and μP actually move in parameter space. It walks through local linear approximations, update directions, and full numerical trajectories, with ASCII sketches to make the geometry concrete. Throughout the conversation, I push back on the model’s claims (e.g., \"implicit l_2 regularization\" for SGD, Adam always normalizing to [1,1], and overly simple μP rules) and the tutor corrects or refines its explanations. I’ve added brief annotations at key points to flag where the reasoning is especially insightful, where it’s oversimplified or only true in special cases, and how it connects to what people actually see in modern deep learning training.\n\n\n\nUsing Sonnet 4.5:\n\nPrompt to give (CoT prompting):\n\nAnnotated chat history:",
    "attachments": [
      {
        "name": "starting_prompt.txt",
        "url": "https://static.us.edusercontent.com/files/P55R48PlyByXZ4C4nhIdgfcz"
      },
      {
        "name": "chat_history.md",
        "url": "https://static.us.edusercontent.com/files/7Ge9koAVt0Tyido59ZxRtVl3"
      }
    ],
    "highlight": false,
    "summary": "This artifact is an AI-powered \"Optimizer Intuition Tutor\" built around a simple 2D quadratic toy model to visualize how SGD, Momentum, Adam, and μP actually move in parameter space. It walks through local linear approximations, update directions, and full numerical trajectories, with ASCII sketches to make the geometry concrete. Throughout the conversation, I push back on the model’s claims (e.g."
  },
  {
    "id": "ed-7439003",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: NoteRefiner-OCR on Adam",
    "dek": "I wanted to come up with a prompt that could easily be copy pasted by anyone into a chatbot (I used GPT 5.1 Auto), such that it would make the chatbot take on the persona of a note refiner. I wanted t...",
    "student": "Jaewon Chang",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7439003"
    },
    "body_html": "I wanted to come up with a prompt that could easily be copy pasted by anyone into a chatbot (I used GPT 5.1 Auto), such that it would make the chatbot take on the persona of a note refiner. I wanted to see if prompting could make GPT 5.1 refine the class notes on the Adam optimizer, and this is the prompt I used:\n\n\nYou are NoteRefiner-OCR, an AI tutor that helps me learn from handwritten or lightly structured lecture notes. I will paste screenshots or PDF snippets from my handwritten notes (e.g., exported from Goodnotes). Treat the content as potentially noisy or incomplete. When I provide an image or OCR text, follow the steps below. After each numbered section, stop and wait for me to say “continue.” Transcription + Confidence Annotations (OCR Step) Transcribe the handwritten notes as accurately as possible. For any words, symbols, equations, or diagrams that appear unclear, annotate with: [low confidence: ...] Do NOT guess or fill gaps yet. Just transcribe and identify uncertainty. Clean Reconstruction Rewrite my notes in a clean, structured form: fix notation fix grammar reorder content logically keep ambiguous parts flagged Do not add new information yet. Gap Fill + Clarification (Adam-Specific) Fill in missing steps only where the notes clearly imply them. Provide short clarifications for: the meaning of Adam’s moment estimates bias correction the update rule any partial equations Flag any additions with [Refinement] so I know they came from you. Core Insight Extraction Summarize the 3–5 essential ideas from my notes about Adam, such as: conceptual role of m_t and v_t why bias correction matters intuition behind adaptive learning rates differences from SGD and RMSProp Keep this grounded in my notes. Deepening Layer (Optional Additions) Based on the content of my notes, add short expansions that provide deeper intuition. Examples: geometric intuition, hyperparameter effects, limitations. Mark every addition with [Expansion]. Worked Numerical Example Give a simple numerical example of an Adam update: choose small g_t, m_{t-1}, v_{t-1} compute m_t, v_t, m_hat_t, v_hat_t compute the parameter update Show all steps clearly. Misconception Check Identify 2–3 likely misconceptions based on my notes and your refinements. Provide a correction and a short explanation for each. Reflection Questions Give me: 2 questions testing basic comprehension 1 question testing deeper intuition Ask me: “Please upload or paste your handwritten notes page.”\n\nAnnotated google drive link: https://drive.google.com/file/d/1a_KhKekMZnZA_m7fp_z7SVY1j5uOBho6/view?usp=sharing\n\nI also worked on another prompt engineering project for my other special participation E, and I was intrigued by how different both prompts were in terms of robustness. For the above prompt in particular, I noticed that asking a follow-up question to one of its generated responses ends up distracting the model enough to where it forgets to execute the main pipeline (i.e. waiting for the user to say \"continue\" before actually continuing on). Although there were 7 parts that my prompt was trying to get the model to generate, after the model ended up forgetting the pipeline after the 4th part, I ended the conversation.\n\nThat being said, I think there are several good/interesting parts about this prompting method. For starters, it first begins by prompting the model to perform OCR on handwritten notes, so it is fully aware that the task at hand is to identify handwritten text. It also makes no assumptions about what is written: if it is unable to read the handwriting for instance, it will mention that it is unclear about that specific portion. Overall, it seems like there definitely could be a bit more prompt engineering to be done to make the model more robust to follow-up questions, but this definitely seems like a good starting point!",
    "attachments": [
      {
        "name": "182 participation E (2).pdf",
        "url": "https://static.us.edusercontent.com/files/SEXPn3GbivEFBaNZdOHO5FFF"
      }
    ],
    "highlight": false,
    "summary": "I wanted to come up with a prompt that could easily be copy pasted by anyone into a chatbot (I used GPT 5.1 Auto), such that it would make the chatbot take on the persona of a note refiner. I wanted to see if prompting could make GPT 5."
  },
  {
    "id": "ed-7438744",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E - Gemini Pro HW Walkthroughs; Detailed and Personalized Prompt Optimization Through Human Feedback",
    "dek": "For Homework 2, I used Gemini Pro as a highly adaptive tutor, but I didn’t just passively receive explanations; I actively shaped  how it taught me until it produced an ideal prompt that other student...",
    "student": "Garv Goswami",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7438744"
    },
    "body_html": "For Homework 2, I used Gemini Pro as a highly adaptive tutor, but I didn’t just passively receive explanations; I actively shaped  how it taught me until it produced an ideal prompt that other students could also use. \n\nI repeatedly asked Gemini to slow down, restate questions, define jargon before using it, and force me to reason through each step instead of dumping full solutions. Whenever its explanations were too abstract or too fast, I guided it to introduce analogies, numerical examples, and geometric intuition, especially for difficult concepts like inductive bias, optimizer trajectories, or initialization variance. \n\nThrough this back-and-forth, I trained it to follow a strict four-phase teaching structure: restate the question, walk through the reasoning, summarize key ideas, and check for understanding. I also refined how it handled each specific HW2 topic, optimizers, initialization, SVD, distributed training, and policy gradients, until the teaching method felt perfectly tailored to my learning style. After enough iterations, Gemini synthesized all of this guidance into a reusable master system prompt along with question-specific prompts, giving me (and now others) a consistent, deeply intuitive tutoring framework for the entire assignment.\n\nConversation Link: https://gemini.google.com/share/b9135207820a\n\nAnnotated Conversation and resulting Ideal Prompt:  ",
    "attachments": [
      {
        "name": "Tutoring the Gemini Pro Tutor (1).pdf",
        "url": "https://static.us.edusercontent.com/files/oHVNgdihRj1xa3Z4e0cRnoIo"
      },
      {
        "name": "Homework 2 - Gemini's Ideal Prompt.pdf",
        "url": "https://static.us.edusercontent.com/files/NOFVzFdmp9HMngkmuhtqFmcd"
      }
    ],
    "highlight": false,
    "summary": "For Homework 2, I used Gemini Pro as a highly adaptive tutor, but I didn’t just passively receive explanations; I actively shaped  how it taught me until it produced an ideal prompt that other students could also use."
  },
  {
    "id": "ed-7438517",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: UniNet Tutor (CNN, RNN, GNN comparative learning tool)",
    "dek": "When learning about CNNs, RNNs, and GNNs, I was getting slightly lost trying to figure out how one might be better than another in certain situations, and wanted to confirm that my understanding was c...",
    "student": "Jaewon Chang",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7438517"
    },
    "body_html": "When learning about CNNs, RNNs, and GNNs, I was getting slightly lost trying to figure out how one might be better than another in certain situations, and wanted to confirm that my understanding was correct. With the help of an LLM to refine a prompt (based on one that I came up with), I came up with the following prompt that compares CNNs, RNNs, and GNNs and dives deep into their specifics. I used GPT 5.1. This is the prompt:\n\n\nUniNet Tutor — CNN–RNN–GNN Comparative Learning Tool\n\nYou are UniNet Tutor, an AI teaching assistant that explains CNNs, RNNs, and GNNs and how they relate to one another. When I name one of these architectures, or provide a specific concept, follow the steps below in order. After each numbered section, stop and wait for me to say “continue.”\n\nCore Mechanism Summary (for CNN, RNN, or GNN)\n\nIn 4–6 sentences, explain: what computation the architecture performs, what structural assumptions or inductive biases it encodes, what types of data it is designed for. Avoid generic descriptions and focus on the distinctive mechanism.\n\nMathematical Skeleton\n\nProvide the minimal mathematical form of its forward pass using clean LaTeX. This should include only the essential operations (e.g., convolution, message passing, recurrence). Also identify: input/output shapes where parameters live what is shared (e.g., weight sharing, time sharing, edge sharing)\n\nRelation to the Other Two Architectures\n\nGive a clear comparison:\n\nhow this architecture generalizes or restricts the others\n\nwhat structural analogies exist\n\nwhat computations can or cannot be simulated by the others\n\nProvide at least ONE non-obvious insight.\n\nStrengths, Weaknesses, and Failure Modes\n\nGive 3 strengths, 3 weaknesses, and 2 realistic failure modes of this architecture. Keep explanations technical (e.g., vanishing gradients, local receptive field limitations, over-smoothing).\n\nConcrete Worked Example\n\nProvide a small, explicit example of the architecture’s forward computation using actual numbers. Keep tensors small: For CNNs: a tiny image (2×2 or 3×3) and a kernel For RNNs: a short sequence (length 3) For GNNs: a simple graph with 3–4 nodes Compute at least one intermediate output step-by-step.\n\n“Architecture Confusion Quiz”\n\nGive me 4 statements mixing CNN, RNN, and GNN properties. Have me classify each as applying to: CNNs, RNNs, GNNs, or All three. After I answer, reveal correct answers with explanations.\n\nHallucination Watchlist (Self-Check)\n\nBriefly identify places in your explanations where: assumptions might differ across textbooks, equivalence claims rely on strong conditions, shapes or graph conventions vary, statements should be verified using lecture notes.\n\nAsk me: “Which architecture would you like to explore first — CNNs, RNNs, or GNNs?”\n\nAnnotated google drive link: https://drive.google.com/file/d/1-wPseIr_q-LgThav3RJ30XhBvzTZZj3p/view?usp=sharing\n\nOne thing I noticed about the prompt was its structural robustness to tangential questions. When asking about a specific part of its explanation, the model answers the question at hand and immediately comes back to wait for the user to type \"continue\". Although I did not stress-test this super intensively, I asked two questions in a row about a specific explanation the model had generated, with both corresponding responses ending with something along the lines of \"Please tell me if you want me to continue with the next part\".\n\nThis tool was extremely helpful because it not only gives a summary of CNNs, RNNs, and GNNs for those who may lack knowledge on the topic, but also compares them to one another, along with strengths, weaknesses and failure modes of each of the architectures. It also doesn't simply go over all 3 topics, since some people may only have trouble with GNNs for instance. In consideration for such cases, the model begins by asking the user to pick a topic among the 3 – i.e. it is up to the user which topics they wish to explore. There is also a simple mathematical example to walk through what the math looks like, along with an architecture confusion quiz that is given towards the end to ensure that the user understands the concept fully.\n\nOne \"limitation\" of the tool that I personally found (and could possibly be resolved by further prompt engineering) is that the model asks whether the user wishes to take the architecture quiz after exploring each topic. So individuals that want to study CNNs, RNNs, and GNNs and then take the quiz will still be prompted whether they want to take an architecture quiz after learning about each topic. All in all, I think this was a fun experience as I was also able to refine my own understanding of the three topics!",
    "attachments": [
      {
        "name": "182 participation E (1).pdf",
        "url": "https://static.us.edusercontent.com/files/0XYr30MsWoG6ftOOSwZGpylk"
      }
    ],
    "highlight": false,
    "summary": "When learning about CNNs, RNNs, and GNNs, I was getting slightly lost trying to figure out how one might be better than another in certain situations, and wanted to confirm that my understanding was correct. With the help of an LLM to refine a prompt (based on one that I came up with), I came up with the following prompt that compares CNNs, RNNs, and GNNs and dives deep into their specifics."
  },
  {
    "id": "ed-7435928",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: Visualizing Optimizer Trajectories (SGD vs Momentum vs Adam)",
    "dek": "I kept memorizing optimizer formulas (momentum accumulates velocity, Adam divides by √v̂) but didn't really understand why they behave differently. So I created a prompt that generates animated visual...",
    "student": "Rishi Thakar",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7435928"
    },
    "body_html": "I kept memorizing optimizer formulas (momentum accumulates velocity, Adam divides by √v̂) but didn't really understand why they behave differently. So I created a prompt that generates animated visualizations of optimizers navigating a 2D loss landscape. Watching them move made the intuition click.\n\nThe Prompt:\n\n\"You are a visual learning tutor helping me understand optimization algorithms for CS182 (graduate deep learning at Berkeley). Your goal is to help me BUILD INTUITION through interactive visualizations, not just equations.\n\nRULES:\n\nFor every optimizer concept, generate RUNNABLE Python code that visualizes it\n\nBefore showing math, show me what the optimizer DOES on a 2D loss landscape\n\nAsk me to PREDICT what will happen before running the visualization\n\nAfter I see the visualization, ask me to explain WHY it behaved that way\n\nBuild up complexity: start with vanilla SGD, then add momentum, then Adam\n\nSTRUCTURE:\n\nPhase 1: Setup a 2D Loss Landscape\n\nGenerate code for a challenging 2D loss surface (e.g., Rosenbrock, Beale, or a ravine)\n\nVisualize it as a contour plot\n\nAsk me: \"Where do you think gradient descent will struggle on this surface? Why?\"\n\nPhase 2: Vanilla SGD\n\nAnimate SGD trajectory on the loss landscape\n\nShow the path it takes, step by step\n\nAsk me to explain what I observe (oscillation? slow convergence? why?)\n\nPhase 3: SGD + Momentum\n\nSame landscape, now with momentum\n\nAsk me to PREDICT how the trajectory will differ BEFORE showing me\n\nAnimate it, then ask: \"Why did momentum help/hurt here?\"\n\nVisualize the velocity vector at each step\n\nPhase 4: Adam\n\nSame landscape, now with Adam\n\nAsk me to predict the difference from momentum\n\nAnimate it, show the adaptive learning rates per dimension\n\nAsk: \"Why does Adam handle the ravine differently?\"\n\nPhase 5: Side-by-Side Comparison\n\nGenerate a single animation showing ALL THREE optimizers racing on the same landscape\n\nDifferent colors for each trajectory\n\nAsk: \"In what situations would you choose each optimizer?\"\n\nPhase 6: Pathological Cases\n\nShow me a landscape where momentum HURTS (overshooting)\n\nShow me a landscape where Adam struggles (sharp minima / generalization)\n\nAsk me to explain each failure mode\n\nREQUIREMENTS FOR CODE:\n\nUse matplotlib with animation (FuncAnimation) or generate frame-by-frame GIFs\n\nMake code self-contained and runnable in a Jupyter notebook or as a .py file\n\nInclude clear comments explaining each part\n\nUse a reasonable number of iterations so animations aren't too long (50-200 steps)\n\nContext: I understand gradient descent conceptually and know the optimizer update formulas, but I don't have intuition for WHY momentum/Adam behave differently in practice.\n\nStart with Phase 1 - generate the loss landscape and ask me your first question.\"\n\nKey Realizations\n\nThe \"predict → visualize → verify\" loop made this stick:\n\nThe \"effective learning rate\" plot was the money shot — seeing Adam automatically give 3x higher LR to the x-direction than y-direction made the adaptive denominator intuitive.\n\nAnalysis\n\nWhat worked:\n\nPredict-before-you-see forced me to actually think, not passively watch\n\nRunnable code means I can tweak parameters and re-run\n\nSide-by-side comparisons make differences obvious\n\nVelocity/LR plots explain why, not just what\n\nWhere it could improve:\n\nDidn't cover learning rate schedules or weight decay\n\nPathological cases (Phase 6) would strengthen understanding of failure modes\n\nCould add RMSprop as intermediate step before Adam\n\nInteresting finding: Momentum actually got lower final loss than Adam (0.0003 vs 0.0014) because its \"wild\" overshooting helped it explore. Adam's caution = less exploration. This is the exploration-exploitation tradeoff I'd only read about abstractly.\n\nFull Thread: https://claude.ai/share/71acabcd-b2eb-4e39-a424-12c8bdcda711\n\nAnnotated PDF: ",
    "attachments": [
      {
        "name": "Optimizer Visualization Annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/SG7RXrLifHO7I3gUHR7xXiPK"
      }
    ],
    "highlight": false,
    "summary": "I kept memorizing optimizer formulas (momentum accumulates velocity, Adam divides by √v̂) but didn't really understand why they behave differently. So I created a prompt that generates animated visualizations of optimizers navigating a 2D loss landscape. Watching them move made the intuition click."
  },
  {
    "id": "ed-7435450",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: State-Space Models (S4/Mamba)",
    "dek": "I was struggling to understand SSMs, the jump from RNNs to continuous-time systems to convolutions felt disconnected. So I created a Socratic prompt that forces the AI to ask questions instead of lect...",
    "student": "Rishi Thakar",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7435450"
    },
    "body_html": "I was struggling to understand SSMs, the jump from RNNs to continuous-time systems to convolutions felt disconnected. So I created a Socratic prompt that forces the AI to ask questions instead of lecturing. This made me actually derive the key insights myself rather than passively reading.\n\nThe Prompt:\n\n\"You are a Socratic tutor helping me understand State-Space Models (S4, Mamba) for CS182 (graduate deep learning at Berkeley).\n\nRULES:\n\nAsk me questions BEFORE explaining. Don't lecture—guide me to discover.\n\nBuild intuition FIRST with analogies, THEN introduce math.\n\nCheck my understanding at each step before proceeding.\n\nBe honest if something is uncertain or an open research question.\n\nAfter the core content, stress-test me with \"what would break if...\" questions.\n\nSTRUCTURE:\n\nPhase 1: Check what I know about RNNs and Transformers (prerequisites)\n\nPhase 2: Intuition for what problem SSMs solve and why\n\nPhase 3: The continuous-time formulation and discretization (with pauses for questions)\n\nPhase 4: The convolution trick (why we can parallelize training)\n\nPhase 5: Limitations and how Mamba addresses them\n\nPhase 6: Common misconceptions students have\n\nPhase 7: Give me 3 self-assessment questions (conceptual, mathematical, reasoning)\n\nContext: I understand RNNs, vanishing gradients, and attention. I haven't worked with differential equations in ML before.\n\nStart with Phase 1.\"\n\nKey Realization\n\nThe AI had me expand a linear recurrence manually:\n\nh₁ = A·h₀ + B·x₁ h₂ = A²h₀ + AB·x₁ + B·x₂ h₃ = A³h₀ + A²B·x₁ + AB·x₂ + B·x₃\n\nFrom this I realized: it's just a convolution with kernel [B, AB, A²B, ...]. Same model, two views , recurrence for inference, convolution for training. Deriving it myself made it click way better than lecture.\n\nAnalysis\n\nWhat worked well:\n\nSocratic approach forced active thinking instead of passive reading\n\nBuilt intuition before math (why SSMs exist → how they work)\n\nGood misconceptions section — I would've said \"O(n) training\" but it's actually O(n log n) due to FFT\n\nWhere it was incomplete:\n\nHiPPO mentioned but not explained mathematically\n\nParallel scan (Mamba's trick) glossed over\n\nNo code examples\n\nWhat I now understand:\n\nLinear recurrence = convolution (parallelizable via FFT)\n\nContinuous-time formulation enables principled initialization\n\nS4 = fixed kernel (LTI), Mamba = input-dependent (selective)\n\nLearnable Δ = learnable temporal resolution\n\nFull Thread: https://claude.ai/share/b2264d6f-874d-440d-a5e5-00157ed1b76b\n\nAnnotated PDF: \n\n",
    "attachments": [
      {
        "name": "State Space Models Annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/dgbaWdHjPVpkOxAgJEpQIvwe"
      }
    ],
    "highlight": false,
    "summary": "I was struggling to understand SSMs, the jump from RNNs to continuous-time systems to convolutions felt disconnected. So I created a Socratic prompt that forces the AI to ask questions instead of lecturing. This made me actually derive the key insights myself rather than passively reading."
  },
  {
    "id": "ed-7434807",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini 3 Pro Guided Learning on Diffusion (HW13)",
    "dek": "I utilized Gemini 3 Pro's Guided Learning mode with Thinking enabled to do the equivalent of pre-lecture readings/exploration to complete the problems on this homework assignment, which covers Diffusi...",
    "student": "Hiya Shah",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7434807"
    },
    "body_html": "I utilized Gemini 3 Pro's Guided Learning mode with Thinking enabled to do the equivalent of pre-lecture readings/exploration to complete the problems on this homework assignment, which covers Diffusion concepts from the last two lectures of the course. I aimed to learn an overview of the concepts I would need to know to tackle this homework, gain background on prerequisites, dive into the homework, and practice active recall/interaction with the homework. I also asked the model to explain some key misconceptions faced by students on these concepts, and I was surprised that it pointed out a key misconception I had on both RLHF and KL divergence while first attending lecture! I also asked it to generate a playground notebook, but it only prompted me to fill in pseudocode step by step (it was not able to generate the notebook in chat for download despite further prompting). I also asked it to search the internet for some other sample resources I could use to study diffusion, and it pointed me to a helpful Huggingface blog on Simplifying Alignment: From RLHF to Direct Preference Optimization (Search: Hugging Face DPO blog). However, it was not able to give me the exact link to click on (this may just be a consequence of the guided learning mode). In contrast, ChatGPT 5.1 immediately generated an ipynb notebook with follow up questions embedded inside it.\n\nannotated trace: \n\n\n\n",
    "attachments": [
      {
        "name": "special participation E diffusion.pdf",
        "url": "https://static.us.edusercontent.com/files/k0jnxP93oUy3BGbnMNUMTtjT"
      }
    ],
    "highlight": false,
    "summary": "I utilized Gemini 3 Pro's Guided Learning mode with Thinking enabled to do the equivalent of pre-lecture readings/exploration to complete the problems on this homework assignment, which covers Diffusion concepts from the last two lectures of the course."
  },
  {
    "id": "ed-7432931",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Interactive Diffusion Models Visualizer, Building Geometric Intuition",
    "dek": "Hi everyone!\n\nThe diffusion lectures introduced a lot of dense math: forward processes, reverse processes, score functions, DDPM vs DDIM, etc. I found it hard to develop intuition for what's actually ...",
    "student": "Elizabeth Weaver",
    "date": "2025-12-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7432931"
    },
    "body_html": "Hi everyone!\n\nThe diffusion lectures introduced a lot of dense math: forward processes, reverse processes, score functions, DDPM vs DDIM, etc. I found it hard to develop intuition for what's actually happening geometrically, so I built an interactive visualization tool using Claude to help understand these concepts.\n\n Link to Interactive Tool\n\nClick the link above to access the tool directly in Claude. You can interact with all the visualizations yourself!\n\nWhat This Tool Does\n\nThe visualizer helps you understand diffusion models through interactive 2D demonstrations:\n\n1. Forward Process Visualization\n\nWatch data points diffuse from structured distributions (moons, spirals, clusters) into Gaussian noise\n\nScrub through timesteps with a slider to see how signal and noise trade off\n\nSee the exact values of √ᾱₜ (signal) and √(1-ᾱₜ) (noise) at each step\n\n2. Reverse Process Visualization\n\nSee how following the score function brings noisy points back to the data manifold\n\nIncludes Bayes rule visualization showing why the reverse conditional is Gaussian\n\nUnderstand why we can start from pure noise and end up with structured samples\n\n3. Score Function Visualization\n\nView the score field ∇ₓ log p(x) as a vector field\n\nSee how the score changes from sharp/detailed (low noise) to smooth/uniform (high noise)\n\nIncludes density heatmap showing p(x) alongside the score vectors\n\n4. DDPM vs DDIM Comparison\n\nSee multiple sampling trajectories side-by-side\n\nDDPM: stochastic trajectories that diverge from the same starting noise\n\nDDIM: deterministic trajectories that always produce the same output\n\nResample to see how randomness affects DDPM but not DDIM\n\n5. Interactive Image Noise Demo\n\nApply the forward process to simple images (gradient, checkerboard, circle, face)\n\nWatch structure dissolve as t increases\n\nReference strip showing key timesteps side-by-side\n\n6. Interactive Manifold Diagram\n\nDrag a \"noisy sample\" point around high-dimensional space\n\nSee the score vector pointing toward the natural image manifold\n\nAnimate the denoising process following the score back to valid images\n\n7. Velocity Field Visualization\n\nSee the \"gas analogy\": particles flowing along streamlines\n\nConnects to the probability flow ODE perspective\n\n8. Comprehensive Quiz Bank (50+ questions)\n\nContext-aware quizzes that change based on which tab you're viewing\n\nQuestions derived from the diffusion paper covered in lecture\n\nCovers forward process, reverse process, score functions, and DDPM vs DDIM\n\nDetailed explanations for each answer\n\nTrack your score and review all explanations\n\nHow to Use This for Studying\n\nStart with the Forward Process tab: pick different distributions and watch how they diffuse. Notice how structure persists longer for some shapes than others.\n\n\n\nToggle on the Score Field: see how arrows point toward data at low noise but become uniform at high noise. This is the \"coarse-to-fine\" intuition.\n\n\n\nSwitch to Reverse Process: start from t=T and watch points flow back to the manifold. Check out the Bayes rule visualization to understand why the reverse process is Gaussian.\n\n\n\nTry the DDPM vs DDIM tab: resample multiple times and notice how DDPM gives different outputs while DDIM is deterministic.\n\n\n\nPlay with the Image Demo: this connects the 2D toy examples to real image generation.\n\n\n\nDrag points in the Manifold diagram: build intuition for how the score always points \"toward real images.\"\n\n\n\nTest yourself with the quizzes: each tab has 15-20 questions ranging from basic definitions to deeper conceptual understanding. The explanations are helpful even if you get the answer right!\n\n\n\nThe Prompt Engineering Process\n\nI worked with Claude Opus 4.5 to iteratively design this tool. Interestingly, I used Claude itself to help me create the prompt. I started by describing what I wanted (interactive diffusion visualizations with geometric intuition), and through back-and-forth conversation, Claude helped me refine the specifications into a detailed prompt. I then used that prompt in a fresh chat to generate the final tool.\n\nAfter sending the prompt to the new chat, I continued refining the visualization through several iterations:\n\nMade the Score Function tab distinct: Initially the Forward Process and Score Function tabs looked identical; I asked Claude to make the Score Function tab show a density heatmap with prominent score vectors instead of data points\n\nMade the manifold diagram interactive: The static manifold illustration became a draggable demo where you can move a \"noisy sample\" point and watch the score vector update, then animate the denoising trajectory\n\nAdded DDPM vs DDIM comparison: I provided the diffusion paper and asked Claude to add visualizations explaining the math, which led to the side-by-side trajectory comparison showing stochastic vs deterministic sampling\n\nAdded Bayes rule and velocity field visualizations: These help explain why the reverse process is Gaussian and connect to the \"gas analogy\" from the paper\n\nMade the image noise demo interactive: Added a slider to control the noise level and a play/pause animation\n\nReorganized the layout: I attempted to move the image demo and manifold sections to the top of the right panel so the intuitive examples are immediately visible alongside the main visualizer, but this is not shown in the visualization \n\nThe model failed here\n\nAdded the quiz section: Started with regeneratable random questions, then switched to showing all questions at once\n\nExpanded and curated quiz questions: Added more technical questions based on the paper, then removed advanced topics (classifier-free guidance, v-prediction, consistency distillation, etc.) that weren't covered in the paper or lecture\n\nAn issue here was that the paper was no longer in the uploads for the chat, and I couldn’t upload it without reaching the length limit. Therefore I think Claude ended up using mostly its own knowledge here.\n\nThe key insights for the prompt:\n\nStart with educational goals: what specific confusions should this address?\n\nSpecify the math precisely: include the actual equations (β schedule, ᾱₜ, forward/reverse formulas)\n\nRequest multiple linked visualizations: 2D toy distributions, actual images, and conceptual diagrams reinforce each other\n\nAsk for interactivity: sliders, toggles, and draggable elements let you explore parameter space\n\nInclude dynamic explanations: text that changes based on the current timestep helps connect visuals to concepts\n\nProvide source material: I gave Claude the diffusion paper we're covering in lecture, which helped generate accurate quiz questions and mathematical explanations\n\nAdd self-assessment: quiz questions with detailed explanations help solidify understanding\n\nIterate and curate: Review generated content against source material to remove anything beyond scope\n\nThe full prompt I used is provided at the end.\n\nCritical Annotations\n\nHere's my honest assessment of the tool:\n\nWhat works well:\n\nThe forward/reverse process visualizations clearly show the signal/noise tradeoff\n\nScore field visualization makes the \"pointing toward data\" intuition concrete\n\nDDPM vs DDIM comparison is very effective: you can immediately see the stochasticity difference\n\nThe interactive manifold diagram is great for building intuition about high-dimensional geometry\n\nStats display (√ᾱₜ, √(1-ᾱₜ)) keeps you grounded in the actual math\n\nThe quiz questions are well-calibrated and the explanations are helpful\n\nVelocity field visualization connects nicely to the probability flow ODE / flow matching perspective\n\nPotential issues / limitations:\n\nThe score field is approximated using kernel density estimation, not a learned neural network. This is pedagogically useful but not exactly what happens in practice\n\nThe 2D visualizations are toy examples; real diffusion operates in ~200,000 dimensions for images, where geometry behaves very differently\n\nThe \"image\" demo uses a tiny 12×12 grid, which oversimplifies the complexity of real image diffusion\n\nThe Bayes rule visualization uses a simplified 1D example; the actual derivation involves more careful analysis of the Gaussian conditionals\n\nTrajectory simulations use simplified dynamics, real DDPM/DDIM have more nuanced update rules\n\nGenerally, Claude Opus 4.5 struggled a lot more with creating this tool than I expected\n\nThe final result is good, but it took more chats than I thought it would\n\nImportant note about the quiz questions:\n\nThe only material I gave the model to generate the quiz questions, besides what it already knew about diffusion, was the paper we were building off of in class\n\nThis means some questions may use slightly different notation or framing than what was presented in class\n\nSome questions may cover details from the paper that weren't emphasized in lecture\n\nUse these questions to deepen your understanding of the paper's perspective, but cross-reference with lecture notes and the homework for exam-specific material\n\nMinor technical notes:\n\nThe DDPM/DDIM trajectory simulation uses a simplified score-based update rather than the exact DDPM/DDIM formulas, but the qualitative behavior (stochastic vs deterministic) is correct\n\nThe velocity field shows E[x₀|xₜ] - xₜ direction, which is related to but not exactly the probability flow ODE velocity\n\nQuestions for Discussion\n\nAfter playing with the tool, consider:\n\nWhy does the score field become more uniform as noise increases? What does this mean for early vs. late denoising steps?\n\n\n\nIn the DDPM vs DDIM comparison, both methods use the same learned score function. Why does adding noise during sampling (DDPM) lead to diversity while removing it (DDIM) leads to determinism?\n\n\n\nThe manifold diagram suggests the score \"points toward real images.\" But in 200,000 dimensions, what does \"toward\" even mean? How does the network learn this direction?\n\n\n\nThe quiz questions are based on the diffusion paper. Did you notice any differences in notation or framing compared to how concepts were presented in lecture?\n\n\n\nHope this helps with studying! The quiz section has 50+ questions across all four topics, so there's plenty to work through. Let me know if you have questions or find any errors in the explanations.\n\nI've added in the prompt, annotated prompt generation chat, and the annotated visualization creation chat below. Hopefully this method could be used to generate visualizations for other concepts as well!",
    "attachments": [
      {
        "name": "diffusion-visualizer-prompt.md",
        "url": "https://static.us.edusercontent.com/files/2B9JUT1I4BsFHGPeMXEJsxAn"
      },
      {
        "name": "Claude-AI tutor for critical feedback on explanations.pdf",
        "url": "https://static.us.edusercontent.com/files/2dMVsmBjvycfcmtIjAkdAbOs"
      },
      {
        "name": "Claude-React component single file.pdf",
        "url": "https://static.us.edusercontent.com/files/G4fa5dowqlveNJatkb5wo4Ex"
      }
    ],
    "highlight": false,
    "summary": "The diffusion lectures introduced a lot of dense math: forward processes, reverse processes, score functions, DDPM vs DDIM, etc. I found it hard to develop intuition for what's actually happening geometrically, so I built an interactive visualization tool using Claude to help understand these concepts."
  },
  {
    "id": "ed-7431475",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Cross-Class Resource Comparison",
    "dek": "Something that is true about many students in this class is that they are simultaneously enrolled in non-orthogonal classes (e.g. 180, 183, etc.) with overlapping topics. Nietzsche famously writes: “t...",
    "student": "Kevin Tseng",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7431475"
    },
    "body_html": "Something that is true about many students in this class is that they are simultaneously enrolled in non-orthogonal classes (e.g. 180, 183, etc.) with overlapping topics. Nietzsche famously writes: “the more affects we allow to speak about one thing, the more eyes, different eyes, we can use to observe one thing, the more complete will our ‘concept’ of this thing, our ‘objectivity,’ be.” In this spirit, it might be useful for someone enrolled in these classes to figure out what is similar to do things like plan studying, clarify differing notation, compare perspectives, find differences in information content, and so on.\n\nI provide prompts for the comparison of overlapping course material from different classes and a trace of me using theme to try to gain educational value. I imagine that these would be best using lecture transcripts but I use slides for ease of access.\n\nI generated these prompts using GPT-5.1. Two traces of 182 vs 183 and 182 vs 180 conversations with Claude Sonnet 4.5 are attached as well.\n\nSYSTEM INSTRUCTIONS (include in prompt exactly):\n\nYou are an educational analysis assistant.\n Your task is to compare overlapping topics across two or more university courses.\n You must:\nCompare concepts across classes with precision (not generic summaries).\n\n\nIdentify differences in emphasis, definitions, assumptions, and notation.\n\n\nContrast problem-solving methodologies taught in each course.\n\n\nPoint out conceptual or pedagogical conflicts between the classes.\n\n\nExplain how a student should adapt their reasoning when switching contexts.\n\n\nExplicitly state when you are uncertain, when something may be hallucinated, or when sources conflict.\n\n\nList concrete examples or exercises that illustrate differences.\n\n\nIf a topic is unclear or ambiguous, you must request clarification rather than fabricate.\n\n\nUSER INSTRUCTIONS (you fill these in when you run the prompt):\n\nI am taking the following courses this semester:\n\nCourse A: [insert course name, e.g. CS 182 – Deep Learning]\n\nCourse B: [insert course name, e.g. CS 189 – Machine Learning]\n(Optional)\n\nCourse C: [insert additional course, e.g. EECS 127 – Optimization]\n\nI want you to compare the following topic(s) across these classes:\n\nTopic(s): [e.g. gradient descent, cross-entropy, overfitting, regularization]\n\nPlease perform the comparison using the following structure:\n\n1. Definitions & Formalism\n\nHow each class defines the concept\n\nNotation differences\n\nUnderlying assumptions\n\n2. Conceptual Goals of Each Course\n\nWhy each class teaches this concept\n\nDepth vs breadth\n\nWhether each course treats the concept theoretically, heuristically, or operationally\n\n3. Methodological Differences\n\nAlgorithms emphasized in each\n\nDifferences in derivations or interpretations\n\nProblem-solving styles expected in homework/exams\n\n4. Conflicts or Divergences\n\nCommon student misconceptions when transferring knowledge between courses\n\nWhere the classes disagree in framing or intuition\n\n5. Complementary Strengths\n\nWhat perspective each course adds\n\nHow understanding from one course deepens knowledge in another\n\n6. Study Strategy Recommendations\n\nHow to integrate the perspectives\n\nHow to avoid context-specific misunderstandings\n\nHow to create a unified mental model\n\n7. Hallucination Check\n\nFor each major claim:\n\nMark [Certain], [Plausible but check course materials], or [Uncertain].\n\nIf you are unsure about anything or lack information, state it explicitly instead of guessing.\n",
    "attachments": [
      {
        "name": "spec_participation_e.pdf",
        "url": "https://static.us.edusercontent.com/files/rGbYrbk7mPGMzsI9ZLuq2dkW"
      }
    ],
    "highlight": false,
    "summary": "Something that is true about many students in this class is that they are simultaneously enrolled in non-orthogonal classes (e.g. 180, 183, etc.) with overlapping topics. Nietzsche famously writes: “the more affects we allow to speak about one thing, the more eyes, different eyes, we can use to observe one thing, the more complete will our ‘concept’ of this thing, our ‘objectivity,’ be."
  },
  {
    "id": "ed-7431297",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: NotebookLM Quiz for Diffusion",
    "dek": "I used NotebookLM to make quizzes on the diffusion lectures in preparation for the final. I found the diffusion concepts to be very confusing mathematically, even though I felt like I had a good overa...",
    "student": "Tyler Pham",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7431297"
    },
    "body_html": "I used NotebookLM to make quizzes on the diffusion lectures in preparation for the final. I found the diffusion concepts to be very confusing mathematically, even though I felt like I had a good overall conceptual understanding. \n\nAt first, I tried making a slideshow with NotebookLM to help connect the heavy math to the overarching concepts about diffusion. However, I found that the slides are too simple and often have more goofy designs and shapes that are unnecessary for a college-level course. Hence, I made a thorough quiz with it instead to gauge my understanding of diffusion. Since I wanted to focus on the more math-heavy concepts of diffusion, I specifically prompted with:\n\nFocus on more in-depth, technical concepts like the conditional probabilities, mu vs x, the math behind the reverse process, etc. rather than basic high-level ideas like what the denoiser does. The questions should be long and detailed, as if at the graduate level.\n\nNotebookLM generated pretty helpful questions that weren't too high-level. Even more helpful was the \"Explain\" button so that you can explain the answer even when you get it right. NotebookLM’s explanations were quite insightful and helpful in further explaining confusing concepts that it quizzed me about. It mostly kept its explanations related to what was contained in the lecture notes, but expanded very well by going in-depth on concepts like the score function and even making connections back to the data manifold mentioned just at the start of the notes. This was very helpful in clearing my misconceptions both mathematically and conceptually in preparation for the final.\n\nNotebookLM Link: https://notebooklm.google.com/notebook/ee93c429-727a-4431-9649-609388e5af3a\n\nAnnotated Trace:",
    "attachments": [
      {
        "name": "diffusion_quiz_chat.pdf",
        "url": "https://static.us.edusercontent.com/files/RrtTMujClRV4zntlXe9V2p3A"
      }
    ],
    "highlight": false,
    "summary": "I used NotebookLM to make quizzes on the diffusion lectures in preparation for the final. I found the diffusion concepts to be very confusing mathematically, even though I felt like I had a good overall conceptual understanding."
  },
  {
    "id": "ed-7431178",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Learning DDPM from GPT as a tutor",
    "dek": "For this Special Participation E, I built an interactive DDPM (diffusion) tutor using a custom prompt in ChatGPT’s Study Mode.\n\nThe tutor walks through the standard DDPM pipeline in four modules: (1) ...",
    "student": "John Wang",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7431178",
      "chatgpt": "https://chatgpt.com/share/69368380-c428-800e-9481-c415a96d1deb"
    },
    "body_html": "For this Special Participation E, I built an interactive DDPM (diffusion) tutor using a custom prompt in ChatGPT’s Study Mode.\n\nThe tutor walks through the standard DDPM pipeline in four modules: (1) the forward noising process and the closed-form q(x_t | x_0), (2) the reverse process p_θ(x_{t-1} | x_t) and noise prediction ε_θ(x_t, t), (3) the simplified “MSE on noise” training objective that comes from the ELBO / Gaussian KLs, (4) the sampling loop (from x_T ~ N(0, I) back to x_0), plus simple variants like DDIM and classifier-free guidance.\n\nIn each module, the tutor:\n\nexplains the intuition and minimal formulas,\n\nasks me concept-check questions,\n\nand gives a slightly flawed statement for me to critique (e.g., “q(x_t | x_0) always has mean zero,” “perfect ε-prediction still produces blurry samples,” or “training only at t=1 is enough”).\n\nThis makes the interaction feel more like a guided oral exam than just reading the DDPM paper again. It helped me straighten out the roles of q(x_t | x_0), p_θ, the noise schedule, and the training loss, and forced me to actively explain and defend my answers instead of passively skimming notes.\n\nFull conversation (with the custom tutor prompt and my answers) is here: https://chatgpt.com/share/69368380-c428-800e-9481-c415a96d1deb\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "For this Special Participation E, I built an interactive DDPM (diffusion) tutor using a custom prompt in ChatGPT’s Study Mode."
  },
  {
    "id": "ed-7431040",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Conceptual Connections Between Disparate Lectures",
    "dek": "Oftentimes, which focused solely on absorbing the material in a class, it is easy to lose sight of the larger connections that tie a topic or field together. An analogy could be a music student that i...",
    "student": "Daniel Kao",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7431040"
    },
    "body_html": "Oftentimes, which focused solely on absorbing the material in a class, it is easy to lose sight of the larger connections that tie a topic or field together. An analogy could be a music student that is so focused on getting the notes of a piece right that they fail to internalize the structure of the musical piece as a whole. In a class like CS 182, where concepts naturally build upon one another, it is especially important to always be able to \"hear the music.\"  As such, I thought it would be illuminating to have a conversation with Deepseek about the connections between two lectures in this course that are months apart, as a way to gain insight on the broader view of the course and Deep learning as a whole. \n\nThis is a link to the annotated trace of the conversation.\n\nOverall, I think the model did a great job in identifying and explaining high level connections between the topics. I was presented with some obvious insights, but also a few connections that I had not made before. When I tried to prompt the model into making untrue connections, it resisted the faulty categorization, which I was pleasantly surprised by. To me it seems that these types of high-level topical natural language conversations play to the the strengths of LLMs, and can be a helpful learning tool for broad understanding of a field.",
    "attachments": [],
    "highlight": false,
    "summary": "Oftentimes, which focused solely on absorbing the material in a class, it is easy to lose sight of the larger connections that tie a topic or field together. An analogy could be a music student that is so focused on getting the notes of a piece right that they fail to internalize the structure of the musical piece as a whole."
  },
  {
    "id": "ed-7431036",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: NotebookLM for Reviewing GNNs",
    "dek": "Here, I used NotebookLM to review GNNs comprehensively. I had never used it before, so this was a new experience and I was doing a mix of trying to learn about things I didn't understand, as well as t...",
    "student": "Akhil Agarwal",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7431036"
    },
    "body_html": "Here, I used NotebookLM to review GNNs comprehensively. I had never used it before, so this was a new experience and I was doing a mix of trying to learn about things I didn't understand, as well as testing its capabilities. I uploaded the lecture notes for both lectures covering GNNs, as well as the transcripts copy-pasted from YouTube for those two lectures. Overall, I was extremely impressed by its performance. First, the mindmap was good, but when it generated the quiz I was far more impressed. The quiz comprehensively reviewed the entire topic of GNNs (conceptually), and all of the answer choices were very related to the correct answer and the topic. Some of the questions were easy for me, while others challenged me more (I actually got 1 wrong as well, which I asked the model about, which was more of a nomenclature question, where it asked about what a concept was). When I asked it to explain why I got it wrong, it responded well, and explained the concept in depth, along with its motivation. Then, I asked it some more questions about the applications of GNNs and types of aggregation functions. It did well while talking about the things in the sources. However, when I dug further, it was limited in its scope by what was in the sources that I uploaded, so I found that while NotebookLM is an amazing resource in understanding the content you upload, it won't be able to help too much beyond that, and it may be beneficial to give it many sources about the topic to help it have more background. The video it made to explain the concepts was actually very good, which I was not expecting, and it covered the entire content nicely. The way it explained the concepts without being very robotic and being more \"human\" / having imperfect wordings also helped.\n\nOverall, it was a great experience, and I will definitely be using NotebookLM again, though I'll be adding as many sources as possible if I want to ask questions out of scope of the main content.\n\nNotebookLM chat: https://notebooklm.google.com/notebook/7772f54e-0aaa-45d3-9d57-08c968c212d5\n\nAnnotated chat trace:",
    "attachments": [
      {
        "name": "Special_Participation_E2.pdf",
        "url": "https://static.us.edusercontent.com/files/0CSoSZb6lpDqvp3BSg2X5IZS"
      }
    ],
    "highlight": false,
    "summary": "Here, I used NotebookLM to review GNNs comprehensively. I had never used it before, so this was a new experience and I was doing a mix of trying to learn about things I didn't understand, as well as testing its capabilities. I uploaded the lecture notes for both lectures covering GNNs, as well as the transcripts copy-pasted from YouTube for those two lectures."
  },
  {
    "id": "ed-7430957",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Gamified approach to Optimization intuition with Gemini pro 3",
    "dek": "Hi all,\n\nI created an AI enhanced learning tool that builds practical intuition through a prediction to feedback loop. With this tool, you make predictions about training outcomes before seeing what h...",
    "student": "Imra Dawoodani",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430957"
    },
    "body_html": "Hi all,\n\nI created an AI enhanced learning tool that builds practical intuition through a prediction to feedback loop. With this tool, you make predictions about training outcomes before seeing what happens. \n\nHeres the Custom Gem:\n\nhttps://gemini.google.com/gem/13_Hu4zQ4ZCJogAYCsbFxBjz3MASNlj7t?usp=sharing \n\nAnnotated Trace of my conversation:\n\nMy findings:\n",
    "attachments": [
      {
        "name": "gemini.google.com-Gemini-fpscreenshot.pdf",
        "url": "https://static.us.edusercontent.com/files/C6xJzt8KDTnr29ttqa8vVUXz"
      },
      {
        "name": "special participation e - predict before you learn.pdf",
        "url": "https://static.us.edusercontent.com/files/Pnasxc0MeaF8NhbycsPw4Nnu"
      }
    ],
    "highlight": false,
    "summary": "I created an AI enhanced learning tool that builds practical intuition through a prediction to feedback loop. With this tool, you make predictions about training outcomes before seeing what happens."
  },
  {
    "id": "ed-7430953",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E:  Simple DiffPool Visualizer",
    "dek": "I made a very small Jupyter notebook called diffpool_visualizer.ipynb that acts as a conceptual DiffPool visualizer. Instead of training a big GNN, it focuses only on the core DiffPool step:\n\nWe build...",
    "student": "Aryan Bansal",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430953"
    },
    "body_html": "I made a very small Jupyter notebook called diffpool_visualizer.ipynb that acts as a conceptual DiffPool visualizer. Instead of training a big GNN, it focuses only on the core DiffPool step:\n\nWe build a tiny toy graph (two triangles connected by a bridge).\n\nWe define a soft assignment matrix S from nodes to clusters (what DiffPool would learn in practice).\n\nWe compute:\n\nNew cluster features \n\n$$X_{pooled}=S^TX$$\n\nA coarsened adjacency \n\n$$A_{pooled}=S^TAS$$\n\nWe then visualize three things side by side:\n\nOriginal graph: each node is colored by how strongly it belongs to a chosen cluster (you can switch clusters with a slider).\n\nAssignment matrix S: shown as a heatmap (rows = nodes, columns = clusters).\n\nCoarsened graph: a tiny graph whose nodes are clusters, with edge thickness showing how strongly clusters are connected.\n\nHow to use it\n\nOpen diffpool_visualizer.ipynb in a Jupyter environment.\n\nRun all cells.\n\nUse the cluster index slider under the last cell:\n\nWatch how the colors on the original graph change as you switch clusters.\n\nCompare that to the corresponding column in the assignment matrix S.\n\nLook at how many cluster nodes there are and how they are connected in the coarsened graph.\n\n",
    "attachments": [
      {
        "name": "diffpool_visualizer.ipynb",
        "url": "https://static.us.edusercontent.com/files/RfrXZqJW6ydpOndadiwXDrs8"
      }
    ],
    "highlight": false,
    "summary": "I made a very small Jupyter notebook called diffpool_visualizer.ipynb that acts as a conceptual DiffPool visualizer. Instead of training a big GNN, it focuses only on the core DiffPool step:"
  },
  {
    "id": "ed-7430788",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Using ChatGPT to surface what you don't know",
    "dek": "For this assignment, I wanted to create a question generator of some kind. Instead of having the model explain the lecture to me, I flipped the direction and had it act as an “office hour simulator” w...",
    "student": "Jermaine Lei",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430788"
    },
    "body_html": "For this assignment, I wanted to create a question generator of some kind. Instead of having the model explain the lecture to me, I flipped the direction and had it act as an “office hour simulator” where the model acts like a line of students asking questions about the lecture. The main idea was to surface the things I don’t know and wouldn’t think to ask on my own. Sometimes it’s really hard to pinpoint your own gaps in understanding so having the model generate realistic, conceptual, and mechanic-focused questions and even tweak baseline assumptions to test whether I truly understood the concepts felt like a unique way to self-check my knowledge. In order to make this work, I’ve created 2 prompts. \n\nThe first one:\n\nThe reason for adding the 3 different types of questions was to maximize the chances that the model would generate a conceptual question that hits an area of understanding that you may lack. After answering the questions in bullet point fashion, the second prompt generates its own “truth” response and compares it to yours:\n\nThe main goal of this second prompt is to identify where your answer lacks some more concrete reasoning/information. This is helpful because even if the model identifies a missing piece of your response that you already know, seeing that missing piece connect to the rest of your answer can reinforce your understanding of the topic.\n\nIn my example, I use the lecture 7 slides. The model’s student questions captured the tone and content of real confusion points. It asked about how the updates work, how the SVD pieces fit together, and how different assumptions would change the behavior of the algorithm. These kinds of questions immediately showed which parts of the lecture I understood well and which parts I was glossing over, and answering them myself first made those gaps obvious when the model later switched into instructor mode and filled in the missing steps.\n\nOverall, this turned out to be a genuinely useful learning tool. The model kept everything grounded in the lecture notes while still giving enough detail to strengthen my understanding, and its critiques helped sharpen my answers rather than just telling me they were wrong. Most importantly, this setup pushed me into a kind of deeper reasoning practice that is hard to create on my own because it required me to articulate ideas clearly, check my logic, and confront misunderstandings I did not realize I had. As a post-lecture study method, I would definitely use this approach again.\n\n\nHere is my annotated chat conversation using Lecture 7 as an example:",
    "attachments": [
      {
        "name": "prompt_1.txt",
        "url": "https://static.us.edusercontent.com/files/WZeH73JhAb6F1IL2s6N6C6r0"
      },
      {
        "name": "prompt_2.txt",
        "url": "https://static.us.edusercontent.com/files/JUuib136CPyKgnursWEpHafZ"
      },
      {
        "name": "OfficeHourSimulChat.pdf",
        "url": "https://static.us.edusercontent.com/files/xoHo8dlUrPjl9FbxojkZYCwU"
      }
    ],
    "highlight": false,
    "summary": "For this assignment, I wanted to create a question generator of some kind. Instead of having the model explain the lecture to me, I flipped the direction and had it act as an “office hour simulator” where the model acts like a line of students asking questions about the lecture. The main idea was to surface the things I don’t know and wouldn’t think to ask on my own."
  },
  {
    "id": "ed-7430787",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: review of the homework topics Hw6 and discussion 7",
    "dek": "In this special participation, I created this prompt to review all the sections of the homework in an easy and dynamic way to make sure I don’t have questions about things mentioned and not mentioned ...",
    "student": "Gustavo Jose Ortiz Zepeda",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430787"
    },
    "body_html": "In this special participation, I created this prompt to review all the sections of the homework in an easy and dynamic way to make sure I don’t have questions about things mentioned and not mentioned in the homework and discussion.\n\nI was really impressed with the questions asked because they were very broad in terms of the topics covered and even some were really tricky. They are all multiple-choice, so you can do the test while riding the BART or during any free moment and keep making progress.\n\nPrompt: I want to review the topics mentioned on this homework, let's make two things, first a refresh of all the concepts explained as detailed as possible and then connected with each other if applies. Now we have the big picture, let's do some simple examples so it is easier to remember and make a better understanding of them. And finally let's do a quiz of at least 30 (could be much more if many wrong answers) multiple choice questions in which we review each topic starting from easy questions and level up if correct answers and downgrade the level if incorrect answers (also giving an explanation of the possible confusion and reviewing the concepts needed to explain the correct answer).",
    "attachments": [
      {
        "name": "Special Participation E-2.pdf",
        "url": "https://static.us.edusercontent.com/files/xMRfWOySPgQORl9pGfecsHvv"
      }
    ],
    "highlight": false,
    "summary": "In this special participation, I created this prompt to review all the sections of the homework in an easy and dynamic way to make sure I don’t have questions about things mentioned and not mentioned in the homework and discussion."
  },
  {
    "id": "ed-7430783",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Using ChatGPT to Generate Learning guides for a Teacher's Style",
    "dek": "An issue I often run into when first encountering a lecturer is adapting to the given teaching style. For example, some teachers may prefer to give a higher level theoretical overview of a subject, wh...",
    "student": "Daniel Kao",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430783"
    },
    "body_html": "An issue I often run into when first encountering a lecturer is adapting to the given teaching style. For example, some teachers may prefer to give a higher level theoretical overview of a subject, while others are more interested in showing students how to empirically solve problems with examples. Perhaps there a teacher introduces a lot of definitions at the beginning of a class and it is thus imperative to write them down to continue learning. These are aspects I slowly adapt to as I get more familiar with a teacher, but there is often a whiplash effect when going from one teaching style to another, especially when browsing the internet for explanations.\n\nAs such, my goal is to create a system prompt to make LLM's analyze an excerpt of a teacher's lecture and generate a learning guide, quickly identifying the key aspects of the lecture style and content. Attached is the system prompt itself, as well as 2 sample transcripts: One is from the CS182 Lecture on Sign SGD, Shampoo, muP and muon, and the second one (just for fun) is a transcript from Terence Tao's lecture on the gaps between prime numbers (here is the youtube link for those interested).\n\nHere is the link to the PDF of my annotated trace, generating a learning guide for the CS182 Lecture\n\nOverall, I found the tool to be quite useful. For example, it was able to identify the importance of EECS 127 to the course material of this class simply through the context of the lecture, and gave helpful suggestions like drawing diagrams by hand and asking yourself conceptual questions. There are definitely limitations to the tool though, for example most context windows cannot fit an entire lecture's transcript and thus the tool is best used on an excerpt. Furthermore, the model does not receive any visual data, and is thus limited in its ability to comment on expressiveness, visual examples etc. Hope you all find this helpful!",
    "attachments": [
      {
        "name": "Daniel Kao Special Participation E_ Learning Guide.pdf",
        "url": "https://static.us.edusercontent.com/files/g41m4UL06Hs1tyaNYAOFCqNp"
      }
    ],
    "highlight": false,
    "summary": "An issue I often run into when first encountering a lecturer is adapting to the given teaching style. For example, some teachers may prefer to give a higher level theoretical overview of a subject, while others are more interested in showing students how to empirically solve problems with examples."
  },
  {
    "id": "ed-7430552",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Equation Intuition Annotator",
    "dek": "I used Claude’s Artifacts to vibe code an equation annotator to help gain intuition for how often monstrous equations work. I think you need a Claude account to use the actual artifact, but you can re...",
    "student": "Kevin Tseng",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430552"
    },
    "body_html": "I used Claude’s Artifacts to vibe code an equation annotator to help gain intuition for how often monstrous equations work. I think you need a Claude account to use the actual artifact, but you can replicate this by feeding the same prompt to a chatbot instead of using my tool to send an API request.\n\nThe link to use it is here\n\nhttps://claude.ai/public/artifacts/4a9d7ab1-dbcc-44fc-b0e7-3afe1e45f38d\n\nHere is the prompt if you want to use an image of an equation:\n\nI've uploaded an image containing a deep learning equation. Please identify the equation and provide a breakdown with these sections:\n\n1. WHAT IT IS: One sentence describing what this equation represents\n2. SYMBOL BREAKDOWN: Explain each symbol/term and what it represents intuitively\n3. WHY IT WORKS: Explain the intuition behind why this formulation makes sense\n4. WHAT IF WE CHANGE THINGS: For each major variable/parameter, explain what happens when you:\n   - Increase it\n   - Decrease it\n   - Set it to zero (if applicable)\n   - Remove it entirely\n5. COMMON MISCONCEPTIONS: What do students often get wrong about this?\n6. VISUAL INTUITION: Describe a geometric or visual way to think about this\n\nUse LaTeX formatting for any mathematical expressions (use $ for inline math and $ for display math).\nBe concise, intuitive, and focus on building understanding rather than just stating facts.\n\n\n\nHere is the prompt if you want to type an equation:\n\nI've uploaded an image containing a deep learning equation. Please identify the equation and provide a breakdown with these sections:\n\n1. WHAT IT IS: One sentence describing what this equation represents\n2. SYMBOL BREAKDOWN: Explain each symbol/term and what it represents intuitively\n3. WHY IT WORKS: Explain the intuition behind why this formulation makes sense\n4. WHAT IF WE CHANGE THINGS: For each major variable/parameter, explain what happens when you:\n   - Increase it\n   - Decrease it\n   - Set it to zero (if applicable)\n   - Remove it entirely\n5. COMMON MISCONCEPTIONS: What do students often get wrong about this?\n6. VISUAL INTUITION: Describe a geometric or visual way to think about this\n\nUse LaTeX formatting for any mathematical expressions (use $ for inline math and $ for display math).\nBe concise, intuitive, and focus on building understanding rather than just stating facts.\n\n\n\nAttached is a pdf with some example traces of its use:\n\n",
    "attachments": [
      {
        "name": "Special Participation E_ Equation Intuition Annotator.pdf",
        "url": "https://static.us.edusercontent.com/files/jLJOMJQLuWeIpBsemSIItt0P"
      }
    ],
    "highlight": false,
    "summary": "I used Claude’s Artifacts to vibe code an equation annotator to help gain intuition for how often monstrous equations work. I think you need a Claude account to use the actual artifact, but you can replicate this by feeding the same prompt to a chatbot instead of using my tool to send an API request."
  },
  {
    "id": "ed-7430420",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: NotebookLM-based HW3 Final Review Notebook",
    "dek": "For this (E) participation, I built a small AI-enhanced review tool for HW3 using Google’s NotebookLM in notebook mode. I created a notebook and uploaded three resources: the HW3 PDF, the official HW3...",
    "student": "John Wang",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430420"
    },
    "body_html": "For this (E) participation, I built a small AI-enhanced review tool for HW3 using Google’s NotebookLM in notebook mode. I created a notebook and uploaded three resources: the HW3 PDF, the official HW3 solutions, and a short HW3 review slide deck I made from the solutions. In Phase 1, I asked NotebookLM to generate a slide-style summary of HW3 (grouped by topics like Gaussian initialization, RMS/RMS norms, sign-SGD updates, µP scaling, and policy gradient/reparameterization). In Phase 2, I re-uploaded the refined slides and used a second prompt to generate a ~5–10 minute low-detail audio overview that walks through these slides. I listened to the audio while following along with the slides as a fast, multi-modal “big picture” recap before the final.\n\nIn Phase 3, I switched to an interactive, problem-centered dialogue inside the same notebook. Using only the uploaded HW3 + solution PDFs, I asked NotebookLM to (1) explain what a specific question (e.g., HW3 Q1) is really testing, (2) walk through the official solution step by step, and (3) propose exam-style variants that test the same underlying idea. I’ve attached my prompts and an annotated interaction trace for Q1, where I explicitly mark places where the explanations are genuinely helpful (e.g., why the expected RMS depends on d1​ but not d2​) and places where the comments about µP scaling are oversimplified or slightly misleading. Classmates can recreate the same NotebookLM setup (upload HW3 + solutions + slides, paste the prompts) and use it as a structured, post-homework, pre-final review environment for HW3.",
    "attachments": [
      {
        "name": "Participation E.pdf",
        "url": "https://static.us.edusercontent.com/files/mUNqQLsGccsCkMioNe12L0Oj"
      }
    ],
    "highlight": false,
    "summary": "For this (E) participation, I built a small AI-enhanced review tool for HW3 using Google’s NotebookLM in notebook mode. I created a notebook and uploaded three resources: the HW3 PDF, the official HW3 solutions, and a short HW3 review slide deck I made from the solutions."
  },
  {
    "id": "ed-7430296",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT Study mode on MAML",
    "dek": "I used ChatGPT's study mode to better understand MAML. I've attached an annotated transcript of my conversation.\n\n\n\nHere are some things I found interesting:\n1. Here around, ChatGPT was very methodica...",
    "student": "Ayush Goel",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430296"
    },
    "body_html": "I used ChatGPT's study mode to better understand MAML. I've attached an annotated transcript of my conversation.\n\n\n\nHere are some things I found interesting:\n1. Here around, ChatGPT was very methodical about explaining MAML. It didn't dump the entire setup and explanation of MAML at once, but moved on one step at a time, followed by a cross check question at every step to make sure I was on the same page.\n\n2. ChatGPT brought up interesting points about second order gradients being implicitly computed which I hadn't thought about when I was learning MAML via lecture.\n\n3. ChatGPT also brought up first order MAML as a more practical alternative. This was very nice to see and learn about as it goes beyond the scope of what it asked, but provided very useful context for if I were to every try implementing MAML.\n\n4. I didn't fully understand how first order MAML was different from multitask learning, and ChatGPT was able to come up with a numerical and visual example. This very clearly illustrated the differences in solutions arrived at by the different methods. Here, the visualization had some mistakes (the plotting wasn't exactly correct), but for the most part this didn't impact my understanding of the topic.",
    "attachments": [
      {
        "name": "maml_gpt_study.pdf",
        "url": "https://static.us.edusercontent.com/files/3L4l09u7BaAAp5bG3Rc8C0gV"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT's study mode to better understand MAML. I've attached an annotated transcript of my conversation."
  },
  {
    "id": "ed-7430233",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: AI-Enhanced Learning Artifact: The GPT-2 \"Logit Lens\" with Cursor",
    "dek": "1. Prompt Strategy \n\nI acted as a \"Technical Lead\" and prompted the AI (Cursor/Gemini) to write a PyTorch + Streamlit script.\n\nPrompt: \"Write a Python script using Streamlit and HuggingFace that imple...",
    "student": "Ijin Yu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430233"
    },
    "body_html": "1. Prompt Strategy \n\nI acted as a \"Technical Lead\" and prompted the AI (Cursor/Gemini) to write a PyTorch + Streamlit script.\n\nPrompt: \"Write a Python script using Streamlit and HuggingFace that implements a 'Logit Lens' for GPT-2. It should hook into every transformer layer, apply the unembedding matrix to the hidden states, and visualize the top-3 predicted tokens at each stage to show how the model's confidence evolves.\"\n\n2. Interaction Trace & Critical Annotation (The Debugging Log) The AI successfully generated the logic for the Logit Lens but failed significantly on implementation details. Below is the log of the 4 specific crashes I had to debug, annotated with my critique of the AI's performance.\n\nhttps://docs.google.com/spreadsheets/d/17VnvoLmzWUtTz3R9J_-RMwJJWNNa0Yxjo5SipqXoh98/edit?usp=sharing \n\n3. Conclusion\n\nThis experiment demonstrated that LLMs are excellent at reactive debugging (fixing crashes when shown a stack trace) but poor at one-shotting. My role shifted from \"Coder\" to \"Reviewer,\" validating that the AI's \"fixes\" were theoretically sound.\n\n\n\nHere is the StreamLit project Link: https://ijinyu1113gpt-2-logit-lens-visualization.streamlit.app/ ",
    "attachments": [],
    "highlight": false,
    "summary": "I acted as a \"Technical Lead\" and prompted the AI (Cursor/Gemini) to write a PyTorch + Streamlit script."
  },
  {
    "id": "ed-7430166",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: Interactive, Trainable Visualization of the Attention Mechanism",
    "dek": "With Claude 4.5 Opus, I built a fully trainable attention head visualization (with a slightly simplified architecture that does not contain a normalization layer or MLP). The purpose of this is for st...",
    "student": "Neil Pattanaik",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430166"
    },
    "body_html": "With Claude 4.5 Opus, I built a fully trainable attention head visualization (with a slightly simplified architecture that does not contain a normalization layer or MLP). The purpose of this is for students visualize their own contrived/toy examples to understand how the attention mechanism operates. \n\nTry it out here: https://claude.ai/public/artifacts/eb7be4c4-ec9c-4398-a2d9-1e9c8559c17c\n\nThe program allows you to choose the dimension of the embedding layer and define your own a vocabulary (in terms of pairs of text and embeddings, no tokenization here). The intention here is again to enable contrived examples that are intuition rich, such as the one below.\n\n\n\nConsider the following embeddings:\n\ncat: [1, 0, 0, 0.8]\n\ndog: [1, 0, 0, -0.8]\n\nlikes: [0.3, 0.3, 1, 0]\n\nmilk: [0, 1, 0, 0.8]\n\nwater: [0, 1, 0, -0.8]\n\n\n\nHere, we choose (for demonstration purposes) to encode animal at index 0, drink at index 1, and an affinity at index 3. This is the default setup, so you can easily go try the following experiment! Observe initially that the attention head does not capture the affinity between cat/milk and dog/water. We will show how in two training steps, we can update the attention to recognize this toy example.\n\nLet's first train on the sequence \"cat likes milk\". The site shows each step of the forward and backward pass, but we'll just show the last step (end of backprop) here for brevity sake.\n\nWe backprop:\n\n\n\nNow, we can train another sequence, \"dog likes water\":\n\n\n\nYou should now be able to observe the positive affinity reflected in the attention matrix on \"cat likes milk\" between cat and milk, while \"cat likes water\" barely has water attending to cat. The analogous feat applies for dog. ",
    "attachments": [],
    "highlight": false,
    "summary": "With Claude 4.5 Opus, I built a fully trainable attention head visualization (with a slightly simplified architecture that does not contain a normalization layer or MLP). The purpose of this is for students visualize their own contrived/toy examples to understand how the attention mechanism operates."
  },
  {
    "id": "ed-7430045",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini Gem for quizzing yourself on prerequisite ML knowledge.",
    "dek": "I created a Gemini gem, called Prerequisite Preparator. It is tailored specifically to be a helpful tutor regarding essential Matrix algebra and vector calculus questions.\n\nI gave it the description: ...",
    "student": "Jacqueline Thibault",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430045"
    },
    "body_html": "I created a Gemini gem, called Prerequisite Preparator. It is tailored specifically to be a helpful tutor regarding essential Matrix algebra and vector calculus questions.\n\nI gave it the description: Quizzes essential prerequisite mathematical concepts for deep learning\n\nAnd the instructions: You are a helpful homework assistant for a college deep learning class. This class heavily relies on prerequisite knowledge of vector calculus and matrix math for ML. Ask me essential matrix algebra questions in a rapid call-and-response type of format. e.g. (what are the essential characteristics of a PSD matrix?)  Only ask ONE question at a time.\n\nUpon my first pass, I gave it this pdf: https://gwthomas.github.io/docs/math4ml.pdf\nwhich I frequently referenced in the beginning. However, I quickly noticed that the questions it were asking were too elementary and not sufficient to provide an in-depth understanding of the necessary prerequisites. I later gave it the hw0 solutions for this class, and it immediately was asking better questions. This can be useful for making sure you have a solid understanding of essential mathematical concepts before manipulating them later on in the class.\n\n\n\nAttached is the gem: https://gemini.google.com/gem/fdaaf1268d88\n\n\nand my annotated trace: ",
    "attachments": [
      {
        "name": "Gemini.pdf",
        "url": "https://static.us.edusercontent.com/files/u0gp7oO4N5xwpgpAr84RVmzF"
      }
    ],
    "highlight": false,
    "summary": "I created a Gemini gem, called Prerequisite Preparator. It is tailored specifically to be a helpful tutor regarding essential Matrix algebra and vector calculus questions."
  },
  {
    "id": "ed-7430032",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT as a Misconception-Driven Student in a Teaching Dialogue",
    "dek": "I used ChatGPT 5.1 and designed a prompt that intentionally makes the model behave like a CS 182 student with realistic, common misconceptions. Instead of asking the LLM to be an expert, I positioned ...",
    "student": "Dagny Streit",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7430032"
    },
    "body_html": "I used ChatGPT 5.1 and designed a prompt that intentionally makes the model behave like a CS 182 student with realistic, common misconceptions. Instead of asking the LLM to be an expert, I positioned myself as the instructor: my role in the interaction was to teach the model, correct its misunderstandings, and guide it with carefully chosen questions.\n\nThis created a highly interactive learning tool where the model’s “mistakes” were actually useful because explaining and correcting them required me to demonstrate that I truly understood the underlying concepts. In other words, the framework forced me to teach the AI, which was a great way to check whether I have internalized the material well enough to identify misconceptions and explain the ideas clearly to someone else. This also makes the prompt a reusable tool for others as anyone can repurpose it for other topics to surface misconceptions and test their own understanding.\n\nAt the end of the conversation, I asked the model to summarize all the misconceptions it made along with the correct explanations I provided. This produced a clear, concise list of key takeaways with most of the important discussed ideas.\n\nAttached below is the annotated conversation around common misconceptions in convolution neural networks, including bias terms, receptive fields, 1x1 convolutions, and strided convolutions. Annotated in red is the misconception the model made. Annotated in green is where the model learned and corrected its logic. Annotated in blue are comments about the instructions I gave.",
    "attachments": [
      {
        "name": "Participation E2 Annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/9X2AUWG1hfKx9KynM5hFogav"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT 5.1 and designed a prompt that intentionally makes the model behave like a CS 182 student with realistic, common misconceptions. Instead of asking the LLM to be an expert, I positioned myself as the instructor: my role in the interaction was to teach the model, correct its misunderstandings, and guide it with carefully chosen questions."
  },
  {
    "id": "ed-7429972",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: ChatGPT Study mode on Variational Autoencoders",
    "dek": "I used ChatGPT's study mode to understand variational autoencoders better. I have attached the annotated pdf of the transcript.\n\nSome notable things in my interaction:\n\n1. I think GPT was able to prov...",
    "student": "Ayush Goel",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429972"
    },
    "body_html": "I used ChatGPT's study mode to understand variational autoencoders better. I have attached the annotated pdf of the transcript.\n\nSome notable things in my interaction:\n\n1. I think GPT was able to provide very good intuitions for variational autoencoders, including why we need VAEs in the first place, the reparameterization trick and the different terms in the loss function.\n\n2. I asked GPT to ask me questions to cross check my understanding. For the most part, it picked great questions and was able to adapt them based on my confusions and doubts. For example, I asked it a question about how the KL divergence term doesn't collapse the latent distribution, and GPT asked me a question regarding reweighting terms in the loss function to make sure I understood the tradeoff.\n\n3. Sometimes, GPT started asking the same question repeatedly in different wording, especially towards the end when I had mostly understood the concept. In these scenarios, I had to guide the conversation myself with other questions I was curious about / details I didn't understand.\n\n4. In the beginning, GPT provided too much information at once, trying to explain every detail in one shot. While the flow of ideas was logical and it started with the intuition, it still would've been better to break it up into sections and only move on until I understood each idea fully.",
    "attachments": [
      {
        "name": "variational_autoencoders_gpt_study.pdf",
        "url": "https://static.us.edusercontent.com/files/ILQGPxhgA8lXgL7MURNqCrmy"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT's study mode to understand variational autoencoders better. I have attached the annotated pdf of the transcript."
  },
  {
    "id": "ed-7429794",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Gemini 3 Pro for Optimization Visualizations",
    "dek": "I had Gemini 3 Pro build an interactive HTML site with Plotly to visualize how SGD, Momentum, and Adam navigate a difficult loss function because I often get confused about how changing their paramete...",
    "student": "Tyler Pham",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429794"
    },
    "body_html": "I had Gemini 3 Pro build an interactive HTML site with Plotly to visualize how SGD, Momentum, and Adam navigate a difficult loss function because I often get confused about how changing their parameters like beta affects their end result. You can use sliding bars to tweak hyperparameters like the learning rate and beta values to see how it affects convergence.\n\nEven though I understand the intuition and motivation behind Momentum and Adam, I wanted to see more mathematical simulations where I could change the parameters and observe why Adam is so stable.\n\nArtifact (The HTML Site):\n\nObservations:\n\nWhen I asked the AI to explain the math inside the tool, it generated complex LaTeX equations. However, it failed to realize that a standard HTML browser cannot render LaTeX without a library like MathJax. It hallucinated a capability the file didn't have. I had to force it to rewrite the math using standard HTML entities.\n\nGemini 3 Pro (which has Thinking) is a lot more concise compared to other models I've used like GPT 5 Thinking. When I asked it to explain more about the math behind Adam and Momentum, it's analysis was extremely short even when I told it to be detailed. This may have been due to already-high token count from the HTML.\n\nI noticed Momentum was consistently beating Adam in the simulation. I thought this was a bug. Gemini correctly explained that this is a feature, not a bug. In a noiseless deterministic function (like this simulation), Momentum acts like a race car without a speed limit. Adam, designed for real noisy data, normalizes the gradients, effectively enforcing a \"speed limit\" for stability.\n\nInitial Prompt:\n\nI want to create an interactive educational tool for my Deep Learning class to visualize the differences between SGD, Momentum, and Adam optimization. Please write a self-contained, single-file HTML/Javascript application (using a library like Plotly.js or a simple Canvas API) that does the following: The Environment: Render a 2D Contour Plot of a 'tricky' loss function where SGD typically struggles (oscillates) but Adam/Momentum succeeds. The Agents: Implement three 'agents' starting at the same point:\n\nSGD (Red dot/line)\n\nMomentum (Blue dot/line)\n\nAdam (Green dot/line) The Controls: Sidebar controls with sliders for:\n\nLearning Rate ($\\alpha$)\n\nMomentum ($\\beta$ or $\\gamma$)\n\nAdam parameters ($\\beta_1$, $\\beta_2$) Animation: A 'Start/Reset' button. When clicked, the agents should animate their path step-by-step down the gradient. Technical Constraints:\n\nDo not use external CSS/JS files; embed everything in the or .\n\nShow a live legend updating the current $(x, y)$ and Loss value for each optimizer.\n\n\n\nAnnotated Trace:",
    "attachments": [
      {
        "name": "optimization_race.html",
        "url": "https://static.us.edusercontent.com/files/ezA5y7lbtb6hz7cbRB5K6ENZ"
      },
      {
        "name": "gemini-chat.2025-12-08.pdf",
        "url": "https://static.us.edusercontent.com/files/6i34NYDPxtLrprXCdyfYqNwj"
      }
    ],
    "highlight": false,
    "summary": "I had Gemini 3 Pro build an interactive HTML site with Plotly to visualize how SGD, Momentum, and Adam navigate a difficult loss function because I often get confused about how changing their parameters like beta affects their end result. You can use sliding bars to tweak hyperparameters like the learning rate and beta values to see how it affects convergence."
  },
  {
    "id": "ed-7429758",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: DeepSeek as Web3 teacher",
    "dek": "For special participation part E, I asked DeepSeek to teach me how to write a smart contract on BTC chain: https://chat.deepseek.com/share/9wu5248zp1z8hls9xy\n\nBased on our conversation, here is a summ...",
    "student": "Menger Wen",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429758"
    },
    "body_html": "For special participation part E, I asked DeepSeek to teach me how to write a smart contract on BTC chain: https://chat.deepseek.com/share/9wu5248zp1z8hls9xy\n\nBased on our conversation, here is a summary in English of what I have accomplished and the current situation:\n\nProgress Summary\n\nI have successfully completed the initial setup and are very close to deploying my first Bitcoin smart contract. Here is what I have done:\n\n✅ Environment Setup: I installed all prerequisite tools (Node.js, NPM, Git) on my Windows 11 computer.\n\n✅ Core Tools Installation: I installed the global CLI tool (@opcat-labs/cli-opcat) which is used to create and manage projects.\n\n✅ Project Creation: I created a new project named helloworld using the CLI. This command automatically generated the complete project structure and configuration files.\n\n✅ Project Dependencies (SDK): I entered the project directory and ran npm install. This installed all necessary dependencies for the project, including the crucial @opcat-labs/scrypt-ts-opcat SDK—the library containing the functions and classes needed to write my contract.\n\n✅ Smart Contract Code: I correctly modified the main contract file (src/contracts/helloworld.ts), creating a simple contract that stores a hash and can only be unlocked by providing the matching message.\n\n✅ Contract Compilation: I ran npm run compile, which successfully transformed my TypeScript code into a blockchain-readable format and generated a contract artifact file (artifacts/contracts/helloworld.json).\n\n✅ Test Key Generation: I generated a private key for the Bitcoin testnet using npm run genprivkey. The command provided I with a testnet address (mx79K19aq2Mq9mjUL1SHQ4y5NwTwcLKsFG) to receive faucet funds.\n\nCurrent Blocking Issue\n\nI am currently stuck at the final deployment step. When I run the deployment script (npx tsx deploy.ts), it fails with the following error:\n\nError: Cannot find module 'D:\\...\\helloworld\\dist\\cjs\\index.cjs'\n\nAnalysis of the Problem: This is a technical configuration or compatibility issue, not a mistake in my following of the tutorial steps. The most likely causes are:\n\nNode.js Version Mismatch: I am using Node.js v22.20.0. The tools in this project (tsx and the SDK) may not be fully compatible with this very recent version and expect an older Long-Term Support (LTS) version like Node.js 18 or 20.\n\nIncomplete Build Process: The error points to a missing file in a dist directory. my npm run compile command compiled the sCrypt contract itself, but the deployment script may require the TypeScript project code to be compiled into a dist folder, which hasn't happened yet.\n\nImmediate Next Steps & Solution\n\nTo resolve this and successfully deploy my contract, I need to:\n\nAdd loadArtifact() to my Script: First, ensure my deploy.ts file includes the two critical lines that tell the system how to interact with my compiled contract. Add them after the other import statements:\n\nimport artifact from './artifacts/contracts/helloworld.json'\nHelloworld.loadArtifact(artifact)\n\n\nSwitch to a Compatible Node.js Version (Recommended Solution): The most effective fix is to switch from Node.js v22 to an LTS version (v18 or v20). I can do this using a version manager like nvm-windows for Windows.\n\nReinstall Dependencies & Recompile: After switching Node.js versions, go back to my project folder, delete the node_modules folder, and run npm install followed by npm run compile again to ensure everything is built correctly for the new environment.\n\nOnce these steps are complete, funding my test address from the faucet and running npx tsx deploy.ts should successfully deploy and call my \"Helloworld\" smart contract on the Bitcoin testnet.\n\nIn short: I have perfectly followed all tutorial steps. The final error is a common technical hurdle that is resolved by adjusting my Node.js version and verifying my deployment script's code.\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "For special participation part E, I asked DeepSeek to teach me how to write a smart contract on BTC chain: https://chat.deepseek.com/share/9wu5248zp1z8hls9xy"
  },
  {
    "id": "ed-7429585",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: A Visualizer for Optimizers",
    "dek": "Hi all, \n\nI created an optimizer visualization tool (https://kithminiherath.github.io/optimizer-vis/) to interactively analyze how different hyperparameters affect the loss minimization trajectory for...",
    "student": "Kithmini Herath",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429585",
      "github": "https://github.com/KithminiHerath/optimizer-vis"
    },
    "body_html": "Hi all, \n\nI created an optimizer visualization tool (https://kithminiherath.github.io/optimizer-vis/) to interactively analyze how different hyperparameters affect the loss minimization trajectory for the following optimizers: \n\nAdamW\n\nSGD (with and without nestorov momentum)\n\nMuon \n\nTo build this visualizer I used classic optimizer test functions (2D loss landscapes) to test convergence, precision, robustness and performance of the above optimization algorithms:\n\nSphere\n\nGaussian Bowl\n\nRosenbrock\n\nRastrigin\n\nThe code for this visualizer is available at: https://github.com/KithminiHerath/optimizer-vis which can be used to extend to more optimizers. \n\nThis visualization tool was built with the help of Gemini 3 on Antigravity using TypeScript and three.js. I also used Claude Code as a secondary agent to get a different view of the code implementations by Gemini and to weed out implementation bugs. \n\nFor a lightweight webapp deployment all optimizers and loss functions were implemented with TypeScript. To ensure there were no implementation bugs, I ran test benches comparing the TypeScript optimizers' step-wise outputs for loss functions against the corresponding PyTorch libraries.\n\nHow I built the visualizer to represent Muon on 2D loss landscapes: \n\nImplementing AdamW and SGD were quite straightforward, but it was challenging for me to make this visualizer to work for Muon in a meaningful way. This is because Muon only works for 2D parameters and the loss functions and the rest of this visualizer was built for vectors. Chatting with Gemini 3 we came up with the following workflow to make this visualizer work for Muon as well in a meaningful way:\n\nSince Muon needs 2D parameters we defined a “matrix mode” where a parameter matrix was defined as \n\n$$W=\\left[\\begin{matrix}x&z\\\\y&w\\end{matrix}\\right]$$\n\nIn the Muon implementation the rows will be orthogonalized here. \n\nWe define the “visible parameters” as $x$ and $y$ and the remaining parameters as “dummy” parameters. By separating $x$ and $y$ into different rows, you force the optimizer to make them orthogonal. If they were in the same row, they would just be normalized together. \n\nEven if $z$ and $w$ are dummy parameters we still need to define gradients for them. Therefore we don’t fix them, in-order for them to support the orthogonality constraints and also to prevent the matrix from being rank-1. Currently they are initialized to -1 and 1 and the final loss function is defined as:  . \n\n$$L_{total}=L_{2D}\\left(x,y\\right)+z^2+w^2$$\n\n$L_{2D}(x,y)$ is one of the four previously mentioned 2D loss functions and the remaining terms follow a simple bowl objective. Providing a \"slope\" for the hidden dimensions this way ensures the matrix has sufficient rank for the Newton-Schulz iteration to work non-trivially. \n\nUnder the above loss function the weights are optimized with the standard Muon implementation in TypeScript and we only visualize the behavior of $L_{2D}(x,y)$ in the tool.\n\nI think this is still a mathematically valid way to observe the behavior of Muon in comparison to the other two optimizers. I also want to note that when Muon is selected as an optimizer from the controls in the visualizer, any other optimizer selected with it will also be working on matrix parameters for common ground. \n\nFeatures of the visualizer: \n\n2D contour and 3D surface plots for visual representation of the loss landscapes. This way during a run the user can analyze both views. I think the 3D view is especially useful when there are multiple local minima, saddle points and when it’s not apparent on the 2D contour plot why the optimizer got stuck at certain points. \n\nLoss function control – select any loss function.\n\nConfigure Optimizer panel – \n\nType – optimizer type selection \n\nHyperparameter sliders to configure the optimizer and add it. \n\nYou’re able to select multiple optimizers at different configurations during a run and they will be listed with the choices of hyperparameters in the Optimizer List. You can also set the starting points of $x$ and $y$ by either clicking anywhere on the contour plot or typing out coordinates in the \"start X\" and \"start Y\" boxes. \n\nYou can also set the number of maximum steps you want the optimizer to run for. The default is 200 steps. \n\nYou start the run with “Start” button and it’ll automatically run until it hits the maximum number of steps. You can also pause runs or step through iterations one step at a time with the “Step” button. While the “Stop” button resets to the beginning of the run, the “Reset” button resets the visualizer.\n\nSome cool visualization examples:\n\nLearning rate comparison within the same optimizer type: AdamW with higher learning rate converging faster by escaping local minima:\n\nComparing several optimizers:\n\nAdamW finds the global minima but both SGD versions reach the local minima:\n\nMuon originally moves towards the local minima but is able to recover and change the trajectory towards the global minima. I think this shows how Muon’s orthogonality constraints initially causes the dominant gradient at that point ($dy$) to affect the gradients in other directions and may overall pull in the local minima direction, but I think once $dw$ and $dz$ recovers under their loss it snaps back in the direction of the global minima:\n\nMuon seems to do great in converging at more complex loss landscapes. I think this is an interesting case that shows how Muon’s spectral norm constraints essentially “saves” it from exploding gradients along steep valleys and take controlled steps and eventually reach the global minima efficiently while the other optimizers seem to be distracted by the steep gradient in one direction (wall like structure) and gets stuck at local minimas since the gradient in other directions (valley like structure) gives less of a signal to move:\n\nLimitations:\n\nUsers are unable to see the behavior of the hidden parameters in the matrix mode.\n\nUsers cannot set different values for the hidden parameters and analyze how that affects optimization trajectory of the 2D losses. \n\nI think this is a useful tool for anyone trying to understand how certain hyperparameters affect certain loss functions, gain insights into the behavior of different optimizers even if it’s for relatively simple loss landscapes. I think it would be a good playground to test specific instances to understand optimizers for academic purposes. \n\nHope y’all can also check this out and let me know if you have any feedback. I’m also interested in expanding this to other optimizers in the future.\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "I created an optimizer visualization tool (https://kithminiherath.github.io/optimizer-vis/) to interactively analyze how different hyperparameters affect the loss minimization trajectory for the following optimizers:"
  },
  {
    "id": "ed-7429583",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Flow Matching vs DDPM Diffusion Visualization",
    "dek": "In Berkeley's CS180: Introduction to Computer Vision and Computational Photography, we also covered diffusion models but under a different lens known as \"flow matching\". From my understanding, flow ma...",
    "student": "Zach Pricz",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429583"
    },
    "body_html": "In Berkeley's CS180: Introduction to Computer Vision and Computational Photography, we also covered diffusion models but under a different lens known as \"flow matching\". From my understanding, flow matching is a way to look at diffusion models that attempt to learn a vector field for samples to follow along in the reverse direction. This involves solving ODEs and resulting in deterministic trajectories compared to solving SDEs in stochastic processes like DDPM.\n\nTo visualize this difference, I worked with Cursor to create a visualization demo for the reverse process. In this demo, we can visualize particles moving from a noisy distribution to a clean two humped distribution. There is a stochasticity slider which adjusts how much randomness the particles will take in their trajectory as they move along a vector field. When that slider is 0, we are simulating a pure flow matching model, and when it is 1 we are simulating a stochastic DDPM process. We can also adjust the amount of particles moving across distributions per second.\n\nFeedback for Cursor:\n\nUsing Cursor was generally a positive experience however it struggled to create the visuals for the gaussians on the left and right hand side. I had to provide it a visual slide from CS180 for it to accomplish this after 3+ tries which was slightly dissapointing. Despite that, it was able to create this application for me in only a little over an hour which is very impressive. \n\nTo use the tool navigate to this link: https://zjpricz100.github.io/Zjpricz100/StochasticDiffusion/index.html\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "In Berkeley's CS180: Introduction to Computer Vision and Computational Photography, we also covered diffusion models but under a different lens known as \"flow matching\". From my understanding, flow matching is a way to look at diffusion models that attempt to learn a vector field for samples to follow along in the reverse direction."
  },
  {
    "id": "ed-7429419",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Inductive Bias Explainer",
    "dek": "I used GPT 5.1 to build a small exploratory tool for understanding inductive bias across the architectures we studied in class this semester. I wrote an initial prompt that let me ask the model about ...",
    "student": "Devan Perkash",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429419",
      "chatgpt": "https://chatgpt.com/share/693635f5-fc80-800e-bb76-062bfb4a2bf1"
    },
    "body_html": "I used GPT 5.1 to build a small exploratory tool for understanding inductive bias across the architectures we studied in class this semester. I wrote an initial prompt that let me ask the model about different kinds of data patterns (local spatial cues, hybrid local/global structure, long-range sequential dependencies, etc.) and compare how various architectures behave based on the \"assumptions\" baked into them.\n\nExecutive Summary:\n\nMy goal was to create a tool that helps students reason about which structures different architectures “like” to learn, and why those preferences matter when the data mixes multiple types of patterns. I wrote a long initial prompt that set up a consistent explanation format so I could see how the model’s reasoning changed across tasks. Then I tried five scenarios that were intentionally varied and realistic: some visual, some sequential, and one involving noisy video motion.\n\nIn many cases, the model gave clear and useful explanations of how CNNs, ResNets, RNNs, Transformers, state-space models, and others behave when their inductive biases align (or don’t align) with the underlying data. The multi-architecture comparisons helped highlight patterns I’ve heard emphasized in lecture, like how some models naturally focus on local structure while others mix information globally.\n\nThere were also a few places where the explanations were a bit simplified. For example, sometimes the model glossed over practical limitations (like how positional encodings affect Transformers, or how certain models handle noise). But overall the responses were consistent and conceptually helpful.\n\nYou can access the chat here:\n\nhttps://chatgpt.com/share/693635f5-fc80-800e-bb76-062bfb4a2bf1\n\nThe full annotated chat session is attached below, where I explain my prompting strategy, comment on the model’s interpretations, and point out small places where the explanations could be sharper or more nuanced.",
    "attachments": [
      {
        "name": "participation_e2.pdf",
        "url": "https://static.us.edusercontent.com/files/OkX7rjKpdilVNNIbgy4bWEtp"
      }
    ],
    "highlight": false,
    "summary": "I used GPT 5.1 to build a small exploratory tool for understanding inductive bias across the architectures we studied in class this semester. I wrote an initial prompt that let me ask the model about different kinds of data patterns (local spatial cues, hybrid local/global structure, long-range sequential dependencies, etc."
  },
  {
    "id": "ed-7429307",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Claude Artifact Creation Based on GNN Lecture Notes",
    "dek": "For this participation assignment, I decided to create a prompt for Claude to create an interactive \"artifact\" designed with the purpose of helping understand key concepts from lecture notes. This too...",
    "student": "Subhash Prasad",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429307"
    },
    "body_html": "For this participation assignment, I decided to create a prompt for Claude to create an interactive \"artifact\" designed with the purpose of helping understand key concepts from lecture notes. This tool is designed to be used as an aide to reading lecture notes themselves, as it promotes active-learning through interactivity. I used Sonnet 4.5, and the specific prompt I used is specified below.\n\nPROMPT:\n\nI'm taking a Deep Learning course and need to create an interactive learning tool to help students (including myself) better understand concepts from this lecture. Please read through these lecture notes and: 1. Identify 3-5 core concepts that would benefit most from interactive visualization or hands-on exploration 2. For each concept, suggest what kind of interactive artifact would be most helpful (e.g., interactive visualizer, step-by-step derivation tool, parameter explorer, concept quiz, etc.) 3. Pick the MOST important/challenging concept and create an interactive artifact for it that includes: - Clear explanations at multiple levels of detail - Interactive elements where I can adjust parameters and see results - Step-by-step walkthroughs where applicable - Self-check questions or exercises The goal is to create something that replaces traditional pre/post-lecture reading with an active learning experience.\n\nARTIFACT GENERATED:\nhttps://claude.ai/public/artifacts/8c3e2ccf-619d-4c6d-a86b-4b43eeb9ef27\n\nANNOTATED CONVERSATION:\nhttps://drive.google.com/file/d/1wntHd7Ix8iB4LBfbf9mPIVM0i_02ZNyc/view?usp=sharing\n\nRESULTS:\nOverall, the model did a decent job. It created a truly interactive component, and clearly + correctly identified the concepts from the lecture notes that are most pertinent to understanding. The visualization makes it easy to understand the core concepts of convolution. The structure of the tool makes sense and is conducive to learning, as complex concepts are covered in later tabs. There is also real-time computation in the simulation, eliminating the overhead of waiting for a new graph if one were doing the same thing by prompting an LLM repeatedly.\n\nSome places for improvement are the omission of several things in the feature which would have been really nice for understanding, like node-masking, and interactivity in the DiffPool section. The model oversimplified in many places in favor of creating a working artifact, while overpromising in the initial response before creating the artifact itself. Additionally, the bias term is left out of the aggregation of neighbors computation, so while using the tool, one must note that the formulas may be incomplete / incorrect.\n\nLecture notes should still be read to fill in the gaps left by the interactive artifact.",
    "attachments": [],
    "highlight": false,
    "summary": "For this participation assignment, I decided to create a prompt for Claude to create an interactive \"artifact\" designed with the purpose of helping understand key concepts from lecture notes. This tool is designed to be used as an aide to reading lecture notes themselves, as it promotes active-learning through interactivity. I used Sonnet 4.5, and the specific prompt I used is specified below."
  },
  {
    "id": "ed-7429068",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Cheatsheet Attention and Diffusion",
    "dek": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, ...",
    "student": "Shoumik Roychowdhury",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429068"
    },
    "body_html": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build individualized pre-lecture learning tools.\n\nI’m sharing the prompt, output artifacts, and annotated interaction trace so you can use them yourselves and also see both the strengths and the failure modes of LLM-assisted studying.\n\n\nNOTE:\nthe model occasionally implied citations (“as from class notes”) without pulling actual page numbers\n Some formulas were slightly rephrased—not incorrect, but not exactly matching lecture notation\nThe kernel attention explanation is correct conceptually, but slightly hand-wavey on the random feature approximation\n\nThe Prompt I Used\n\n“Generate a comprehensive, exam-ready cheatsheet for Berkeley EECS 182 (Fall 2025), focusing especially on:\nAttention mechanisms (self-attention, cross-attention, multi-head attention, transformer architecture),\nGenerative AI models with emphasis on Diffusion Models (forward process, reverse process, score matching, ELBO, denoising networks, sampling algorithms).\nThe cheatsheet should prioritize mathematical clarity, include equations and derivations, use text diagrams, and be optimized for last-minute review.”\n\n\nNote I also provided the homework and discussion associated with the previously mentioned topics\n\nConclusion:\nUseful as a study tool, but not a replacement for primary sources (lecture slides, notes, HW derivations). You must still verify key formulas.\n\n\n\n",
    "attachments": [
      {
        "name": "Attention_and_Diffusion_CheatSheet.pdf",
        "url": "https://static.us.edusercontent.com/files/bMYCGPVYJPtPwR0xcrmAoCeM"
      }
    ],
    "highlight": false,
    "summary": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build individualized pre-lecture learning tools."
  },
  {
    "id": "ed-7429063",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: AI Lecturer",
    "dek": "Tool: Claude Opus 4.5, Lecture: Lecture 6\n\nGoal:\n\nThe goal of this is to turn the handwritten lecture notes into a complete, step-by-step “textbook chapter” without skipping any content using a struct...",
    "student": "Anshul Verma",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7429063"
    },
    "body_html": "Tool: Claude Opus 4.5, Lecture: Lecture 6\n\nGoal:\n\nThe goal of this is to turn the handwritten lecture notes into a complete, step-by-step “textbook chapter” without skipping any content using a structured system prompt. The prompt forces the LLM to rewrite every equation and symbol, explain every concept in plain English, and derive formulas line-by-line.\n\nEvaluation:\n\nDid Well\n\nCaptured the full narrative flow of the lecture, connecting disparate topics \n\nGave clear intuition for difficult math\n\nRarely skipped topics touched on in the notes\n\nLimitations\n\nOccasionally summarized text blocks instead of rewriting them verbatim \n\nMixed external knowledge into the notes without always clearly labeling it \n\nSometimes invented small details to make the narrative smoother\n\nPrompt: https://drive.google.com/file/d/11pExwTIi11A0ssL2ztrrajsW3Qx9z87d/view?usp=sharing\n\nLLM Trace: https://claude.ai/share/4993f343-6808-4e3c-8c5f-314f3d094867\n\nAnnotated Trace: https://drive.google.com/file/d/18RcfXiPb9KIqi1Rz7LUGtkjwB_Rgqe66/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "The goal of this is to turn the handwritten lecture notes into a complete, step-by-step “textbook chapter” without skipping any content using a structured system prompt. The prompt forces the LLM to rewrite every equation and symbol, explain every concept in plain English, and derive formulas line-by-line."
  },
  {
    "id": "ed-7428760",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Gemini 2.5 Flash for Project Coordination",
    "dek": "I used Gemini 2.5 Flash to see how well it could coordinate among group members for the final project. We ran into a lot of issues in terms of how to split and run the computationally heavy code; an a...",
    "student": "Diana Kohr",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428760"
    },
    "body_html": "I used Gemini 2.5 Flash to see how well it could coordinate among group members for the final project. We ran into a lot of issues in terms of how to split and run the computationally heavy code; an analysis of feasibility and a schedule for progress dependencies would have been nice. \n\nConversation: https://gemini.google.com/share/db18b2dd0a70\n\nAnnotated: https://drive.google.com/file/d/1nLEeUowcs1n5HS0BHMy1t2IXE7C4TAXN/view?usp=sharing\n\nPrompts: \n\nA lot of my prompts were quite project specific, so here's a general framework. \n\nLet Gemini warm up to your project idea by asking it about relevant literature and proposing your idea / question. \n\nAsk what datasets are appropriate to use for the project. Point Gemini in the direction of scale that you prefer. \n\nIntroduce more specific information about your setup in terms of what needs to be run. Share what you have available in terms of compute (how many devices, what runtime on Colab). Ask how you can efficiently split the workload. \n\nThis will produce a full plan that includes implementation (which is also helpful). Tell Gemini to focus on the most time-consuming parts and ask how everybody can run things in parallel. \n\nCool thing you can do at the end: ask, if given significantly more time, how would you expand the scope of the project? \n\nResults: \n\nPicked up on the gist of the project super quickly. \n\nRetrospectively, having almost finished the project, Gemini's predictions on how long things would take were pretty accurate. If I could redo the project, I would've gone with the suggested datasets, since we were a little over-ambitious. \n\nIt created a schedule that highlighted the key dependencies among parts, which were sticking points for us. \n\nFor some reason, it kept embedding random diagrams that had nothing to do with the project? Maybe this is a me problem. \n\nOverall, quite satisfied. \n\n",
    "attachments": [],
    "highlight": false,
    "summary": "I used Gemini 2.5 Flash to see how well it could coordinate among group members for the final project. We ran into a lot of issues in terms of how to split and run the computationally heavy code; an analysis of feasibility and a schedule for progress dependencies would have been nice."
  },
  {
    "id": "ed-7428691",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Deepseek as a Socratic Tutor on DDPM",
    "dek": "Annotated Trace: \n\nConversation: https://chat.deepseek.com/share/3720l4kn5g9dtco2c1\n\nI found the DDPM/DDIM lecture mathematically intimidating. For my special participation I thought it would be usefu...",
    "student": "Zach Pricz",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428691"
    },
    "body_html": "Annotated Trace: \n\nConversation: https://chat.deepseek.com/share/3720l4kn5g9dtco2c1\n\nI found the DDPM/DDIM lecture mathematically intimidating. For my special participation I thought it would be useful to utilize Deepseek to help me understand the ins and outs of the DDPM algorithm derivation from lecture.\n\nTo do this, I asked Deepseek to act as a \"socratic tutor\" and ask ME questions regarding the notes from class. I gave it clear rules to follow and prvent giving me too many solutions and answers right off the bat. This allowed for a thorough exercise with active participation from my part. \n\nThe Good:\n\nDeepseek did a great job overall and it helped me gain a lot more confidence in the subject matter and probability as a whole. I was especially impressed with its ability to create on the fly questions after I miss a certain concept or neglect a certain piece of the proof. I also felt it bridged the reverse and forward process of diffusion models very well with conceptual questions throughout allowing me to see a bigger picture. I felt challenged still, but never discouraged by its questioning. Not only this but deepseek did all this while being able to read and interpret (with moderate success) my handwritten math along the way. \n\nThe Bad:\n\nOccasionally Deepseek would neglect certain concepts I thought it would cover more. This could be fixed with prompting but I wish it noticed the highlighted \"pink\" sections in the professor's notes talking about dropping terms and normalization. Some sub questions on this would be nice to allow me to feel more confident in these steps. I also felt that Deepseek should have continued my session into a leading question with DDIM but once again I could have asked for this in the prompt.\n\nOverall I think Deepseek is an excellent tool for reinforcing understanding of difficult math concepts in lectures. It is great for asking how to do something but its even better for quizzing and tutoring a student who needs active practice in their study routine (like me)!",
    "attachments": [
      {
        "name": "DDPM DeepSeek Annotated Trace.pdf",
        "url": "https://static.us.edusercontent.com/files/3somhTG4Hvj0hHIEQq3dqnwy"
      }
    ],
    "highlight": false,
    "summary": "I found the DDPM/DDIM lecture mathematically intimidating. For my special participation I thought it would be useful to utilize Deepseek to help me understand the ins and outs of the DDPM algorithm derivation from lecture."
  },
  {
    "id": "ed-7428663",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E - Understanding RoPe Visually with help From Claude and 3Blue1Brown",
    "dek": "Conversation Link: https://claude.ai/share/da72b7bb-e46b-40b4-ab0c-32b4e5286e30\n\nConfused by RoPe, I used Claude Sonnet 4.5 to create the necessary facilities to genrate a 3Blue1Brown style Manim vide...",
    "student": "Garv Goswami",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428663"
    },
    "body_html": "Conversation Link: https://claude.ai/share/da72b7bb-e46b-40b4-ab0c-32b4e5286e30\n\nConfused by RoPe, I used Claude Sonnet 4.5 to create the necessary facilities to genrate a 3Blue1Brown style Manim video with both Visual and Auditory capabilities.: \n\nWhy rotation? \n\nHow does rotation create relative position?\n\nWhat does chunking mean visually?\n\nWhy different frequencies?\n\nand also examples of the concepts. \n\nClaude was able to focus on: \n\n1. Complete Animation System (Manim)\n\n10 animated scenes covering all RoPE concepts (4:10 total runtime)\n\nProfessional visualizations: rotations, matrices, algorithms, properties\n\nFixed to work without LaTeX (removed all MathTex dependencies)\n\n2. Narration System\n\nTime-coded scripts for all 9 main scenes\n\n3 TTS integration options (Google TTS, ElevenLabs, pyttsx3)\n\nScripts perfectly timed to match a video\n\n3. Documentation\n\nSetup guides, quickstart, narration workflow\n\nComplete timeline with scene-by-scene breakdown\n\nVideo syncing instructions\n\nHere is the zip file of all included files that Claude was able to generate as well as the completed video and audio files for anyone to view and hear. The actual scripts are able to generate more granularly, but I included the bare minimum for file size consideration. \n\n",
    "attachments": [
      {
        "name": "claude_rope_explanation 2.zip",
        "url": "https://static.us.edusercontent.com/files/pjy9ikgqvzn1SLpkG2wKVziS"
      }
    ],
    "highlight": false,
    "summary": "Confused by RoPe, I used Claude Sonnet 4.5 to create the necessary facilities to genrate a 3Blue1Brown style Manim video with both Visual and Auditory capabilities.:"
  },
  {
    "id": "ed-7428660",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Optimizer Formula Tool",
    "dek": "Here, I wanted to understand optimizers further and looked into building a tool that can help with developing a deeper understanding of different optimizer formulas by comparing their parameters and t...",
    "student": "Rohan Gulati",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428660",
      "chatgpt": "https://chatgpt.com/share/69360546-3510-8012-90ae-a34d21fad966"
    },
    "body_html": "Here, I wanted to understand optimizers further and looked into building a tool that can help with developing a deeper understanding of different optimizer formulas by comparing their parameters and their purpose over many iterations. \n\nThe goal of this tool was to create a conversational model that would provide a set of formulas used by a particular optimizer and quiz the user on what each parameter or term represents, which optimizer it belongs to, or how it worked. Additionally, after a student provided a response, the model would have to guide the user towards the correct answer rather than providing the correct answer afterwards. While that was the initial goal, the model was able to delve deeper into the task and build follow-up questions that reaffirmed understanding even when seeing correct answers. One behavior I found was that the model would reiterate responses and reflect on what parts were correct or required correction. Once, the model appeared to hallucinate from a double-negative in the prompt, but later shared understanding of the intended meaning. I thought it was particularly helpful at generating scenarios to reason about, such as the behavior of different functions that can be used compute the gradient magnitude in momentum.\n\nChat History: https://chatgpt.com/share/69360546-3510-8012-90ae-a34d21fad966 \n\nAnnotated Conversation: https://docs.google.com/document/d/1vB9L85HXcFHdDDUfWCok-MmY3UjAPhfi7S8M1h8qoLs/edit?tab=t.0 ",
    "attachments": [],
    "highlight": false,
    "summary": "Here, I wanted to understand optimizers further and looked into building a tool that can help with developing a deeper understanding of different optimizer formulas by comparing their parameters and their purpose over many iterations."
  },
  {
    "id": "ed-7428589",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Muon Intuition Tutor",
    "dek": "I used ChatGPT (GPT 5.1) as a “Muon Intuition Tutor” for Lecture 7 (Muon optimizer) to provide a chatbot tutor that can explain the optimizer from various facets of understanding.\n\nExecutive Summary:\n...",
    "student": "Devan Perkash",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428589",
      "chatgpt": "https://chatgpt.com/share/69361414-1a90-800e-8b28-6db3a50a52cd"
    },
    "body_html": "I used ChatGPT (GPT 5.1) as a “Muon Intuition Tutor” for Lecture 7 (Muon optimizer) to provide a chatbot tutor that can explain the optimizer from various facets of understanding.\n\nExecutive Summary:\n\nAs part of my learning process, I turned ChatGPT into an AI learning tool aimed at building intuition for Muon from multiple angles. I tend to learn best when I internalize a concept in multiple ways, and I wanted to make a tool that could provide similar value. I wrote a long initial prompt that forced the model into a fixed three-layer structure for every answer:\n\nIntuitive explanation - (high-level story, no formulas)\n\nGeometry / structural explanation - (what the matrix is doing to space)\n\nMathematical explanation - (SVD, constraints, and Newton–Schulz details)\n\nThis structure worked surprisingly well. ChatGPT consistently gave clear high-level and geometric explanations of why Muon cares about the “shape” of the gradient, what UV^T represents, and how semi-orthogonal updates differ conceptually from Adam- or SGD-style steps. These layers matched the way Lecture 7 motivated Muon and were genuinely helpful for my own understanding.\n\nOn the math side, the model correctly walked through the constrained optimization view (maximize alignment under a norm constraint) and connected it to the SVD solution. It also produced a reasonably structured explanation of the Newton–Schulz iteration and even attempted a small numeric example.\n\nHowever, the experiment also showed some important weaknesses:\n\nIt conflated different uses of Newton–Schulz (inverse square root vs. orthogonalization) and did not always clearly state that Muon is only approximating UV^T.\n\nIt tended to understate the importance of normalization before applying the polynomial, even though Lecture 7 emphasizes scaling singular values into (0,1) for convergence.\n\nIn the optimizer comparison section, it slightly over-sold Muon as universally better than Adam/Shampoo in “bad conditioning” settings without fully discussing trade-offs.\n\nIn the 2×2 numeric example, the conceptual steps were correct, but the detailed arithmetic is not something I would trust blindly for this type of usage (LLMs are error-prone there).\n\nOverall, the three-layer prompting strategy made the model’s strengths and weaknesses very visible: it is an effective conceptual tutor for Muon and a decent first pass at the math, but it still needs human oversight for subtle assumptions (normalization, convergence conditions, and when Muon is actually the right tool).\n\nYou can access the chat here:\n\nhttps://chatgpt.com/share/69361414-1a90-800e-8b28-6db3a50a52cd\n\nAnd you can read the full annotated trace here:",
    "attachments": [
      {
        "name": "participation_e.pdf",
        "url": "https://static.us.edusercontent.com/files/YhcfcNNuWkfddCK52FPh6jH8"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT (GPT 5.1) as a “Muon Intuition Tutor” for Lecture 7 (Muon optimizer) to provide a chatbot tutor that can explain the optimizer from various facets of understanding."
  },
  {
    "id": "ed-7428575",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Using NotebookLM to Infer Learning Priorities and Generate Assessment-Style Questions from Homework Assignments",
    "dek": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.\n\nI uploaded all the homework assignments into NotebookLM to see if i...",
    "student": "WeiYi Zhang",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428575"
    },
    "body_html": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.\n\nI uploaded all the homework assignments into NotebookLM to see if it could infer what’s likely important and generate exam-style practice questions, and whether those questions were meaningfully different from just redoing homework.\n\nThe goal wasn’t to predict the exam, but to see whether AI could actually support final exam preparation realistically—and where it still needs human judgment.",
    "attachments": [
      {
        "name": "Using NotebookLM to Infer Learning Priorities and Generate Assessment-Style Questions from Homework Assignments.pdf",
        "url": "https://static.us.edusercontent.com/files/q0L7irpAuKXpSgZtM7L725Tj"
      }
    ],
    "highlight": false,
    "summary": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation."
  },
  {
    "id": "ed-7428572",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Study Guide for Fermi Estimation (HW11) with Chatgpt 5.1 Study Mode",
    "dek": "I utilized ChatGPT 5.1 Study Mode to understand the prereading-equivalent context behind Fermi Estimation and GPU power and memory, which was something I was relatively unfamiliar with before attempti...",
    "student": "Hiya Shah",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428572",
      "chatgpt": "https://chatgpt.com/share/693618eb-456c-8005-9a98-6de49720855c"
    },
    "body_html": "I utilized ChatGPT 5.1 Study Mode to understand the prereading-equivalent context behind Fermi Estimation and GPU power and memory, which was something I was relatively unfamiliar with before attempting these problems. While these problems were a great introduction to the more HW-based concepts and self-contained, I had some follow up questions about the context that was provided, especially in the figures. I also prompted GPT to understand various parts of the figures, and I was surprised by how well it was able to analyze the figures (compared to some other models I tested hw 11 with such as Llama 4 Maverick). I also asked GPT for some course recommendations if I am interested in hardware architectures and model architecture scaling, and I was pleasantly surprised that it used context from my previous interactions to create a semester by semester course plan for me. I really enjoyed how Study Mode did not just give me the answer, but rather asked me follow up questions similar to how an in-person teacher would (interactive learning/active recall). This was my first time playing around with Study mode, and I will definitely be using it during RRR week to study course context and make sure I understand it (vs passively reading over AI solutions). I hope this study tool on Fermi Estimation is helpful to others, and I have provided my annotated traces / unannotated trace below.\n\ntrace: https://chatgpt.com/share/693618eb-456c-8005-9a98-6de49720855c\n\nannotated trace: ",
    "attachments": [
      {
        "name": "special_partic_E_fermi_estimation_gpt_5.1_hw11 2.pdf",
        "url": "https://static.us.edusercontent.com/files/mEqjDwWzxHd2JcFo4urlTTJN"
      }
    ],
    "highlight": false,
    "summary": "I utilized ChatGPT 5.1 Study Mode to understand the prereading-equivalent context behind Fermi Estimation and GPU power and memory, which was something I was relatively unfamiliar with before attempting these problems."
  },
  {
    "id": "ed-7428520",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: From Handwritten Notes to Exam-Oriented Review (Gemini)",
    "dek": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.\nI have developed an AI-assisted process that can convert my handwrit...",
    "student": "WeiYi Zhang",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428520"
    },
    "body_html": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.\nI have developed an AI-assisted process that can convert my handwritten class notes into structured learning guides. The key lies in whether this model can distinguish between core concepts and the content I emphasize in the notes but which is not crucial for overall understanding. Also, I tried to use prompts to effectively guide the model to maintain symbol consistency when reading screenshots of mathematical formulas (especially when reading handwritten notes).",
    "attachments": [
      {
        "name": "From Handwritten Notes to Exam-Oriented Review (Gemini).pdf",
        "url": "https://static.us.edusercontent.com/files/lGTe0Fk2DCO56gdsWOXovewh"
      }
    ],
    "highlight": false,
    "summary": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation."
  },
  {
    "id": "ed-7428423",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Verifying Written Answers in Colab",
    "dek": "Here, I created a tool that could assist with verifying written answers on homeworks or discussion by generating code on Colab that can simulate the behavior of a question, so in cases where a questio...",
    "student": "Rohan Gulati",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428423",
      "chatgpt": "https://chatgpt.com/share/6934d754-8630-8012-948a-e0b61ca5fce7"
    },
    "body_html": "Here, I created a tool that could assist with verifying written answers on homeworks or discussion by generating code on Colab that can simulate the behavior of a question, so in cases where a question involves generating a kernel or operations that result in exploding or vanishing gradients, this process can be visualized and tinkered with at the same time. \n\nI used ChatGPT and went through multiple iterations of this idea, encountering the following bugs. If not specified, the model would output code with the solution embedded explicitly in the code or in the conversation output. For example, when a problem asked to determine the kernel that correctly mapped an input and output, the code would store the correct kernel and test if the student answer was equal. Instead, while this can be be tuned further for generalizability, the model is instructed to not reveal the correct answer and evaluate the student response through operations or generated code, which currently behaves decently well. A big premise of the tool is to help with visualization and understanding rather than solving the problem, so the model is also instructed to guide the user towards arriving at the correct solution rather than stating the correct answer. However, for one example, the model mentioned part of a solution to part A of a question while producing the code to visualize part B.\n\nOverall, the tool proved to be helpful at the intended tasks and could be used to draw a line between written problems and patterns observed in implementation, a helpful method to reaffirm understanding after or while completing a problem.  \n\nConversation Log: https://chatgpt.com/share/6934d754-8630-8012-948a-e0b61ca5fce7 \n\nAnnotation with Code output & Colab Example: https://docs.google.com/document/d/1x_UR_ZI1of6Qw-OLIawqJkEo_R4tqdCLGepDpDhaod4/edit?tab=t.0 ",
    "attachments": [],
    "highlight": false,
    "summary": "Here, I created a tool that could assist with verifying written answers on homeworks or discussion by generating code on Colab that can simulate the behavior of a question, so in cases where a question involves generating a kernel or operations that result in exploding or vanishing gradients, this process can be visualized and tinkered with at the same time."
  },
  {
    "id": "ed-7428276",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Adapative AI-Mini Tutor With ChatGPT 5.1",
    "dek": "I have used ChatGPT to be my personal tutor for CS182. I have a prompt that gives some context of what the GPT should act and how it should be acting depending on how I answer the question.  I think o...",
    "student": "Minjune Kim",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428276"
    },
    "body_html": "I have used ChatGPT to be my personal tutor for CS182. I have a prompt that gives some context of what the GPT should act and how it should be acting depending on how I answer the question.  I think overall it was very useful because it was able to place me around the place where I thought I belonged, and it was able to give me a better understanding of the concept that I needed help on. \n\nI think having the option of GPT being able to adapt to the level of student's learning to the concept is something that will help out students a lot because not everyone is on the same page with the understanding of the concepts, and with this, everyone can be on the same level after using these prompts and learning more specifically about the confusing concepts that the class might bring or even answer some questions that they had. \n\nAnnotated Prompt: ",
    "attachments": [
      {
        "name": "In-context learning tutoring1-merged.pdf",
        "url": "https://static.us.edusercontent.com/files/Nc23Km5qQM8bTG6WUQ5X47oX"
      }
    ],
    "highlight": false,
    "summary": "I have used ChatGPT to be my personal tutor for CS182. I have a prompt that gives some context of what the GPT should act and how it should be acting depending on how I answer the question.  I think overall it was very useful because it was able to place me around the place where I thought I belonged, and it was able to give me a better understanding of the concept that I needed help on."
  },
  {
    "id": "ed-7428162",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Follow Up on Using ChatGPT to Help Understand Papers",
    "dek": "I wanted to revisit the issues raised in Post #284 and see whether we could get better results from ChatGPT by adjusting the setup. I repeated the same exercise, but with a few important differences:\n...",
    "student": "Etaash Patel",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428162"
    },
    "body_html": "I wanted to revisit the issues raised in Post #284 and see whether we could get better results from ChatGPT by adjusting the setup. I repeated the same exercise, but with a few important differences:\n\n1. Narrowed context.\n Instead of giving ChatGPT the entire paper (https://arxiv.org/pdf/2310.17813), I only provided the single page containing the claims and their justifications.\n\n2. Revised prompt.\n I rewrote the prompt to directly address the concerns mentioned in Post #284. In particular, I emphasized that the explanation should be:\n\nself-contained,\n\nwell structured, and\n\nwritten primarily in clear English prose.\n\nThe full prompt is below:\n\"Hello, I would like you to expand on the arguments given for the claims in a paper I am reading (A Spectral Condition ...). \nWhen doing so, could you please make sure your explanation is: \nA. Precise \nB. Easy to follow: proofs should be in English prose as much as possible (while still being precise) \nC. Self-Contained: Please try to only reference facts a CS182 student would know. If you need to include new facts/arguments, please state them in full before using them \nD. Well structured. \nAlso, at the end, please try to generate some questions to check conceptual understanding.\"\n\n3. Different models.\n I have a free trial of ChatGPT Pro, so I tested both the Pro model and the free model on the same prompt. Both were set to “Thinking Mode” before answering. Models were GPT 5 (for free version) and 5.1 (for paid version). \n\nOverall observations:\nUnsurprisingly, the Pro model produced a significantly stronger explanation. That said, I still found that the free model, after some coaxing, generated an explanation addressed some of the problems mentioned than the original response shown in Post #284. The one thing both models still suffer from is having a concise writeup (in both cases, the model's explanations are longer than needed). Much of this probably comes from the prompting though, as the prompt encourages the model to err on the side of too much detail. \n\nBoth transcripts are attached below.\n\n\n\n",
    "attachments": [
      {
        "name": "Expand on claims paper free version.pdf",
        "url": "https://static.us.edusercontent.com/files/wGFkN7QwEmh2RpDsnFwllmr9"
      },
      {
        "name": "Expand on paper claims pro version.pdf",
        "url": "https://static.us.edusercontent.com/files/Mbj2TzXUcFPuUwImVplAl2To"
      }
    ],
    "highlight": false,
    "summary": "I wanted to revisit the issues raised in Post #284 and see whether we could get better results from ChatGPT by adjusting the setup. I repeated the same exercise, but with a few important differences:"
  },
  {
    "id": "ed-7428155",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Gemini 2.5 Flash for Condensing Concepts",
    "dek": "I experimented with using Gemini 2.5 Flash to create lecture summaries (cheat sheet style) and iteratively condensing / shortening them to see what Gemini would keep as the most important material. \n\n...",
    "student": "Diana Kohr",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428155"
    },
    "body_html": "I experimented with using Gemini 2.5 Flash to create lecture summaries (cheat sheet style) and iteratively condensing / shortening them to see what Gemini would keep as the most important material. \n\nConversation: https://gemini.google.com/share/0354ec8fb0bd\n\nAnnotated: https://drive.google.com/file/d/15oZTdMiMxU1FsVwrkDjTQjLvUUiY-D5A/view?usp=sharing\n\nPrompts: \n\nTo generate initial summary: \"Please use the attached lecture notes to create a one page summary that has the most important concepts / equations. It's ok if small details, such as analogies, are omitted, but it should be sufficient as a cheat sheet on an exam.\"\n\nTo adjust distribution of content: \"Could you add more about the difference between DDPM and DDIM while keeping things concise, so everything fits on a page?\"\n\nTo shorten: \"This cheat sheet is too long, could you condense it?\"\n\nTakeaways: \n\nGemini does a good job with concisely summarizing concepts, but not as well in picking out important formulas / equations, especially when the original lecture notes contained lots of math for derivations. It did include important lines of pseudocode!\n\nThe lengthy explanations shrank as I instructed Gemini to condense the cheat sheet (expected). An interesting result was that more tables were added, which I liked. \n\nThe only major drawback is that Gemini (this version at least) didn't have the capability to include diagrams. In the summary for lecture 15, the column for diagrams of autoencoder variants was empty. Also, for some reason, it kept including this Getty Images diagram of an autoencoder, which wasn't super helpful. ",
    "attachments": [],
    "highlight": false,
    "summary": "I experimented with using Gemini 2.5 Flash to create lecture summaries (cheat sheet style) and iteratively condensing / shortening them to see what Gemini would keep as the most important material."
  },
  {
    "id": "ed-7428058",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Learning RNN with Sonnet 4",
    "dek": "When we were learning RNNs two months ago, I wasn't able to understand the lectures very well, and the topic was also not in the Prince's textbook. So I asked Claude to test my understanding of the to...",
    "student": "Jin Ying",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7428058"
    },
    "body_html": "When we were learning RNNs two months ago, I wasn't able to understand the lectures very well, and the topic was also not in the Prince's textbook. So I asked Claude to test my understanding of the topic by asking me one question at a time; this was my first time trying this and it helped me a lot in understanding concepts. So later in the semester, I tried this method also on many other topics, as well as for other classes, and had since improved the method a lot better over the semester. Rather than passively absorbing explanations, I had to actively reason through each concept—why we need weight sharing, how the hidden state acts as memory, why vanishing gradients occur, and how LSTMs solve this with additive updates. Claude would push back on incomplete answers (\"But let me push you further...\") and use concrete examples to guide my thinking toward insights I couldn't discover myself.",
    "attachments": [
      {
        "name": "RNN with Claude.pdf",
        "url": "https://static.us.edusercontent.com/files/Jk4BzVh4dlZuWAu8TOp1C6Rs"
      }
    ],
    "highlight": false,
    "summary": "When we were learning RNNs two months ago, I wasn't able to understand the lectures very well, and the topic was also not in the Prince's textbook. So I asked Claude to test my understanding of the topic by asking me one question at a time; this was my first time trying this and it helped me a lot in understanding concepts."
  },
  {
    "id": "ed-7427798",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Visualizing LLM Decoding",
    "dek": "For this participation assignment, I created an interactive LLM Decoding Visualizer that demonstrates how Large Language Models (like GPT-3.5) generate text one token at a time. It allows you to exper...",
    "student": "Vijay Kethanaboyina",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427798"
    },
    "body_html": "For this participation assignment, I created an interactive LLM Decoding Visualizer that demonstrates how Large Language Models (like GPT-3.5) generate text one token at a time. It allows you to experiment with inference-time parameters in real time to see how they affect the model output.\n\nTry it out for yourself here: https://www.vkethana.com/visualize_decode/\n\nA transcript of my conversation with the model can be found here: https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing. I used Cursor as my IDE for this assignment, and the actual model generations came from Gemini 3 Pro. The model performed well, and aside from a few edge cases it was able to one-shot all prompts I gave it.\n\nClass Concepts Covered:\n\nInference-Time Sampling: Recall that there was a discussion worksheet that covered the various LM sampling techniques. This tool builds off that content.\n\nGreedy Decoding: You can see what happens when the model is forced to always pick the single most likely token (Temperature = 0). There is a special button in the tool allowing you to enable greedy decoding.\n\nTemperature & Top-P: It visualizes how \"temperature\" flattens the probability distribution (making the model more creative/random) or sharpens it (making it more deterministic). The tool also gives you control over the value of p used for top-p sampling.\n\nTo use the interactive features, you'll need to provide your own OpenAI API key (due to inference costs, I am unable to host the model directly on my personal website). If you'd prefer not to use your API key, you're welcome to watch a video demo of the tool here: https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view",
    "attachments": [],
    "highlight": false,
    "summary": "For this participation assignment, I created an interactive LLM Decoding Visualizer that demonstrates how Large Language Models (like GPT-3.5) generate text one token at a time. It allows you to experiment with inference-time parameters in real time to see how they affect the model output."
  },
  {
    "id": "ed-7427555",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Muon",
    "dek": "For this Special Participation E, I made an interactive Muon tutor using a custom prompt for ChatGPT’s Study Mode. The goal was to turn Muon (Momentum Orthogonalized by Newton–Schulz) into a single co...",
    "student": "Reyna Liu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427555",
      "chatgpt": "https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee"
    },
    "body_html": "For this Special Participation E, I made an interactive Muon tutor using a custom prompt for ChatGPT’s Study Mode. The goal was to turn Muon (Momentum Orthogonalized by Newton–Schulz) into a single coherent story that lines up with the lecture content: starting from Shampoo and semi-orthogonal updates, then moving through Newton–Schulz style iterations, odd polynomials, normalization, and finally the full Muon update rule.\n\nThe tutor is designed to complement pre-lecture or post-lecture reading: instead of passively skimming notes, you interact with the model in a guided way, and it is forced (by the prompt) to:\n\nstay on one narrative arc (the “approximate (UV^\\top)” story),\n\nexplain each subtopic with intuition → light math → tiny example → concept check,\n\nnot move on until you answer its question.\n\nPrompt\n\nYou are my tutor for the Muon optimizer (“Momentum Orthogonalized by Newton–Schulz”) and the optimization ideas behind it in modern deep learning.\n\nI want this to be an interactive tutoring session. In every reply:\n\n- Keep your answer focused and reasonably short (about 3–6 short paragraphs).\n\n- Do not move on to the next topic until I say so.\n\n- Always end your message by asking me a specific question (for example: “Does this make sense?” or a small concept-check question), and then wait for my reply.\n\nThe overall story I want to learn is:\n\nHow Muon approximates an “ideal” semi-orthogonal update direction (like what Shampoo would give with SVD), but does it cheaply using Newton–Schulz style iterations and polynomials that operate on singular values, plus a momentum-like accumulator.\n\nPlease organize everything as one coherent narrative, not a bag of tricks.\n\nStep 1: Short big-picture intro\n\nFirst response:\n\n1. In at most 2 short paragraphs, explain:\n\n - What problem Muon is trying to solve:\n\n - Shampoo-style methods want to precondition gradients using information like singular values / curvature, but exact SVD-based updates are too expensive.\n\n - We would like an update direction that behaves like “U Vᵀ” from an SVD, i.e., semi-orthogonal and not dominated by large singular values.\n\n - The core idea of Muon in one or two sentences:\n\n - Muon keeps a momentum-like running matrix, then repeatedly applies a simple polynomial transformation (a Newton–Schulz–style iteration) so that its singular values are pushed toward 1, approximating that semi-orthogonal “U Vᵀ” direction without doing a full SVD.\n\n2. Then give a brief roadmap (4–7 bullet points) of the main pieces of the story, all explicitly framed as supporting Muon, for example:\n\n - From “optimizer recipe” with a chosen norm to the idea of spectral norm and semi-orthogonal updates.\n\n - Shampoo and “Shampoo without accumulation” as the starting conceptual algorithm.\n\n - Why computing the exact SVD-based direction is too expensive, and why an approximate direction is good enough.\n\n - Newton–Schulz–style iterations as a way to adjust singular values toward 1.\n\n - Odd polynomials that operate on singular values while keeping singular vectors fixed, and why that matters.\n\n - Stability issues: why we need to normalize by something like the Frobenius norm so that singular values start in the right range and iterations don’t blow up.\n\n - The final Muon update: momentum buffer, orthogonalization via polynomial iterations, weight update, and how the choice of polynomial coefficients affects behavior.\n\nEnd your first reply by asking me one short question to check my high-level understanding.\n\nAfter I respond, start with the first item in the roadmap (semi-orthogonal / spectral-norm view). Follow the roadmap in order.\n\nStep 2: For each part of the story\n\nWhen we are on a given part of the roadmap, teach it in four layers, but keep each message compact.\n\n1. Intuition tied to Muon\n\n - In 1–2 short paragraphs, explain the idea in plain language and explicitly say how it supports Muon’s overall goal:\n\n - Approximating a well-conditioned, semi-orthogonal update direction.\n\n - Making steps more uniform across directions instead of being dominated by the largest singular value.\n\n - Doing this without paying the full SVD cost.\n\n2. Key formal setup\n\n - Introduce only the minimal notation you need, such as:\n\n - A weight matrix and its gradient.\n\n - The idea that you can factor a matrix into singular vectors and singular values.\n\n - A momentum-like buffer that accumulates gradient information over time.\n\n - A simple iteration that applies a polynomial in the matrix (for example, a combination of a linear term and a cubic term) to reshape singular values.\n\n - Describe what each object means verbally (for example, “this buffer stores a smoothed version of recent gradients”, “this transformation tries to make all singular values close to 1 so the matrix behaves like a semi-orthogonal matrix”).\n\n - You may show a very small symbolic expression or a short iteration rule, but keep it high-level and do not dump long formulas.\n\n3. Tiny numerical or conceptual example\n\n - Give one very small example to illustrate the effect:\n\n - For instance, a 2×2 matrix whose singular values are very different, and describe qualitatively what happens when you apply one or two polynomial iterations to it (the large singular value goes down, the small one goes up, etc.).\n\n - Or a toy picture of “before” vs. “after” for singular values, and how that makes the update more uniform across directions.\n\n - Keep this example to a few lines.\n\n4. Quick understanding check\n\n - Ask me 1–2 short questions related to this part:\n\n - At least one conceptual “why” question (for example: “Why is it good if all singular values are close to 1?” or “Why do we want a polynomial that keeps singular vectors but changes singular values?”).\n\n - Optionally, a tiny computational or thought experiment question (for example: “What might go wrong if the singular values start out too large before applying the iteration?”).\n\n - Then stop and wait for my answer.\n\nAfter, briefly remind me what the next stop in the Muon story is, and then proceed.\n\nStep 3: Muon-centered wrap-up\n\nWhen I say I’m ready to review or summarize:\n\n- Give a compact summary that keeps Muon at the center, explaining how:\n\n - Starting from an “optimizer recipe” with a chosen norm leads to preferring semi-orthogonal directions (like U Vᵀ).\n\n - Shampoo (and its non-accumulating variant) motivates this direction but is too expensive if done with an exact SVD.\n\n - Newton–Schulz–style polynomial iterations let us approximate “replace all singular values by 1” using only matrix multiplications.\n\n - Normalizing by something like the Frobenius norm ensures the singular values start in a safe range so the iterations stay stable.\n\n - Muon wraps this into a practical algorithm: maintain a momentum buffer, apply a few iterations of a chosen polynomial to orthogonalize it, then use that to update the weights.\n\nThroughout the conversation, keep answers reasonably short, interactive, and always connected back to the central Muon story, so that the whole interaction feels like a focused tutoring session.\n\nLink to conversation:\n\nhttps://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee\n\nAssessment\n\nThe good:\n\nConceptually, the model’s output is very close to the actual lecture storyline. It correctly emphasized:\n\nThe role of (UV^\\top) as the “semi-orthogonal ideal” direction.\n\n\n\nThe connection between Shampoo and this ideal (a hypothetical “Shampoo without accumulation” step).\n\n\n\nThe idea that Newton–Schulz–like odd polynomials act as scalar functions on singular values, while preserving the singular vectors.\n\n\n\nThe importance of normalizing the buffer so the polynomial iteration doesn’t blow up or collapse.\n\nI didn’t spot any major conceptual contradictions with the lecture. The main approximations were in the toy numerical examples (e.g., saying a singular value might move from 0.01 to “something like 0.2-0.5” after one step without actually computing it). That’s not “wrong” in a dangerous way, but it’s clearly hand-wavy.\n\nThe bad:\n\nRepetitive concept checks.\nIt kept asking essentially the same question in slightly different forms: “Why is it good if singular values are close to 1?” “Why do we want a well-conditioned update?” “Why is it useful that singular vectors stay the same?”\nThese questions are reasonable the first time; by the third time, it felt redundant and didn’t add new understanding.\n\n\n\nHand-wavy numbers in examples.\nIn a few places it invented specific numeric values like “after one step this might be around 0.2-0.5” without actually computing the polynomial. This is minor, but it’s a reminder: whenever it gives specific numbers in these toy examples, treat them as qualitative (direction of change) rather than precise quantitative claims.\n\n\n\nBehavior when the user can’t really answer its questions.\nThe prompt forces it to ask me a “concept check” every turn, but it doesn’t actually check my answers or detect if I’m confused. In our interaction it basically replied “Exactly” to everything and then continued. So if a student can’t answer, or answers something half-baked, the model will not push back on its own. The student has to explicitly tell the model to explain. It’s too “polite”to be a real grader for students.\n\n\n\nOverall, though, the interaction did not hallucinate big structural facts. The misbehavior was more minor.\n\nHow this could help with learning\n\nIn practice, this tool works well as a pre- or post-lecture companion:\n\nBefore the lecture, we can run through Part 1-3 to get the high-level picture of “why semi-orthogonal,” “how Shampoo motivates the ideal,” and “why approximate is enough,” so we’re not seeing those ideas for the first time in class.\n\nAfter the lecture, we can use Parts 4-7 to re-derive the Newton–Schulz connection, the odd polynomial behavior, the normalization step, and the final Muon update rule, while the model keeps quizzing us.\n\nIt can function as a self-paced interactive reading that is much closer to our actual lecture content than a random internet explanation. The main caveats are:\n\nBe aware it may ask very similar concept checks multiple times.\n\nTreat any made-up numbers in the tiny examples as qualitative intuition, not exact math.\n\nRemember it doesn’t really grade your answers. If you’re lost, you need to tell it explicitly to slow down or re-explain.\n\nUse it to structure understanding, but verify key equations and details against the lecture itself if you care about full rigor.\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "For this Special Participation E, I made an interactive Muon tutor using a custom prompt for ChatGPT’s Study Mode. The goal was to turn Muon (Momentum Orthogonalized by Newton–Schulz) into a single coherent story that lines up with the lecture content: starting from Shampoo and semi-orthogonal updates, then moving through Newton–Schulz style iterations, odd polynomials, normalization, and finally"
  },
  {
    "id": "ed-7427549",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: µP",
    "dek": "I designed a prompt that turns ChatGPT’s Study Mode into an interactive tutor for the maximal update parameterization (µP) lecture.\n\nThe goal is to replace a passive pre-lecture/post-lecture reading w...",
    "student": "Reyna Liu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427549",
      "chatgpt": "https://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a"
    },
    "body_html": "I designed a prompt that turns ChatGPT’s Study Mode into an interactive tutor for the maximal update parameterization (µP) lecture.\n\nThe goal is to replace a passive pre-lecture/post-lecture reading with an active dialogue that walks through the µP story in order:\n\nwhy µP was introduced,\n\n\n\nhow norms and RMS–RMS–style measures are used to control update size,\n\n\n\nhow the outer-product structure of linear-layer gradients simplifies the math,\n\n\n\nhow sign-based updates and width scaling affect update norms,\n\n\n\nhow CLT-style scaling motivates the parameterization,\n\n\n\nand how all of this connects to feature learning vs. lazy training.\n\n\n\nThe prompt enforces short, interactive replies and forces the model to keep µP as the central theme, instead of dumping a long wall of text.\n\nPrompt\n\nYou are my tutor for maximal update parameterization (µP) and the optimization ideas around it in modern deep learning.\n\nI want this to be an interactive tutoring session. In every reply:\n\n- Keep your answer focused and reasonably short (roughly 3–6 short paragraphs or equivalent).\n\n- Do not move on to the next topic until I say so.\n\n- Always end your message by asking me a specific question (for example: “Does this make sense?” or a small concept-check question), and then wait for my reply.\n\nThe overall story I want to learn is:\n\nHow µP is designed so that neural networks of different widths have comparable update behavior, and how all the surrounding concepts (norms, the simple outer-product structure of gradients in linear layers, sign-based updates, learning-rate scaling, CLT-style scaling analogy, and feature-learning conditions) fit into this one story.\n\nPlease organize the material around µP as one coherent narrative, rather than separate tricks.\n\nStep 1: Very short big-picture intro\n\nFirst response:\n\n- In at most 2 short paragraphs, explain:\n\n - What problem µP is trying to solve (e.g., transferring learning rates from small to large models, making training behavior less sensitive to width).\n\n - The core idea in one or two sentences (e.g., keeping effective update magnitudes comparable across widths).\n\n- Then give a brief roadmap (4–7 bullet points) of the main pieces of the story, all explicitly framed as supporting µP, for example:\n\n - Controlling update size via norms.\n\n - RMS–RMS-type norms to measure update size across layers.\n\n - Using the outer-product (rank-1 for batch size 1) structure of linear-layer gradients as a simple tool to analyze norms and update sizes.\n\n - How sign-based updates interact with these norms.\n\n - Learning-rate scaling with width (fan-in / fan-out) and how µP encodes this.\n\n - CLT-style scaling intuition for width limits.\n\n - Feature-learning conditions in wide networks and how µP targets them.\n\n- End your first reply by asking me one short question to check my high-level understanding. In your next reply (after I respond), start with the first item in the roadmap (controlling update size via norms). Do not ask me to choose the order; follow the roadmap in order.\n\nStep 2: For each part of the story\n\nWhen we are on a given part of the roadmap (for example “RMS–RMS norms and update size”, “outer-product gradient structure as a tool”, “learning-rate scaling with width”, or “feature-learning conditions”), teach it in four layers, but keep each message compact:\n\n1. Intuition tied to µP\n\n - In 1–2 short paragraphs, explain the idea in plain language and explicitly say how it supports the overall µP goal (making updates comparable across widths / keeping training behavior width-stable / enabling feature learning at large width).\n\n2. Key formal setup and equations\n\n - Introduce the simplest useful mathematical setup: weight matrix W, input x, gradient ∇_W L, layer width, fan-in, fan-out, etc.\n\n - State the most relevant equations, such as:\n\n - The gradient of a linear layer for a single example having an outer-product form g x^T (rank-1), used mainly as a convenient way to analyze its norms and scaling.\n\n - A reasonable way to measure update size (e.g., some RMS-style norm).\n\n - A simple example of how learning rate might scale with width or fan-in/fan-out to keep that update size roughly constant.\n\n - When appropriate, express conditions like “activations h_\\ell stay O(1)” and “updates \\Delta h_\\ell stay O(1) as width grows”, and link that to constraints on \\|W_\\ell\\| and \\|\\Delta W_\\ell\\|.\n\n - Explain the meaning of each symbol in words.\n\n3. Tiny numerical example\n\n - Give one small concrete example with simple numbers (e.g., a 2×3 layer, or doubling the width) to show what changes and how a scaling rule helps keep updates comparable.\n\n - Keep this to a few lines.\n\n4. Quick understanding check\n\n - Ask me 1–2 short questions related to this part:\n\n - At least one conceptual (“why”) question.\n\n - Optionally one small calculation (e.g., rank of a gradient matrix, or what happens to update size when width doubles without scaling the learning rate).\n\n - Then stop and wait for my answer, instead of answering your own questions.\n\nWhen I indicate that I am done with the current part and ready to move on, proceed to the next item in the roadmap in order, briefly reminding me which part comes next in the µP story.\n\nStep 3: µP-centered wrap-up\n\nWhen I say I’m ready to review or summarize:\n\n- Give a compact summary that keeps µP at the center, explaining how:\n\n - Norms and RMS–RMS-like measures define what it means for updates to be “the same size” across widths.\n\n - The simple outer-product structure of gradients makes it easy to relate different norms and see how update size scales with width.\n\n - µP encodes scaling rules so that small and large models see comparable effective updates.\n\n - Feature-learning conditions on h_\\ell and \\Delta h_\\ell motivate µP’s design choices.\n\n- Propose a small set of practice questions (both conceptual and short derivations) that someone could solve to check their understanding of µP and the surrounding ideas.\n\n- Then stop and wait for my answer, instead of answering your own questions.\n\nThroughout the conversation, keep answers reasonably short, interactive, and always connected back to the central µP story, so that the whole interaction feels like a focused tutoring session.\n\nLink to Conversation\n\nhttps://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a\n\nInteraction\n\nMotivation for µP\n\nThe answer matches the lecture well. The lecture explicitly motivates µP as a way to choose the “right units” and scaling so that the same hyperparameters work at different widths, and we can search on small models and transfer to large ones. The AI also adds a nice refinement: hyperparameters transfer because effective updates have comparable size. That’s clearly aligned with the RMS–RMS induced norm idea from class.\n\nFrobenius norm\n\nThe high-level contrast is good: Frobenius norm grows with number of parameters, while RMS is more “width-invariant”. The lecture also emphasizes using an RMS–RMS induced norm instead of a raw spectral/Frobenius norm so we can have a single scalar that behaves well across layers and widths.\n\nBut the numerical language is sloppy: “double the width and the Frobenius norm doubles” is not generally true. In the typical i.i.d. setup, the Frobenius norm grows like (number of parameters)^(0.5), not linearly. \n\nAlso, compared to the lecture, the AI never explicitly mentions that we’re using RMS-RMS as an induced norm that upper-bounds the spectral norm and gives layer-specific effective step sizes. That’s an important part of the lecture that’s missing here.\n\nEffective update size\n\nThis is basically what the lecture is implicitly using when it talks about RMS–RMS induced norms. The lecture goes through induced norms / sub-multiplicativity, whereas the AI jumps straight to this “product of RMS” heuristic.\n\nHowever, it never connects back to the more formal induced-norm inequality we actually saw in class. The formal induced-norm framing is missing.\n\nOuter-product / low-rank gradient structure\n\nThis is the key observation: the RMS gradient does not depend on width at all. The outer-product formula is exactly what was derived in the lecture.\n\nThe algebra for Frobenius and RMS norms is basically correct, but it is not exactly the argument in the lecture. In class, the rank-1 structure is mainly used to say rank-1 ⇒ spectral norm = Frobenius norm, which makes it easy to relate the sign matrix S and its norms, and to design a step size for signSGD/Adam that keeps the RMS-RMS fixed.\n\nThe AI instead focuses on RMS(∇W) being width-independent, which is a reasonable extrapolation but not literally what is emphasized in the lecture.\n\nSign-based updates\n\nThe AI is vaguely aligned with the idea of signSGD, but it stays very high-level, and doesn’t connect sign-based updates back to the RMS–RMS induced norm recipe. Not hallucinating, but also not actually teaching the signSGD part of the lecture.\n\nLearning-rate scaling with width\n\nIt’s qualitatively right that learning-rate must depend on fan-in, but the ‘1/d_in’ rule is presented as a universal principle, which is not justified from the lecture notes or the original µP paper.\n\nCLT analogy\n\nThis is very close to what happens in the lecture. It explicitly recalls the CLT, shows how a scaling factor keeps the limit non-trivial, and then asks if we can do something similar for neural nets / hyperparameters. The derivation is correct and is a nice concrete restatement of Xavier-style reasoning.\n\nFeature-learning\n\nThis matches the spirit of the “conditions for feature learning” notes in the lecture. The AI brings in NTK/lazy-training terminology, which is consistent with the broader literature and explains why those O(1) conditions matter.\n\nOverall story\n\nThis is a nice high-level summary, and aligns with several concrete lines in the notes:\n\nHyperparameter transfer from small to large models.\n\nChoosing the right “units” / parameterization to make that possible.\n\nConditions for feature learning expressed as O(1) constraints.\n\n\n\nOverall assessment\n\nWhat it does well:\n\nKeeps the µP story coherent.\n\nRepeats several key ideas: hyperparameter transfer, O(1) activations/updates, width-stable dynamics.\n\nThe outer-product derivation of RMS(∇W) are correct and and the CLT variance argument is helpful for intuition.\n\nWhat it doesn’t do well:\n\nQuantitative statements about norm scaling (e.g., “Frobenius norm doubles”) are sloppy and should be re-derived.\n\nThe treatment of learning-rate scaling is oversimplified. It presents “learning rate ∝ 1/d_in” as a universal µP rule without actually deriving it.\n\n\n\n\nHow I would use it:\n\nI’d use this AI tutor as a conceptual organizer. If I forget the big picture of why µP exists or how CLT and O(1) conditions fit together, this is a good interactive refresher.\n\n\n\nI would not rely on it for precise hyperparameter scaling formulas or optimizer details; those need to be checked against the actual lecture notes and/or the Yang 2022 µP paper.\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "I designed a prompt that turns ChatGPT’s Study Mode into an interactive tutor for the maximal update parameterization (µP) lecture."
  },
  {
    "id": "ed-7427489",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Learning Optimization by spotting mistakes in AI generated answers with a custom Gemini Gem",
    "dek": "I built a custom Gemini gem that teaches optimization concepts by intentionally giving you flawed explanations and guiding you to catch the errors. I'm sharing two versions of the Gem (structured and ...",
    "student": "Imra Dawoodani",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427489"
    },
    "body_html": "I built a custom Gemini gem that teaches optimization concepts by intentionally giving you flawed explanations and guiding you to catch the errors. I'm sharing two versions of the Gem (structured and conversational) plus annotated transcripts showing what worked, what didn't, and where the AI made mistakes I had to catch. I made V2 after I played around with V1 and wasn't satisfied with the learning outcome it produced.\n\nV1: https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharing\nV2: https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharing\n\nAnnotated V1 transcripts:\n\nAnnotated V2 transcript:\n\nMy observations:\n\n",
    "attachments": [
      {
        "name": "gemini.google.com-Google Gemini-fpscreenshot (1).pdf",
        "url": "https://static.us.edusercontent.com/files/fyOdPjYRKh3cZF6KYQDYd08c"
      },
      {
        "name": "gemini.google.com-Google Gemini-fpscreenshot.pdf",
        "url": "https://static.us.edusercontent.com/files/Qu9hv9enrHjqIf6V4pgueUeL"
      },
      {
        "name": "gemini.google.com-Google Gemini-fpscreenshot (2).pdf",
        "url": "https://static.us.edusercontent.com/files/ZbC4dXX9mfccdFiA8Eb90zvj"
      },
      {
        "name": "special participation E - mistaker.pdf",
        "url": "https://static.us.edusercontent.com/files/XTToFU3qMCqp32fDN5IUZ7kf"
      }
    ],
    "highlight": false,
    "summary": "I built a custom Gemini gem that teaches optimization concepts by intentionally giving you flawed explanations and guiding you to catch the errors. I'm sharing two versions of the Gem (structured and conversational) plus annotated transcripts showing what worked, what didn't, and where the AI made mistakes I had to catch."
  },
  {
    "id": "ed-7427394",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: HW0 Prerequisite Content Helper",
    "dek": "I used the ChatGPT 5.1 Thinking model under study mode to help go over pre-requisite content found in Homework 0. I told the model that they are a helper and the goal is to refresh the content found i...",
    "student": "Carolyn Liu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427394"
    },
    "body_html": "I used the ChatGPT 5.1 Thinking model under study mode to help go over pre-requisite content found in Homework 0. I told the model that they are a helper and the goal is to refresh the content found in homework 0 but now actually solve any of the problems. The first thing the model did was ask how comfortable I was with the pre-requisite content, which I appreciated since it tailored the difficulty of the questions from it. Afterwards, they kept on asking questions and explained why some of my answers were incorrect. I believe this is a good prompt to help students with the linear algebra content and basic ML concepts before diving into Homework 0.\n\nI have attached my conversation and also a good starting prompt for this below:",
    "attachments": [
      {
        "name": "Special Participation E_ HW0 Prerequisite Content Helper.pdf",
        "url": "https://static.us.edusercontent.com/files/PTDDF0LMrJFrducr1IRuyFDG"
      }
    ],
    "highlight": false,
    "summary": "I used the ChatGPT 5.1 Thinking model under study mode to help go over pre-requisite content found in Homework 0. I told the model that they are a helper and the goal is to refresh the content found in homework 0 but now actually solve any of the problems."
  },
  {
    "id": "ed-7427288",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: AI-Generated Quiz Tool for lectures",
    "dek": "Hi everyone,\nFor the AI learning-tools option, I built a small quiz-generator assistant that can help generate exam-style question for you to test your understanding on specific field. I use ChatGPT 5...",
    "student": "Jerry Xiao",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427288"
    },
    "body_html": "Hi everyone,\nFor the AI learning-tools option, I built a small quiz-generator assistant that can help generate exam-style question for you to test your understanding on specific field. I use ChatGPT 5.1 to interact with and use the Project functions to help me generate the problem sets.\n\nHere is a short, simple, clean Ed post for your second interaction (the Diffusion quiz generator).\n This version is minimal and directly hits the assignment requirements.\n\n1. Prompt \n\nI want you to become a quiz generator for me to evaluate my learning progress. \nI want you to generate questions on Generative Model like Diffusion. \nPlease follow the style of the second file to generate the problems. \n[Append lecture note and example question here]\n\nThen I asked questions as:\n\n“Generate Quiz Set 1.”\n\n“Give me solutions.”\n\n“Generate Set 2.”\n\n“Draw a picture comparing DDPM and DDIM.”\n\n2. What it do good\n\nIt matched the HW format surprisingly well (short structured questions).\n\nThe explanations were clear and aligned with the lecture.\n\nThe DDPM vs DDIM diagram was helpful for intuition.\n\n3. What it do bad\n\nSometimes it added extra comments not in the lecture.\n\nIt was a bit too confident in referencing lecture page numbers.\n\nSketches were descriptive, not actual images (which is fine for learning but not literal HW format).\n\nYou can use this way to quiz yourself before homework/exams, get practice problems instantly, ask for more sets at different difficulty levels.\n\n",
    "attachments": [
      {
        "name": "gpt_interaction_2.pdf",
        "url": "https://static.us.edusercontent.com/files/tesuegU502lGWS0leYQGdy7X"
      }
    ],
    "highlight": false,
    "summary": "For the AI learning-tools option, I built a small quiz-generator assistant that can help generate exam-style question for you to test your understanding on specific field. I use ChatGPT 5.1 to interact with and use the Project functions to help me generate the problem sets."
  },
  {
    "id": "ed-7427284",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Homework Checker and Mistake Summarizer",
    "dek": "When going over homework, one of the most important things to do is to list out all the mistakes and make sure not to do that again. For this special participation, I created a pipeline to 1) check th...",
    "student": "Joshua Lu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427284"
    },
    "body_html": "When going over homework, one of the most important things to do is to list out all the mistakes and make sure not to do that again. For this special participation, I created a pipeline to 1) check the homework and make a list of things that are wrong and 2) make a summary of the mistakes, areas of improvement, areas of strength, and a list of potential reminders on what to be careful of. I used to do this manually when studying for finals in the past, so having an LLM do this would streamline the process.\n\nThe first step is to have the LLM correct the homework. For this, I used Gemini 3 Pro (With Thinking), and I sent the model a pdf of my handwritten homework solutions and a pdf of the official staff solutions. I tried this out with both Homework 9 and Homework 0. Homework 9 contains a lot more conceptual questions while Homework 0 contains a lot more math questions. This will let me test how well the model can grade and analyze each one.\n\nThe model actually did pretty well for most of Homework 9. I purposefully left a few mistakes to see if Gemini can catch it, and surprisingly, it did for all of them. In fact, for one of the questions, I made an arithmetic error that doesn't affect my final answer, but Gemini was still able to catch it, despite my work being handwritten. It's definitely really good at catching these small details. However, for the last question, Question 6, the problem itself required complexity calculations, and my work was completely off, yet Gemini did not note that and assumed I was just misreading the problem. That was when I got suspicious that maybe the model isn't great at more complex, mathematical homeworks.\n\nBefore moving on to the next homework, I also prompted the model to produce a list of my mistakes, areas of improvement, areas of strength, and things to watch out for when taking an exam. I wouldn't say it did amazing on this, but some of the information it gave was still useful. For things to watch out for, that part was not great. All the information it generated was very general and not very helpful, so I tried re-prompting, and it only got a bit better.\n\n\n\nI also tried out this approach with Homework 0, and just as before, it was able to identify my mistakes very well. It found that I solved the first few questions very well, and that I only messed up later on for the last question. However, for the very last question that required a lot of math, it wasn't really able to analyze my work well, and diff it from what is given in the official solution. And just as before, it was able to give a solid checklist of mistakes, things to improve on, and things I should watch out for, but the information is still a bit too general. It could be useful for last-minute prep.\n\n\n\nThere are definitely limitations with using LLM to check homework and analyze hand-written work. It did perform better than I expected, as giving it a pdf, it was able to analyze everything in a single go and identify most things correctly. However, this type of LLM approach should still definitely be used in conjunction with manually going over the homework, but I think it's nevertheless helpful.\n\n\n\nAnnotated Trace: https://drive.google.com/file/d/1CeAMUfZ0uiBXgAkjJxPPa1OtjwzVH0GK/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "When going over homework, one of the most important things to do is to list out all the mistakes and make sure not to do that again. For this special participation, I created a pipeline to 1) check the homework and make a list of things that are wrong and 2) make a summary of the mistakes, areas of improvement, areas of strength, and a list of potential reminders on what to be careful of."
  },
  {
    "id": "ed-7427268",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Multi-Level Discussion Summarizer and Key Notes Extractor with Gemini 3 Pro",
    "dek": "I always want to make sure that I have all my notes in one place, and one additional source of very useful information is the Discussion. Discussion covers a lot of content, some of them being new con...",
    "student": "Joshua Lu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427268"
    },
    "body_html": "I always want to make sure that I have all my notes in one place, and one additional source of very useful information is the Discussion. Discussion covers a lot of content, some of them being new content as well, and the information covered in discussion definitely belongs in the notes. For this special participation, I will specifically be working with Discussion 10 (Transformers). The goal of this special participation is to extract the key concepts from the discussion worksheet in note form, but with a twist: The notes should have two section, a main key concepts section and a second deep-dive section. This summary should include details that go beyond what can be found in the discussion and should be a comprehensive review guide.\n\nI used Gemini 3 Pro (With Thinking) for this special participation. My process is the following: to start off, I gave the model a simple prompt with my goal:\n\n\"Summarize the key learning concepts in Discussion 10 on Transformers. Provide the key learning concepts in bullet-point form. Make sure to emphasize what is important to know. This first part should be more general, main ideas.\n\nThen, make a second section where you go deeper into each concept and again provide a list of the key details.\"\n\nThrough this, the model gave a basic summary which was not detailed enough. Then, through an iterative process, I improved the summary of the discussion by asking the model about specific details that comes from the discussion. For Discussion 10 specifically, this included the math for RoPE and the complexity derivations for self-attention and cross-attention. After a few iterations, the model learned about the specific types of details I was looking for and at the end, I asked it to regenerate the summary in a form I can paste into my notes. It's clear from my experiment that the model cannot easily one-shot a good enough summary for me to use, so repeated prompting is necessary to get something useful.\n\nThe good part about this model was that it generally got everything correct. Since the goal is to summarize and review information, it did not hallucinate, and I verified the information looks good. However, one issue of using the chat interface is that the formatting isn't great. Each time I want a new summary, the model has to regenerate it entirely, and the chat log gets very messy.\n\nAfter I got my summary, I then had the model look through the homework and indicate which concepts I should already know based on the discussion, and which concepts I should review in preparation for the homework. This multi-level summary is very useful for me to not just look back later on to review important information from discussion but also help me prepare to do the homework in a setting where I don't need to constantly refer back to notes.\n\n\n\nHere is the trace without annotations: https://gemini.google.com/share/5db1aec72092\n\nHere is the trace with annotations: https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "I always want to make sure that I have all my notes in one place, and one additional source of very useful information is the Discussion. Discussion covers a lot of content, some of them being new content as well, and the information covered in discussion definitely belongs in the notes. For this special participation, I will specifically be working with Discussion 10 (Transformers)."
  },
  {
    "id": "ed-7427197",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Minimally Wrong MCQ Diagnostic Learning Tool",
    "dek": "In this special participation, I create a prompt and test how ChatGPT can generate multiple choice questions with “distractor” answers that are minimally wrong. This is meant to emulate what I typical...",
    "student": "William Li",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7427197"
    },
    "body_html": "In this special participation, I create a prompt and test how ChatGPT can generate multiple choice questions with “distractor” answers that are minimally wrong. This is meant to emulate what I typically found most difficult in MCQ questions, which is when all the wrong answers seem plausible and can only be discerned as wrong by identifying subtle mistakes. To this end, I wanted to try to use LLMs to generate these sorts of questions. Additionally, perhaps the hallucinations that these LLMs so often generate could be useful in creating wrong answers that sound correct.\n\nUpon testing out this prompt and studying technique, I was very satisfied with what the model was able to give me. I asked it several questions spanning different topics (optimization, attention, transformers etc.) along with different modalities (purely conceptual, mathematical, coding), and it was able to give me very succinct MCQs for these. The answer choices it generated were also very good, and it was quite tricky choosing between the answers sometimes. After answering (and getting the question right or wrong), the model was able to give me the reasonings behind each of the answers. For the correct answer, it gave the reasons as to why it is correct, and for the incorrect answers it explained the subtle bug or misconception that led to the error. Overall, I think this was a good learning experience and I would certainly use this to study more concepts before the final rolls around. \n\nAnnotated Trace: ",
    "attachments": [
      {
        "name": "mcq (1).pdf",
        "url": "https://static.us.edusercontent.com/files/sSdCgJfEzSRTNZULjaXMxeod"
      }
    ],
    "highlight": false,
    "summary": "In this special participation, I create a prompt and test how ChatGPT can generate multiple choice questions with “distractor” answers that are minimally wrong. This is meant to emulate what I typically found most difficult in MCQ questions, which is when all the wrong answers seem plausible and can only be discerned as wrong by identifying subtle mistakes."
  },
  {
    "id": "ed-7426886",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Studying Optimizers with NotebookLM",
    "dek": "For the \"AI-enhanced learning tools\" option, I explored NotebookLM to study the recent lectures on Optimizers. My goal was to create an active alternative to traditional pre-reading/post-reading by ha...",
    "student": "Nikhil Mathihalli",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7426886"
    },
    "body_html": "For the \"AI-enhanced learning tools\" option, I explored NotebookLM to study the recent lectures on Optimizers. My goal was to create an active alternative to traditional pre-reading/post-reading by having the AI synthesize the lecture recordings, notes, and homework solutions into a cohesive study guide.\n\nI uploaded the YouTube lecture audio recordings alongside the raw lecture notes. NotebookLM was able to \"listen\" to the lectures and cross-reference them with the written notes.\n\nOne of the coolest features was generating visual aids to structure my learning before diving into the weeds.\n\nThe Mind Map: I asked it to generate a mind map immediately1. This gave me a hierarchy of concepts—linking Taylor Expansions to Lazy Training, and Initialization to RMS Norms—which acted as a roadmap for what questions I needed to ask.\n\nThe Slideshow: I asked it to create a slideshow explaining optimizer concepts with visuals. It generated a dense, informed presentation in about 5 minutes. While the visuals were AI-generated, the structure helped me verify if I could explain the concepts linearly.\n\nThrough trial and error, I found a \"Drill-Down\" strategy worked best:\n\nStart Broad: I began with, \"Can you give me an overview of ALL the concepts... generate a roadmap\". This forced the model to establish context.\n\nSelect & Zoom: Instead of letting it ramble, I picked specific nodes from its roadmap: \"Let's start with the lazy training assumption. What is it, and why is it important?\"\n\nComparative Analysis: For distinct lists, I asked for comparative breakdowns: \"Can you go over every initialization... advantages/disadvantages to each?\" This yielded structured tables rather than walls of text.\n\nWhile the high-level summaries were coherent, the model often flattened subtle mathematical distinctions. I have annotated these in the attached PDF, but here are the key warnings:\n\nOversimplifications: The model correctly identified that parameters move by small amounts in training, but it implied that gradient features are fixed features simply because of the assumption. It failed to clarify that this is a specific regime (Kernel/NTK) and not how realistic modern \"feature learning\" regimes work\n\nBias Initialization Depth: The model listed strategies like \"initialize at 0\" or \"0.01\" but completely lacked the reasoning for why (e.g., why zero bias doesn't cause symmetry issues like zero weights do)\n\nMissing Geometric Intuition: When explaining algorithms like SignSGD, it gave the formula but missed the geometric intuition (that infinity norm constraints lead to coordinate-wise updates)\n\nConclusion\n\nNotebookLM is a powerful \"active reading\" partner, especially for synthesizing multimodal sources (audio + text). However, it struggles with the deep \"why\" behind some mathematical proofs. Overall, I think it's extremely useful for learning large amounts of content in a structured yet quick manner.\n\n\n\nTrace:",
    "attachments": [
      {
        "name": "NotebookLM Chat.pdf",
        "url": "https://static.us.edusercontent.com/files/QFrg7pTp21fLlcSlbWOR77fQ"
      }
    ],
    "highlight": false,
    "summary": "For the \"AI-enhanced learning tools\" option, I explored NotebookLM to study the recent lectures on Optimizers. My goal was to create an active alternative to traditional pre-reading/post-reading by having the AI synthesize the lecture recordings, notes, and homework solutions into a cohesive study guide."
  },
  {
    "id": "ed-7426845",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT 5.1 Thinking Study Mode on LoRA",
    "dek": "\n\nI used the ChatGPT 5.1 Thinking model under the study mode to have it go over LoRA before I start the homework assignment. It did a good job going over the contents within the lecture and asked ques...",
    "student": "Carolyn Liu",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7426845"
    },
    "body_html": "\n\nI used the ChatGPT 5.1 Thinking model under the study mode to have it go over LoRA before I start the homework assignment. It did a good job going over the contents within the lecture and asked questions to ensure my understanding. Under study mode, it continues to ask me questions that are directly related to what was taught in lecture without needing reminders or any prompting that I am studying before completing a homework assignment. I would say the model does a good job at proposing questions that solidify basic understanding but does not increase in difficulty to be like a homework or discussion problem. However, it is able to adapt questions based on how well the user understands the content.\n\nI also gave the same starting responses to the ChatGPT 5.1 Thinking model without study mode. While it did give a few questions, it was less interactive and only listed a few questions in the end after going over the lecture content. Instead of asking for an answer to the questions, it states that if the user has any more questions, they can respond.\n\nFor studying the content, using the model under study mode provides a more interactive experience by continuously asking questions and adapting to how well the user understands the content. However, the regular model is suitable for covering all the content in the lecture.\n\nBelow is an annotated version of the conversations I had with both models:",
    "attachments": [
      {
        "name": "Special Participation E_ ChatGPT LoRA Learning.pdf",
        "url": "https://static.us.edusercontent.com/files/yYHjwnDCT893e59r2azDoiPT"
      }
    ],
    "highlight": false,
    "summary": "I used the ChatGPT 5.1 Thinking model under the study mode to have it go over LoRA before I start the homework assignment. It did a good job going over the contents within the lecture and asked questions to ensure my understanding."
  },
  {
    "id": "ed-7426644",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: GPT diagonistic quiz generator for lectures",
    "dek": "I wanted to design a self-quiz generator I can use to test how well I understand the knowledge learned after lecture. To do this, I uploaded lecture notes and wrote a prompt that asks Chat GPT to prod...",
    "student": "Ruihan Xia",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7426644"
    },
    "body_html": "I wanted to design a self-quiz generator I can use to test how well I understand the knowledge learned after lecture. To do this, I uploaded lecture notes and wrote a prompt that asks Chat GPT to produce 5 conceptual questions from a lecture section, each with an answer, a quick intuition, a formal reasoning layer, and an explicit assumption check.\n\nIn the chat with example of lecture 6 & 7, ChatGPT outputed conceptal questions covering RMS norms, maximal update parametrization, spectral-norm-constrained updates, Muon optimizer, and Newton–Schulz iteration. I then asked for related computational examples that involve concrete math and applications to standard problems like linear regression. \n\nHowever, I noticed a few issues. Several explanations essentially copied equations from the lecture slides (e.g., the RMS→RMS norm formula, the Muon spectral-norm optimization step). I think a bit more derivation would be helpful. There are some vague leaps in response as well. In general Chatgpt outputs answers that are more on the conceptual side unless I ask for explicit math. ",
    "attachments": [
      {
        "name": "AI diagnostic quiz.pdf",
        "url": "https://static.us.edusercontent.com/files/1ybzCcd297wvzg3FnuxiPneI"
      }
    ],
    "highlight": false,
    "summary": "I wanted to design a self-quiz generator I can use to test how well I understand the knowledge learned after lecture. To do this, I uploaded lecture notes and wrote a prompt that asks Chat GPT to produce 5 conceptual questions from a lecture section, each with an answer, a quick intuition, a formal reasoning layer, and an explicit assumption check."
  },
  {
    "id": "ed-7426411",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Claude Sonnet 4.5 on Diffusion Models",
    "dek": "I created a Socratic dialogue tool using Claude to learn diffusion models. I gave it our lecture slides; instead of asking it to summarize slides, I explicitly told it to ask me one question at a time...",
    "student": "Jin Ying",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7426411"
    },
    "body_html": "I created a Socratic dialogue tool using Claude to learn diffusion models. I gave it our lecture slides; instead of asking it to summarize slides, I explicitly told it to ask me one question at a time, ignore lecture materials temporarily so I can return to it to test my understanding after the conversation, and focus on building intuition rather than explaining formulas.\n\nClaude helped build intuition before introducing math, handled my confusion productively, and when I gave wrong answers it showed me why my reasoning was incomplete. However, it made several technical oversimplifications that need verification, which I annotated in our conversation.\n\nI found it helpful to spend an hour in Socratic dialogue to build intuition and test myself to see if I only understand something partially, annotate anything that seems off, and then verify against what we've learned in lectures and the textbook. This helped me go from memorizing and taking what we learned in the class for granted to actually understanding concepts deeper. But it's not a replacement for rigorous study; I still need to work through derivations and implementations myself to achieve a real understanding.",
    "attachments": [
      {
        "name": "Diffusion Models with Claude.pdf",
        "url": "https://static.us.edusercontent.com/files/JX86S4sPR4eF5GEeYVpRULOp"
      }
    ],
    "highlight": false,
    "summary": "I created a Socratic dialogue tool using Claude to learn diffusion models. I gave it our lecture slides; instead of asking it to summarize slides, I explicitly told it to ask me one question at a time, ignore lecture materials temporarily so I can return to it to test my understanding after the conversation, and focus on building intuition rather than explaining formulas."
  },
  {
    "id": "ed-7425579",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Module Review Generator with Multi-Source Integration",
    "dek": "I extended Jameson's lecture notes generator #301 to create a comprehensive module review tool.\n\nBuilding on the original script's approach of using lecture transcripts + slides with Gemini API, I cre...",
    "student": "Moxin Tang",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7425579"
    },
    "body_html": "I extended Jameson's lecture notes generator #301 to create a comprehensive module review tool.\n\nBuilding on the original script's approach of using lecture transcripts + slides with Gemini API, I created module review generator that:\n\nCombines multiple sources: Integrates lecture notes, discussion solutions, and homework problems into a single comprehensive review document\n\nSynthesizes content by topic: Uses Gemini API to organize material thematically rather than chronologically, making it better for exam prep\n\nIncludes source citations: Each concept/problem is tagged with its source (e.g., Lecture 24, Discussion 12 Problem2a, HW 10 Problem1, ...) for easy reference\n\nThe script is easily configurable to combine any set of lectures, discussions, and homeworks for different modules.\n\nExample usage:\n\nI combines Lectures 24-27 + Discussions 12-13 + HW 10, 11, 13 into one study guide which is about generative models and post-training.\n\nsample output in \n\nI think the review successfully integrates multiple sources, creating meaningful connections between lectures and the accompanying discussions and homework problems.\n\n\nannotated transcript:\n\n\n\n",
    "attachments": [
      {
        "name": "module_review_generator.py",
        "url": "https://static.us.edusercontent.com/files/nyMA5YPN5fZmDF5CrF7AOzwx"
      },
      {
        "name": "module_24-27_comprehensive_review.tex",
        "url": "https://static.us.edusercontent.com/files/SXST8e0lnZ6JVZRd1QMWRnWP"
      },
      {
        "name": "annotated_module_review_24-27.pdf",
        "url": "https://static.us.edusercontent.com/files/oqSINuasbiLX7tolCEz7yC9G"
      }
    ],
    "highlight": false,
    "summary": "Building on the original script's approach of using lecture transcripts + slides with Gemini API, I created module review generator that:"
  },
  {
    "id": "ed-7424917",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Tensor Norm Visualization Tool",
    "dek": "Using Gemini's Canvas mode, Gemini was able to build this neat interactive visualization of the various tensor norms we discussed in the context of CNNs. It can be difficult to imagine and remember wh...",
    "student": "Neil Pattanaik",
    "date": "2025-12-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424917"
    },
    "body_html": "Using Gemini's Canvas mode, Gemini was able to build this neat interactive visualization of the various tensor norms we discussed in the context of CNNs. It can be difficult to imagine and remember which axes are normalized over for each norm, which inspired me to create this tool. It displays 4 axes (H, W, C, Batch) and has both a 2d and 3d view of BatchNorm, RMS + LayerNorm, and InstanceNorm.\n\n\n\nhttps://gemini.google.com/share/57ed79731305\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "Using Gemini's Canvas mode, Gemini was able to build this neat interactive visualization of the various tensor norms we discussed in the context of CNNs. It can be difficult to imagine and remember which axes are normalized over for each norm, which inspired me to create this tool. It displays 4 axes (H, W, C, Batch) and has both a 2d and 3d view of BatchNorm, RMS + LayerNorm, and InstanceNorm."
  },
  {
    "id": "ed-7424843",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Analytical Failure Modes for Optimizer Intuition via Gemini Pro 3",
    "dek": "While thinking more carefully about optimizers in CS 182, I became curious about  why particular optimizers exist, beyond just memorizing their update rules. In particular, I wanted to understand them...",
    "student": "Krish Yadav",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424843"
    },
    "body_html": "While thinking more carefully about optimizers in CS 182, I became curious about  why particular optimizers exist, beyond just memorizing their update rules. In particular, I wanted to understand them as responses to specific geometric or scaling failures, rather than as isolated algorithms. To explore this, I used Gemini Pro 3 to construct a sequence of minimal, analytic failure modes for optimizers covered in class.\n\nI prompted the model to generate short, symbolic training scenarios (no code, no datasets) where a given optimizer behaves pathologically. For each scenario, it first asked me to predict what would go wrong, and only afterward explained what failed, which assumption was violated, and which optimizer or idea was introduced to address that failure. The scenarios included:\n\nill-conditioning in gradient descent\n\nthe noise floor in SGD\n\nfailure of L2 regularization in Adam vs. AdamW\n\nwidth-dependent instability motivating μP\n\nand the lazy (NTK) training regime\n\nThis approach was effective for connecting lecture material across geometry, scaling laws, and optimizer design, and for separating formal guarantees from heuristic intuition. I added annotations highlighting where the explanations aligned closely with lecture material and where the model relied more on intuition or standard deep learning lore.\n\nOverall, this worked well as an AI-assisted alternative to post-lecture reading, helping build optimizer intuition through concrete failure cases while still requiring active oversight.\n\nFor more, look at the annotated PDF.",
    "attachments": [
      {
        "name": "annotated-gp3-optimizer-failure.pdf",
        "url": "https://static.us.edusercontent.com/files/dWuLm2KWAtuO5b3BE8KghxCC"
      }
    ],
    "highlight": false,
    "summary": "While thinking more carefully about optimizers in CS 182, I became curious about  why particular optimizers exist, beyond just memorizing their update rules. In particular, I wanted to understand them as responses to specific geometric or scaling failures, rather than as isolated algorithms."
  },
  {
    "id": "ed-7424838",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Learning CNNs by Building with Cursor",
    "dek": "Concept: Convolutional Neural Networks (CNNs) & Kernel Filters\n\nTool Used: Cursor (AI Code Editor)\n\nArtifact: The Kernel Whisperer (GitHub Repo)\n\nThe Goal: I found the recent lectures on ConvNets inte...",
    "student": "Nikhil Mathihalli",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424838",
      "github": "https://github.com/nikhilmathihalli/kernel-whisperer"
    },
    "body_html": "Concept: Convolutional Neural Networks (CNNs) & Kernel Filters\n\nTool Used: Cursor (AI Code Editor)\n\nArtifact: The Kernel Whisperer (GitHub Repo)\n\nThe Goal: I found the recent lectures on ConvNets interesting, but I wanted to move beyond static slides. I decided to treat the AI not just as a tutor, but as a \"junior developer\" to help me build an interactive learning tool. The goal was to learn about filters (blur, edge detection, sharpen) by actually applying them to images in code, effectively replacing my standard post-lecture review with an active engineering project.\n\nThe Approach: I used Cursor to build a React-based interactive playground. I realized early on that Cursor works best when you act as the \"Architect.\" I wrote a highly detailed \"spec\" prompt defining exactly what the app should contain—specifically requesting a UI that allows for real-time filter toggling and an embedded AI chat interface tailored specifically to answer conceptual questions about CNNs.\n\nInteraction Trace & Critical Analysis:\n\nSince the interaction was code-heavy, my critical annotation focuses on the difference between Knowledge Generation and Debugging:\n\nWhere it Succeeded (The Math):\n\nOne-Shot Accuracy: Surprisingly, Cursor did not hallucinate on the actual implementation of the convolution logic or the filter matrices. Because I provided a detailed prompt about the mathematical purpose of the filters, it generated the core processing logic correctly on the first try.\n\nWhere it Failed (The Engineering):\n\nDebugging Loops: While the math was good, the AI struggled significantly with \"glue code\" and UI state management. When a bug arose in the React rendering cycle, Cursor often got stuck in a loop, suggesting fixes that broke other parts of the app.\n\nHuman Intervention: This highlighted a key limitation: AI is great at generating isolated logic (like a specific kernel), but requires a human to oversee the broader system architecture and fix integration bugs.\n\nVerdict: Building this tool forced me to understand the inputs and outputs of CNNs much better than just reading about them. If you want to try it out or see the code, the repo is linked above!",
    "attachments": [
      {
        "name": "Kernel Whisperer.pdf",
        "url": "https://static.us.edusercontent.com/files/ASLPoMV2jTJR6sAdXVDm8gIb"
      }
    ],
    "highlight": false,
    "summary": "The Goal: I found the recent lectures on ConvNets interesting, but I wanted to move beyond static slides. I decided to treat the AI not just as a tutor, but as a \"junior developer\" to help me build an interactive learning tool."
  },
  {
    "id": "ed-7424833",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Creating New Discussion Sheets With Lectures That Current Discussion Sheet Does Not Ask using ChatGPT",
    "dek": "I attempted to create a webpage that will take two inputs, one for lecture slides and another for discussion sheets (both in pdf format). Then, I would have chatgpt scan over both pdf files, and try t...",
    "student": "Minjune Kim",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424833"
    },
    "body_html": "I attempted to create a webpage that will take two inputs, one for lecture slides and another for discussion sheets (both in pdf format). Then, I would have chatgpt scan over both pdf files, and try to find concepts that the discussion did not cover that were in the lecture notes. With the concepts that weren't there, it would create new discussion sheet that's just like the discussion sheets for the class with answers such that it can be used to study concepts that weren't on the discussion but was on the lecture.\n\nDuring this process, I ran into some logistical error using chatGPT because at first, it was not able to detect any words for the lecture notes because all of the lecture notes were hand written, so I had to re-prompt GPT, such that it would be able to convert the hand-written notes into a readable format such that it will be able to recognize what concepts were covered in lecture. Furthermore, I did not prompt it carefully enough and not specific enough that when it first created the discussion sheet, it looked nothing like the discussions sheet, and it was also asking questions on only a few questions on concepts. \n\nHere is my annotated report for the prompt:",
    "attachments": [
      {
        "name": "Website code for discussion questions-merged.pdf",
        "url": "https://static.us.edusercontent.com/files/JTaAJOtGIlI8BtpiNwFrxieX"
      }
    ],
    "highlight": false,
    "summary": "I attempted to create a webpage that will take two inputs, one for lecture slides and another for discussion sheets (both in pdf format). Then, I would have chatgpt scan over both pdf files, and try to find concepts that the discussion did not cover that were in the lecture notes."
  },
  {
    "id": "ed-7424719",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Understanding Transformers and the value of KV Cache through visual diagrams",
    "dek": "I am a hugely visual person, and I benefit from learning through images and videos. However, a lot of LLM and AI based concepts are really abstract, and it is hard to have detailed images of all the n...",
    "student": "Aaron Zheng",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424719",
      "chatgpt": "https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113"
    },
    "body_html": "I am a hugely visual person, and I benefit from learning through images and videos. However, a lot of LLM and AI based concepts are really abstract, and it is hard to have detailed images of all the nuances of AI. \n\nHowever, Mindmaps that explain concepts in a visual, interdependent way, are helpful for me. Using a special prompt, I was able to learn more about transformers, KV caching and attention.\n\nI first told the LLM to generate a prompt that could make itself draw mindmaps and detailed drawings to explain machine learning concepts, where the \"concept\" is a variable. Then I copied the prompt and put the concept as \"transformers\". \n\nI then told the LLM to give me a markdown text-based version of the mindmap drawing, and it was very detailed, covering a lot of information. \n\nI generated two diagrams, shown here:\n\n\n\nPrompt:\n\n\"\"\"\n\nI want you to act as an expert AI educator who teaches complex machine learning concepts through highly intuitive mindmaps.\n\nGiven a topic, produce a mindmap-style breakdown with:\n\n1 central concept\n\n5–8 major branches\n\nUnder each branch:\n\nShort, intuitive explanations (not academic jargon)\n\nVisual analogies where appropriate\n\nStep-by-step decompositions\n\nImportant equations (only if helpful)\n\nCommon misunderstandings\n\nReal-world examples\n\nAdditionally, output:\n\nA “Beginner-Friendly Summary” at the top\n\nA “Deep Intuition Layer” beneath the mindmap (why the concept works)\n\nA “How It Fails / Edge Cases” section\n\nA “Connections to Other AI Concepts” section\n\nA “Mental Hooks” section (mnemonics / metaphors to remember the idea)\n\nPresent the mindmap in a structured outline like:\n\nCentral Node\n ├── Branch 1\n │ ├── Subpoint\n │ ├── Subpoint\n ├── Branch 2\n │ ├── Subpoint\n │ └── Subpoint\n … etc.\n\nMake it extremely intuitive and visually organized so I can use it to build internal mental models.\n\nTopic: <INSERT YOUR TOPIC HERE>\n\n\"\"\"\n\nchatgpt convo: https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113\n\n\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "I am a hugely visual person, and I benefit from learning through images and videos. However, a lot of LLM and AI based concepts are really abstract, and it is hard to have detailed images of all the nuances of AI."
  },
  {
    "id": "ed-7424570",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Gemini Pro 3 as a Lecture-Grounded Discussion Worksheet Assistant",
    "dek": "I prompted Gemini Pro 3 to act as a lecture-grounded discussion worksheet assistant. During discussions, I usually find myself scrolling through lecture notes to recall the relevant concepts, so my go...",
    "student": "Dagny Streit",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424570"
    },
    "body_html": "I prompted Gemini Pro 3 to act as a lecture-grounded discussion worksheet assistant. During discussions, I usually find myself scrolling through lecture notes to recall the relevant concepts, so my goal was to create a tool that helps students understand the conceptual foundations behind each worksheet question without giving solutions and without pulling from the worksheet’s explanations.\n\nTo achieve this, I wrote a strict prompt enforcing:\n\nExclusive use of Lecture PDFs for conceptual content (I provided my handwritten lecture notes that tried to capture a lot of what was said in lecture).\n\nUse of Discussion PDFs only for reading the question text (I provided Discussion 13 and asked it about Question 2).\n\nI then tested whether the model could behave like an assistant who has only seen the lectures, not the solutions. The interaction included:\n\nInitial conceptual explanation of a worksheet question using lecture terminology only.\n\nZoom-in prompts to elaborate on specific lecture ideas (e.g., the tradeoff between losses).\n\nA diagnostic checklist of concepts students should review before attempting the discussion question.\n\nLecture-grounded practice questions and hints that did not overlap with worksheet wording.\n\nA self-correcting step, where the model identified phrases that were not actually supported by the lecture slides and rewrote them accordingly.\n\nWhat worked:\n\nThe model produced structured mini-lectures, learning goals, and checklists.\n\nIt consistently linked specific and relevant lecture slides, including portions of diagrams (note: the links do not show unfortunately in the PDF log of the conversation with Gemini).\n\nThe self-correcting step was effective. The model recognized when it used unsupported terminology and corrected itself.\n\nThese features made it genuinely useful for conceptual grounding before discussion.\n\nWhat did not work:\n\nI initially tried using ChatGPT, but I switched to Gemini because it supported clickable references to my uploaded lecture notes, which made checking grounding much easier.\n\nGemini tended to hallucinate on diffusion-specific concepts (Markov chains, Bayes’ rule, etc.) that were not in the lecture PDFs, so explicit prompting and self-correcting were necessary. I think this was because it was looking at Question 1d instead of Question 2d of the discussion worksheet.\n\nMy lecture notes may not have been comprehensive and could have caused the model to occasionally fill gaps with general deep learning knowledge rather than lecture content. I try to capture a lot of information in my handwritten lecture notes, but some things that are said in lecture may be missed.\n\nOverall, it worked well once constrained, and the self-correction step was key for keeping it oriented with lecture material. Attached is the annotated conversation.",
    "attachments": [],
    "highlight": false,
    "summary": "I prompted Gemini Pro 3 to act as a lecture-grounded discussion worksheet assistant. During discussions, I usually find myself scrolling through lecture notes to recall the relevant concepts, so my goal was to create a tool that helps students understand the conceptual foundations behind each worksheet question without giving solutions and without pulling from the worksheet’s explanations."
  },
  {
    "id": "ed-7424475",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Structured Notes with NotebookLM RAG Tool",
    "dek": "For this assignment, I evaluated whether Google NotebookLM is a viable tool for generating \"Cornell\" Notes from our handwritten lecture slides. Taking notes in “Cornell Style” can help to make sure yo...",
    "student": "Elizabeth Polito",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424475"
    },
    "body_html": "For this assignment, I evaluated whether Google NotebookLM is a viable tool for generating \"Cornell\" Notes from our handwritten lecture slides. Taking notes in “Cornell Style” can help to make sure you are not getting bogged down in the details by dedicating a column on the left of your page to keywords/main ideas, a column on the right to the notes themselves, and a box on the bottom for a summary. Here is a summary of why these types of notes are useful: Cornell Note Taking — The Best Way To Take Notes, Explained | Goodnotes Blog\n\n(Citation: Image taken from link above for illustrative purposes).\n\nI used NotebookLM, which is a RAG-based research tool that grounds its generation primarily in your uploaded documents. I was able to carry out the generation simply by uploading the handwritten lecture notes (interestingly, I did have to “flatten” the PDFs before the software was able to “read” the content, and prior to doing so, NotebookLM insisted that the document was empty). I chose Lecture 7 (MuON) as the stress test because it contains relatively few diagrams which would have been more of a challenge for the tool to replicate/parse. \n\nOverall, because NotebookLM is powered by Gemini Pro which, as many students have pointed out in their special participation submissions, is very well-equipped to deal with this content, it did a highly accurate job of generating Cornell style notes and writing decent summaries. In my opinion, the biggest limitation with the NotebookLM tool is the I/O behavior, between some issues uploading the PDF as discussed and the fact that I could not download a PDF of the trace or of the Cornell notes themselves. Its ability to parse the notes and provide inline citations for which page of the document the equations came from was very helpful once the document was in a format it could parse. The tool seems to have many more built-in features that would be very interesting to explore.\n\nThe Artifact\n\nI have attached the PDF of the transcript below, which includes the Cornell notes within. The structure follows the Cornell method:\n\nLeft Column: High-level cues (\"Newton-Schulz Iteration\", \"Shampoo vs MuON\").\n\nRight Column: More detailed mathematical notes/derivations with inline citations.\n\nSummary: A synthesis of the “page” of notes. \n\nI have uploaded an annotated trace of my conversation, which includes the Cornell notes within. ",
    "attachments": [
      {
        "name": "muon_annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/aUuZSCc3YLb25Q4tuQPAzacD"
      }
    ],
    "highlight": false,
    "summary": "For this assignment, I evaluated whether Google NotebookLM is a viable tool for generating \"Cornell\" Notes from our handwritten lecture slides. Taking notes in “Cornell Style” can help to make sure you are not getting bogged down in the details by dedicating a column on the left of your page to keywords/main ideas, a column on the right to the notes themselves, and a box on the bottom for a summar"
  },
  {
    "id": "ed-7424307",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Nano Banana 3 Pro for Note Generation and Content Understanding",
    "dek": "Google recently launched Nano Banana Pro, its new image generating model. I saw online that it could do many cool things such as solve math problems on paper or explain pictures in depth. I decided to...",
    "student": "Leon Kornfeld",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424307"
    },
    "body_html": "Google recently launched Nano Banana Pro, its new image generating model. I saw online that it could do many cool things such as solve math problems on paper or explain pictures in depth. I decided to use it on a bunch of different tasks to see how it fairs as a study tool. \n\nExperiment 1, Convolution:\n\nPrompt 1: Can you make me an image of hand drawn notes explaining a convolutional neural network. I will prompt you for many different images but can you draw first a diagram of what a convolution would look like with a 2D kernel and a 3D kernel. Be sure to include a visualization of the output channels depending on how many kernels are applied.\n\nOutput 1:\n\nAnalysis:\n\nOverall, the note looks fantastic. The handwriting is neat and it is nicely structured. The first section of the note makes sense. It explains the convolution operation as a dot product and sum. The output feature map is of proper dimension assuming zero padding, and stride is 1. There does seem to be a rogue \"& sum\" underneath the bottom arrow.\n\nWhile the 3D convolution section correctly notes the output map is of depth 1, it incorrectly generated the output dimensions as a 3 by 3. Also, the choice of operator \"+\" is an odd notation to use.\n\nLastly, for the \"Multiple Kernels and Output Channels\" section, it correctly identified that there should be 3 output channels. However, the diagrams have the weird \"+\" notation and the input and output dimensions are not really detailed.\n\nTo address the dimension issue in \"3D convolution\", I submitted prompt 2:\nPlease make it more mathematically rigorous. For example, in your 3D convolution, there are only 4 rows in the original input and the kernel is of size 3. However, their output has 3 rows. This is incorrect if assuming zero padding since the number of rows should just be 2.\n\nOutput 2:\n\nWith this prompt all the output feature maps were filled in with numbers. They are all obviously incorrect. Moreover, while it did shrink the number of rows in \"3D Convolution\" to 2, it also shrunk the number of columns to 2 as well. The output map dimensions in \"Multiple Kernels\" are correct, but there is a coloring issue: for consistency, it would make sense that the first output channel is purple.\n\nPrompt 3:\n\nThis is also still incorrect since the output map for the 3D convolution should be a 2 by 3, not a 2 by 2. Also the numerical values and the math do not make sense.\n\nLastly, for the multiple kernels and output channels section, it's confusing notation of adding the different kernels. Can you please fix that.\n\nOverall, the coloring scheme is also kind of confusing since you have a purple kernel that doesn't have a corresponding output channel while the green and orange kernels do. Please be consistent with everything you are doing.\n\n(Note: this prompt could have definitely been better).\n\nOutput 3:\n\nThere was no real improvement to \"3D Convolution.\" However, \"Multiple Kernels\" did get rid of the weird \"+\" notation and showed each output map individually for the 3 kernels with the proper coloring scheme. However, the last step still has the wrong colors. Also note, none of the numbers are correct.\n\nConclusion: \n\nNano Banana 3 has an amazing ability to generate notes that discuss the concept of CNNs. While the specifics (dot product values, correct dimensions, etc.) are still shaky, the overall structure, quality, and high level concepts are very very good. Based on this experiment, however, I would not yet recommend using this as a study tool.\n\nExperiment 2, Images -> Images:\n\nPrompt 1: Solve this problem in my hand writing and generate an image of the work and the solution\n\nOutput 1:\n\n\n\nNano Banana 3 was able to read my handwriting and recognize that the problem it needed to solve was least squares. It proceeded to provide a mostly correctly proof (minus a few notational issues with the transposes) and arrived at a correct answer. It even added in the condition that A^T A needs to be invertible. However, while it did not solve the problem with my handwriting, the type of paper used stayed the same.\n\nFor my next prompt, I provided a screenshot of a note from lecture:\n\nPrompt 2:\n\nTake this lecture note about the weights in MLPS and CNNs and annotate the image explaining what each picture means.\n\nOutput 2:\n\n\n\nMistake 1: The top two description boxes are flipped. However, the content in each box would be fully correct were they pointing to the right spot.\n\nMistake 2: It correctly notes that the diagrams are from the Prince book but the written text describing that is no longer in the output.\n\nThe rest of the description boxes are actually quite amazing. Descriptions b and d both relate their images to the corresponding images in a and c, showing an in-depth understanding of all the images provides in the prompt image. Moreover, their individual interpretations of the weight matrices and what they represent without much context is also quite great.\n\nConclusion:\n\nNano Banana Pro has an impressive ability to take in images , understand their contents, and produce new images by either adding on to or augmenting the inputted ones. I ran another experiment that I did not feature here that took in images describing more complicated math. The output was close to the original picture (handwriting slightly rewritten) with some added gibberish. Therefore, I would conclude that Nano Banana Pro has the ability to understand well structured diagrams or easy math, but it is not necessarily at the point yet where it can understand and generate images for more complicated math.",
    "attachments": [],
    "highlight": false,
    "summary": "Google recently launched Nano Banana Pro, its new image generating model. I saw online that it could do many cool things such as solve math problems on paper or explain pictures in depth. I decided to use it on a bunch of different tasks to see how it fairs as a study tool."
  },
  {
    "id": "ed-7424217",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Misconception Diagnostic Learning with Claude and Deepseek",
    "dek": "In this assignment, I designed an AI-enhanced learning tool that does not simply explain deep learning concepts but instead actively diagnoses and corrects my misunderstandings. I interacted with two ...",
    "student": "Zesheng Cai",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7424217"
    },
    "body_html": "In this assignment, I designed an AI-enhanced learning tool that does not simply explain deep learning concepts but instead actively diagnoses and corrects my misunderstandings. I interacted with two different AI models—Claude and DeepSeek—and provided intentionally imperfect answers to their diagnostic questions. This allowed the models to analyze my reasoning, detect misconceptions, and generate personalized explanations.\n\nThe workflow follows four stages:\n\nI answer diagnostic questions about Attention and Self-Attention.\n These answers intentionally contain a mix of correct ideas and common misunderstandings.\n\nThe AI infers my misconceptions from my responses.\n Each system identifies which parts of my reasoning are correct, partially correct, or mistaken.\n\nThe AI produces tailored explanations based on the specific misconceptions it detected.\n These include counterexamples, intuitive analogies, and conceptual clarifications.\n\nThe AI generates personalized exercises that target the exact areas where I showed confusion.\n This turns the interaction into a highly adaptive learning process.\n\nThis workflow transforms AI from a passive explanation tool into an active diagnostic tutor—similar to a human TA who tests my understanding before teaching.\n\nInstead of asking the AI to teach me concepts directly, I designed a system where the AI actively discovers and corrects my misunderstandings about deep learning. I call this approach a Misconception Diagnostic System. It acts like a doctor diagnosing a patient:\n\nIt asks targeted diagnostic questions\n\nIt infers hidden misconceptions from my answers\n\nIt generates personalized corrective explanations\n\nIt produces practice exercises tailored to my specific gaps\n\nThis system goes far beyond traditional Q&A or passive reading.\n It creates a learning process that is:\n\nAdaptive — tailored to my level\n\nInteractive — requiring me to think and respond\n\nMisconception-driven — correcting what I don’t know, not what I already know\n\nHigh-resolution — identifying subtle misunderstandings\n\nBidirectional — my answers shape the AI’s teaching strategy\n\nThis is fundamentally different from standard “AI explains a topic” workflows.\n Instead, the AI becomes an active diagnostic tutor. \n\nClaude\n\nStrengths\n\nVery strict structure and excellent instruction following\n\nClean four-stage pipeline\n\nHigh linguistic clarity\n\nLow hallucination rate in technical formulas\n\nProduces polished conceptual exercises\n\nWeaknesses\n\nSometimes fabricates my answers (“overconfident inference”)\n\nPersonalized corrections are less detailed\n\nExplanations sometimes feel too “textbook-like\"\n\nDeepSeek\n\nStrengths\n\nStrong reasoning-first approach\n\nUses numerical counterexamples to build intuition\n\nExcellent at detecting subtle conceptual mistakes\n\nExplanations are detailed and mathematically grounded\n\nExercises more directly target my actual misunderstandings\n\nWeaknesses\n\nSometimes overly verbose\n\nOccasionally over-interprets my intentions\n\nHigher chance of speculative reasoning\n\nOverall Comparison\n\nClaude = structure-first system\n\nDeepSeek = reasoning-first system\n\nClaude shines at formatted explanation.\n DeepSeek shines at conceptual diagnosis.\n\nUsing both provides a more complete learning experience.\n\nSummary\n\nThrough this assignment, I developed and tested a novel AI-enhanced learning tool based on misconception diagnosis rather than passive explanation. By intentionally providing imperfect answers to diagnostic questions, I enabled Claude and DeepSeek to identify my conceptual gaps and generate personalized corrections and targeted exercises. This made AI function more like a real tutor rather than a search engine.\n\nThe interaction trace demonstrates the strengths and weaknesses of two leading AI models: Claude excels at structured instruction following, while DeepSeek provides deeper mathematical intuition and finer-grained diagnostic reasoning. Their complementary strengths highlight how different AI systems can address different aspects of the learning process.\n\nMost importantly, the Misconception Diagnostic System provides a highly adaptive, interactive, and personalized alternative to traditional pre-lecture or post-lecture reading. It forces me to articulate my understanding, reveal misconceptions, confront errors, and reinforce corrected concepts through targeted practice.\n\nThis approach not only deepens intuition but also broadens conceptual coverage, making it a powerful and innovative method for AI-enhanced learning in deep learning courses.\n\n",
    "attachments": [
      {
        "name": "Using Deepseek and Claude as tutors.pdf",
        "url": "https://static.us.edusercontent.com/files/BRRW4vBrN2TPdTSbWOtHiO28"
      }
    ],
    "highlight": false,
    "summary": "In this assignment, I designed an AI-enhanced learning tool that does not simply explain deep learning concepts but instead actively diagnoses and corrects my misunderstandings. I interacted with two different AI models—Claude and DeepSeek—and provided intentionally imperfect answers to their diagnostic questions."
  },
  {
    "id": "ed-7423912",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Using DeepSeek to Develop Intuition and Deepen Understanding in Deep Learning",
    "dek": "For this assignment, I chose DeepSeek as the AI-enhanced learning tool because it demonstrates unusually strong reasoning capabilities, especially in mathematical explanation, multi-step intuition bui...",
    "student": "Zesheng Cai",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7423912"
    },
    "body_html": "For this assignment, I chose DeepSeek as the AI-enhanced learning tool because it demonstrates unusually strong reasoning capabilities, especially in mathematical explanation, multi-step intuition building, and structured teaching. My goal was not only to obtain direct answers, but also to evaluate whether DeepSeek could serve as an active substitute for traditional pre-lecture or post-lecture readings.\n\nTo achieve that, I first asked DeepSeek a sequence of foundational but conceptually challenging questions on CNNs, pooling, data augmentation, and batch normalization. These questions were intentionally selected to reveal my current level of understanding, so that the model could adapt its explanations to my background.\n\nAfterwards, I prompted DeepSeek to take the role of an instructor and generate a set of quiz-style questions to test my comprehension. This part was extremely useful: the quiz forced me to articulate the intuition behind invariances, optimization behavior, and design trade-offs. The progression from easy to difficult questions mirrored the structure of typical deep learning readings and helped reinforce both the breadth and depth of my understanding.\n\nThroughout the interaction, DeepSeek performed well in explaining intuition, giving structured arguments, and generating pedagogically meaningful questions. At the same time, several responses contained oversimplifications, slight exaggerations, or unnecessary repetition, which I highlighted in the annotations. These issues illustrate that while the model is powerful, its output still requires human verification and critical reading—very similar to how one must evaluate a technical textbook.\n\nOverall, this exercise shows that DeepSeek can function as a dynamic, interactive learning companion: it not only answers technical questions but also probes understanding, generates practice material, and supports conceptual clarity. With careful supervision, this approach can effectively complement traditional study methods and enhance conceptual learning in deep learning courses. \n\n",
    "attachments": [
      {
        "name": "Understanding Downsampling and Pooling in CNNs (1) - DeepSeek.pdf",
        "url": "https://static.us.edusercontent.com/files/telbENslFri4PbZcEo65z5ku"
      }
    ],
    "highlight": false,
    "summary": "For this assignment, I chose DeepSeek as the AI-enhanced learning tool because it demonstrates unusually strong reasoning capabilities, especially in mathematical explanation, multi-step intuition building, and structured teaching."
  },
  {
    "id": "ed-7423645",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: “Lecture-to-LaTeX Cheatsheet” Workflow",
    "dek": "I’ve been testing a workflow where I feed an LLM a PDF of lecture notes and have it generate a clean, structured LaTeX summary that I can drop directly into a personal cheatsheet. My motivation is tha...",
    "student": "Lenci Ni",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7423645"
    },
    "body_html": "I’ve been testing a workflow where I feed an LLM a PDF of lecture notes and have it generate a clean, structured LaTeX summary that I can drop directly into a personal cheatsheet. My motivation is that I really like having compact LaTeX reference sheets for classes—they’re useful for finals and for quickly revisiting where I first learned certain ideas.\n\nI’ve attached the final prompt I created, along with a short trace showing how I refined it. I started with a rough version, had the LLM summarize the Attention lecture, and then reprompted it to make the summary more condensed and better formatted. I also gave it one of my old cheatsheets so it could match my style. After seeing the final output, I asked it to improve my original prompt. The LLM generally produced clean LaTeX, though it sometimes made small syntax mistakes. For better summaries, it might help to use another student’s pipeline that converts handwritten notes or recordings into cleaner digital notes before giving them to the LLM. Overall, this workflow ended up being a surprisingly effective way to generate clean study materials with much less manual effort.\n\nPrompt:\n\nTrace (annotated):\n\nExample cheatsheet:",
    "attachments": [
      {
        "name": "participation_e_2_prompt.pdf",
        "url": "https://static.us.edusercontent.com/files/lHetOcJgnAu8hBwC9t5mftLg"
      },
      {
        "name": "participation_e_2.pdf",
        "url": "https://static.us.edusercontent.com/files/r1aNXRFE6Z9szCloMijgUKCH"
      },
      {
        "name": "CS_182_Cheatsheet.pdf",
        "url": "https://static.us.edusercontent.com/files/LpgU8srRrXVOarFW9hpenyu6"
      }
    ],
    "highlight": false,
    "summary": "I’ve been testing a workflow where I feed an LLM a PDF of lecture notes and have it generate a clean, structured LaTeX summary that I can drop directly into a personal cheatsheet. My motivation is that I really like having compact LaTeX reference sheets for classes—they’re useful for finals and for quickly revisiting where I first learned certain ideas."
  },
  {
    "id": "ed-7423129",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Gemini's Guided Learning",
    "dek": "I used Gemini's Guided Learning tool to create a tool for post-lecture confirmation of knowledge. It provides a quick summary of the lecture notes provided, then tests knowledge in a series of increas...",
    "student": "Kian Hekmatnejad",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7423129"
    },
    "body_html": "I used Gemini's Guided Learning tool to create a tool for post-lecture confirmation of knowledge. It provides a quick summary of the lecture notes provided, then tests knowledge in a series of increasingly complex questions, continuing until the student demonstrates adequate understanding of the concepts for CS182 standards. Here is the link to my conversation and the summary is attached:\n\nhttps://gemini.google.com/share/459fac511f56 ",
    "attachments": [
      {
        "name": "Special participation E2.pdf",
        "url": "https://static.us.edusercontent.com/files/KgjKsoc1zJdRLxc7b72mdTpl"
      }
    ],
    "highlight": false,
    "summary": "I used Gemini's Guided Learning tool to create a tool for post-lecture confirmation of knowledge. It provides a quick summary of the lecture notes provided, then tests knowledge in a series of increasingly complex questions, continuing until the student demonstrates adequate understanding of the concepts for CS182 standards."
  },
  {
    "id": "ed-7423074",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: The \"Deep Learning Detective\" Game",
    "dek": "Special Participation E: The \"Deep Learning Detective\" Game\n\nIn Deep Learning, a model can run without errors but still fail to learn (e.g., loss flatlines, gradients explode). Beginners often struggl...",
    "student": "Tom Chen",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7423074"
    },
    "body_html": "Special Participation E: The \"Deep Learning Detective\" Game\n\nIn Deep Learning, a model can run without errors but still fail to learn (e.g., loss flatlines, gradients explode). Beginners often struggle to link these \"symptoms\" to the underlying mathematical causes. I designed a prompt to simulate this diagnostic process.\n\nPlease check the prompt in the following prompt.txt:\n\nHere is a case about how to use it:\n\nMy analysis about this tool:\n\nThe Goods\n\nPrecise Symptom-to-Cause Mapping: The AI correctly identified that spatial depth (20 layers) + temporal length (100 steps) + small init = Vanishing Gradients. It didn't hallucinate \"Exploding Gradients\" (which would show NaNs) or \"Overfitting\" (which would show low training loss).\n\nMathematical Grounding: Instead of just guessing, it provided the formula for BPTT. This is crucial for a learning tool—it explains why the failure happened, not just what happened.\n\nCorrect Remediation: It suggested the standard industry fix (Switch to LSTM) and the \"Power User\" fix (Orthogonal Initialization for Vanilla RNNs), showing a tiered understanding of solutions.\n\nLimitations\n\nOversimplification of Identity Initialization: The AI suggested \"Identity Initialization\" as a secondary fix. While theoretically sound (Le, Jaitly, Hinton 2015), in practice, training a 20-layer Vanilla RNN on 100 steps is notoriously unstable even with good initialization. The AI presented this as a definite \"fix,\" whereas a human expert would warn that it might still be very fragile compared to an LSTM.\n\nLack of \"Exploding\" Warning: When suggesting a switch to ReLU (in the \"Secondary Fix\" section), the AI briefly mentioned clipping but failed to emphasize that ReLU in RNNs often leads to the opposite problem: Exploding Gradients (due to unbounded activations). A more rigorous tutor would have flagged this risk more aggressively.",
    "attachments": [
      {
        "name": "prompt.txt",
        "url": "https://static.us.edusercontent.com/files/zcJvRXCe2aVJBMO1SGyx6WdH"
      },
      {
        "name": "Special Participation E2.pdf",
        "url": "https://static.us.edusercontent.com/files/kqona55LibEDryE59oebGL41"
      }
    ],
    "highlight": false,
    "summary": "In Deep Learning, a model can run without errors but still fail to learn (e.g., loss flatlines, gradients explode). Beginners often struggle to link these \"symptoms\" to the underlying mathematical causes. I designed a prompt to simulate this diagnostic process."
  },
  {
    "id": "ed-7422938",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Interactive Visualization of Qwen 3 MoE architectures",
    "dek": "Recap of Assignment Instructions\n\nFor this assignment, we were asked to create an AI-enhanced learning tool for a specific concept or lecture. The goal was to explore how modern LLM systems can act as...",
    "student": "Vijay Kethanaboyina",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422938"
    },
    "body_html": "Recap of Assignment Instructions\n\nFor this assignment, we were asked to create an AI-enhanced learning tool for a specific concept or lecture. The goal was to explore how modern LLM systems can act as substitutes or supplements for traditional pre- and post-lecture readings.\n\nWe were required to:\n\nDesign a prompt, workflow, or artifact that classmates could reuse to learn the same material.\n\nProvide an interaction trace demonstrating how the tool works.\n\nAnnotate the trace with critical commentary, highlighting where the model was helpful, where it made mistakes, and what we learned about interacting with it.\n\nWhat I Made\n\nFor my submission, I explored the internal architecture of the Qwen model family. I used GPT5-codex (an OpenAI model designed for code generation tasks) to create an interactive visualization of the model architecture that breaks down its components (tokenization, attention structure, MoE usage, architectural variations, etc.) into digestible conceptual blocks.\n\nI'm hosting the tool on my personal website here: https://www.vkethana.com/qwen-arch/\n\nMy annotated interaction trace with the LLM is here: https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharing\n\nSome Insights I Had About the LLM Interaction\n\nThe model was able to generate the majority of the final product in just one prompt.\n\nThere were some minor detail-related / visual discrepancies that needed to be corrected in subsequent prompts. But in terms of zero-shot performance, I would say that Codex did pretty well\n\nThe model tends to summarize information without being prompted to do so\n\nFor example, in the very first version of the app, the model omitted most of the information about specific parameter counts, embedding widths, etc. I had to explicitly prompt the model to add these details into the visualization\n\nCursor (a VSCode fork with added features to support coding agents) is a great complement to code generation models like GPT5-Codex\n\nSome features I found particularly useful include being able to roll back the codebase to an arbitrary point in the conversation, diff visualization so that you can see what the model did to the codebase, and easy support for exporting conversations.",
    "attachments": [],
    "highlight": false,
    "summary": "For this assignment, we were asked to create an AI-enhanced learning tool for a specific concept or lecture. The goal was to explore how modern LLM systems can act as substitutes or supplements for traditional pre- and post-lecture readings."
  },
  {
    "id": "ed-7422808",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E Use Gemini 3 do Final Exam Reviewing",
    "dek": "When studying EECS 182, I wanted a high‑level “big picture” view of all the discussions plus some realistic exam practice, without rereading every single PDF from scratch. I asked Gemini 3 Pro with Gu...",
    "student": "Fangzhou Zhao",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422808"
    },
    "body_html": "When studying EECS 182, I wanted a high‑level “big picture” view of all the discussions plus some realistic exam practice, without rereading every single PDF from scratch. I asked Gemini 3 Pro with Guided Thinking to act like a Berkeley professor: review the discussion notes and then generate an example exam in that style. My hope was to use it as both a conceptual review sheet and a source of practice problems for midterm/final prep.\n\nGemini’s response did a solid job of capturing the themes running through the course: optimization vs geometry, residual connections as “gradient highways,” SSMs as convolutions vs recurrences, attention as a fix for bottlenecks, and how inference‑time tricks like beam search and soft prompting fit in. It also produced exam questions that felt very “182‑ish”: derivations about convolution kernels, RoPE inner products, SSM kernels, and beam‑search bookkeeping that line up well with what I’ve seen in discussion. As practice prompts to work through on my own, they’re genuinely useful.\n\nAt the same time, Gemini did hallucinate or slip on some technical details (for example, getting certain scaling factors and regularization dependences wrong) and sometimes went deeper or more confidently into math than was actually justified. So I treat its write‑up as good conceptual scaffolding and a source of exam‑style questions, but not as an authority on precise formulas. With a red pen and the official discussion solutions next to it, though, its output becomes a pretty effective study packet.\n\n\n\nhttps://gemini.google.com/share/7ccfff76d2f3",
    "attachments": [
      {
        "name": "Special E.pdf",
        "url": "https://static.us.edusercontent.com/files/vyNFe8SDW76StQtkiaFNxqN2"
      }
    ],
    "highlight": false,
    "summary": "When studying EECS 182, I wanted a high‑level “big picture” view of all the discussions plus some realistic exam practice, without rereading every single PDF from scratch. I asked Gemini 3 Pro with Guided Thinking to act like a Berkeley professor: review the discussion notes and then generate an example exam in that style."
  },
  {
    "id": "ed-7422782",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini 3 Pro as a Socratic Tutor for Deep Learning Theory (RMSNorm & MuP)",
    "dek": "Hi everyone,\n\nFor the \"AI-Enhanced Learning Tools\" option, I experimented with using an LLM (Gemini) as a Socratic Academic Tutor to help me work through the mathematical derivations of RMS Norm, Init...",
    "student": "Ijin Yu",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422782"
    },
    "body_html": "Hi everyone,\n\nFor the \"AI-Enhanced Learning Tools\" option, I experimented with using an LLM (Gemini) as a Socratic Academic Tutor to help me work through the mathematical derivations of RMS Norm, Initialization, and Maximal Update Parametrization (MuP).\n\nInstead of just asking for answers, I used a specific system prompt to force the AI to guide me through the logic gaps. My goal was to replace passive reading of the lecture notes/slides with an active derivation session.\n\n1. The Setup (The Prompt)\n\nI used the following prompt to set the \"persona\" and rules for the AI. This prevents the model from dumping walls of text and forces it to track my understanding.\n\nSystem Prompt Used:\n\n\"You are an expert Academic Tutor. We are about to have a study session regarding Deep Learning.\n\nYour Goal: Answer my questions and help me work through problems. Do not just give me the answer; use Socratic questioning to guide me if I am stuck, but provide clear explanations when I am genuinely confused.\n\nCrucially: Silently track concepts I understood vs. concepts where I struggled.\n\nOutput Trigger: When I type 'MAKE NOTES', stop tutoring and output a 'Personalized Study Artifact' summarizing my learning process, struggle points, and a review checklist.\"\n\n2. Interaction Trace & Highlights\n\nTopic: We covered the derivation of RMS Norm, why it is considered a \"relaxation\" of strict orthogonality, and how this derivation directly leads to the \"MuP\" (Maximal Update Parametrization) rules used for training massive models like GPT-3.\n\n3. Critical Annotation (Critique of the AI)\n\nPer the assignment instructions, here is my critical analysis of the AI's performance during this session:\n\nWhere it excelled (The \"Good\"):\n\nAnalogy Generation: When I struggled to understand why we scale RMS Norm by $\\sqrt{d}$ (width) rather than keeping the total L2 norm fixed, the AI generated a \"Crowded Room\" analogy (Total Volume vs. Average Volume). This successfully bridged the gap between the math notation and the intuition of \"signal health\" in high dimensions.\n\nLinking Concepts (Synthesis): The AI successfully recognized that the derivation I was working on (checking stability of $\\Delta h$) was the mathematical foundation of MuP. It proactively linked the theoretical algebra to a real-world application (hyperparameter transfer), which wasn't explicitly in my initial upload.\n\nDebugging Misconceptions: It correctly identified a \"Notation Collision\" I had regarding \"Order 1.\" I confused Polynomial Order (Linear) with Asymptotic Order (Constant). The AI didn't just correct the math; it explained why I made the mistake (the language ambiguity).\n\nWhere to be careful (The \"Bad/Misleading\"):\n\nNotation \"Ghost Terms\": When I asked about using the Product Rule for finite differences ($\\Delta$), the AI said \"Yes,\" but had to be pressed to explain the technical inaccuracy. It initially glossed over the \"second order term\" ($\\Delta W \\Delta h$) that we ignore in Deep Learning. A student blindly accepting the first answer might think the Calculus Product Rule applies perfectly to discrete steps, which is mathematically false (though a standard approximation in DL).\n\nHallucination Check: While it didn't hallucinate facts in this session, it did generate specific Python code for MuP. I would need to verify this against the official Microsoft mup library documentation before using it in a project, as LLMs often mix up syntax for niche libraries.\n\n4. The Output Artifact\n\nAt the end of the session, the MAKE NOTES trigger produced a study guide tailored to my specific confusion points during the chat. (See the end of the attached trace).\n\nTakeaway: This prompting strategy is highly effective for \"math-heavy\" theory where you need to verify your intuition, provided you force the AI to question you rather than lecture you.",
    "attachments": [
      {
        "name": "Google Gemini.html",
        "url": "https://static.us.edusercontent.com/files/71FMfXBYRIcHskTsuGYMdOD3"
      }
    ],
    "highlight": false,
    "summary": "For the \"AI-Enhanced Learning Tools\" option, I experimented with using an LLM (Gemini) as a Socratic Academic Tutor to help me work through the mathematical derivations of RMS Norm, Initialization, and Maximal Update Parametrization (MuP)."
  },
  {
    "id": "ed-7422729",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT as a Finetuning Simulation",
    "dek": "Motivation/Summary\n\nI tend to struggle quite a bit with hyperparameter tuning whenever it comes up in the homeworks, and I noticed that LLMs tend to be pretty good with it, probably due to having a lo...",
    "student": "Akhil Agarwal",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422729",
      "chatgpt": "https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562"
    },
    "body_html": "Motivation/Summary\n\nI tend to struggle quite a bit with hyperparameter tuning whenever it comes up in the homeworks, and I noticed that LLMs tend to be pretty good with it, probably due to having a lot of examples to go off of. So, I decided to make a finetuning simulator, where the LLM comes up with some hypothetical task, model architecture, loss function, and optimizer, and the user has to work on finetuning it. The model would produce training/validation loss and accuracy curves after every change, and also forced the user to explain their reasoning. I learned quite a bit in my chat with it, such as some nuances of the learning rate scheduling, as well as how large oscillations can happen in validation loss and not in training loss if some hyperparameters are off. It did quite well, adjusting the curves according to the changes proposed and providing very helpful analysis when requested. I wanted the user to do most of the work, and so it was instructed to do minimal analysis unless requested, but it started to add more analysis as the chat went on, though still not too much. It also didn't deny all of my changes as bad or accept them all as good, so I think it was trying to be objective based on the situation it started with, which was great.\n\nTrace: https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562\n\nAnnotated Trace:\n\n\n\nSystem Prompt:\n\nRole: You are an advanced Deep Learning Hyperparameter Tuning Simulator. Your goal is to help the user master tuning dynamics by allowing them to manipulate hyperparameters and observing the consequences via simulated loss and accuracy curves.\n\nOperational Rules: Initialization:\n\nStart by randomly selecting a Task (e.g., Image Classification, Sentiment Analysis, Regression), a Model (CNN, MLP, GNN, Transformer), an Optimizer (SGD, Adam, AdamW, SGD-Momentum), and a Loss Function (MSE, Cross-Entropy).\n\nDo not initialize the hyperparameters, and allow the user to initialize the values to start. If they are missing a key hyperparameter which the model would not be able to work without, make sure to prompt them towards initializing it without mentioning the name of it, but if it is possible to run without it or set it to 0 as a default, do that but do not mention the hyperparameter, allowing the user to discover it. If there is some extra hyperparameter they supply, or they would like to modify the architecture, allow for that, as long as it is implementable.\n\nThe key is to allow the user as much flexibility as they would like, and only help them in any way when they request it. The first message should simply ask the user for hyperparameters, and not mention the names of any of them, along with defining the task, model architecture, and loss function.\n\nDo not explain why the values are bad.\n\nThe \"Reasoning\" Requirement (Strict):\n\nThe user must propose a change and provide a reason (e.g., \"Decrease LR to 1e-3 to stop oscillation\").\n\nCondition A: If the reasoning contradicts the action (e.g., \"Increase LR to reduce noise\"), REJECT the change and ask them to clarify.\n\nCondition B: If the reasoning is logical but the move is mathematically wrong for the current state (e.g., \"Increase LR\" when it's already exploding), ACCEPT the change and simulate the disastrous result.\n\nCondition C: If the reasoning is logical and the move is correct, ACCEPT the change and simulate the improvement.\n\nVisual Feedback Only:\n\nCRITICAL: Do not provide text-based \"Expert Analysis\" or explain why the curve looks the way it does. Do not give away the solution.\n\nInstead, you must generate a synthetic Loss/Accuracy curve that accurately reflects the mathematical behavior of the current hyperparameters.\n\nExample: If LR is too high, plot a jagged, exploding line. If Batch Size is small, add heavy Gaussian noise to the line. If Overfitting, curl the Validation Loss upward.\n\nResponse Format:\n\nCurrent Hyperparameters: List the current state.\n\nSimulation: The graph of the loss and accuracy (training & validation).\n\nVisual Description: A brief, objective description of the line (e.g., \"The line is flat,\" \"The line is oscillating\"). Do not interpret the meaning.\n\nNext Step: Ask the user: \"What is your next proposal? (Remember to include your reasoning.)\"\n\nIF the user is asking for feedback or analysis, provide it to the extent that the user asks, giving no more information than is necessary, while satisfying the user's request.\n\nGoal: The user should \"win\" by successfully tuning the model to high accuracy through trial and error, relying solely on their ability to read the graphs. Only offer a hint if the user explicitly asks for help or fails 3 times in a row. Ensure that the simulation is realistic.",
    "attachments": [
      {
        "name": "Special_Participation_E1.pdf",
        "url": "https://static.us.edusercontent.com/files/JBaLf9A0eQFhV9gozao2dw5q"
      }
    ],
    "highlight": false,
    "summary": "I tend to struggle quite a bit with hyperparameter tuning whenever it comes up in the homeworks, and I noticed that LLMs tend to be pretty good with it, probably due to having a lot of examples to go off of. So, I decided to make a finetuning simulator, where the LLM comes up with some hypothetical task, model architecture, loss function, and optimizer, and the user has to work on finetuning it."
  },
  {
    "id": "ed-7422403",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Using ChatGPT to Automatically Find and Organize Related Papers",
    "dek": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students deepen their understanding of lecture content by automatically finding and organizing related r...",
    "student": "Qicheng Zhu",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422403",
      "chatgpt": "https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324"
    },
    "body_html": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students deepen their understanding of lecture content by automatically finding and organizing related research papers.\n\nThe whole prompt workflow consists of three steps:\n\n(1) Given a PDF of the lecture notes, the model extracts several core technical topics; \n\n(2) For each topic, it generates specific search queries and uses them to retrieve relevant papers from Google Scholar or arXiv (ideally via Agent Mode);\n\n(3) Based on the retrieved papers, it produces structured summaries that explicitly connect back to the lecture topics, proposes an appropriate 2-3 hour reading plan, and generates conceptual reflection questions. This turns paper reading activity into an intended, reflective and guided literature exploration rather than just paper searching and reading.\n\nHere is the chat Link: https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324\n\nHere is the report:",
    "attachments": [
      {
        "name": "Participation E2 Qicheng Zhu.pdf",
        "url": "https://static.us.edusercontent.com/files/3Jt3PO58cbiatKc7bvom9O7y"
      }
    ],
    "highlight": false,
    "summary": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students deepen their understanding of lecture content by automatically finding and organizing related research papers."
  },
  {
    "id": "ed-7422368",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: HW Concept Check CLI",
    "dek": "Sometime when I look at a homework question, I don't know exactly where to start. Although the struggle of interpreting a question is good, a reminder/concept check seems like it could be helpful. At ...",
    "student": "Aryan Bansal",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422368"
    },
    "body_html": "Sometime when I look at a homework question, I don't know exactly where to start. Although the struggle of interpreting a question is good, a reminder/concept check seems like it could be helpful. At the same time, asking a chat application makes it hard to not overshare and delegate work.\n\nTherefore, I created a simple CLI that presents a series of conceptual questions about homework questions. The CLI makes it easy to select and a homework no. and part no. The generated question can be responded to via the cmd line or a hint can be requested. When a response is submitted, it is evaluated against the expected answer, and a follow up question will be presented to fill in the gaps. An LLM is necessary for the task of grading free-response answers effectively.\n\nI first created an ingestion script that iteratively takes every homework and uses an effective system prompt to generate the bank of questions and write to .json files. This does not have to be run again. The main script \"concept_cli_app.py\" launches the GUI. The script is bring your own key (export OPENAI_API_KEY=sk...)\n\nBelow I've attached the zip file of the repo and an annotated example interaction. The README has proper instructions (create env, export key, run it).\n\n\n\n\n\n",
    "attachments": [
      {
        "name": "example_interaction.txt",
        "url": "https://static.us.edusercontent.com/files/qsc1HxW5tESls4AiK9ItaOdV"
      },
      {
        "name": "concept_cli.zip",
        "url": "https://static.us.edusercontent.com/files/PRZLzDJxu9zFPhbSItsaGj4j"
      }
    ],
    "highlight": false,
    "summary": "Sometime when I look at a homework question, I don't know exactly where to start. Although the struggle of interpreting a question is good, a reminder/concept check seems like it could be helpful. At the same time, asking a chat application makes it hard to not overshare and delegate work."
  },
  {
    "id": "ed-7422332",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Understanding Pooling and Backprop better from 10/2 and 9/30 lectures",
    "dek": "This interaction documents my use of ChatGPT as an AI-enhanced learning tool to help me understand material from the 9/30 and 10/2 EECS 182 lectures. I prompted the model with very specific questions ...",
    "student": "Tamzid Razzaque",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422332"
    },
    "body_html": "This interaction documents my use of ChatGPT as an AI-enhanced learning tool to help me understand material from the 9/30 and 10/2 EECS 182 lectures. I prompted the model with very specific questions that came directly from moments of confusion during lecture, such as why gradients scale like √N for shared weights in backprop, whether gradients are summed or averaged, how gradients flow through mean and max pooling, and how pooling and convolution affect spatial dimensions versus channel count in architectures like AlexNet. I also asked follow-up clarification questions about notation (e.g., what symbols like a, b, c, d and g represent) and about how activations change across training steps.\n\nThe AI responded by breaking each concept into step-by-step explanations, often re-deriving what was shown in lecture more slowly and with concrete examples. In several cases, it successfully clarified the professor’s intent, especially around weight sharing, pooling backpropagation, and the distinction between activations and learnable parameters. The tool was particularly helpful as a substitute for pre- or post-lecture reading, translating fast-paced boardwork and verbal explanations into structured reasoning.\n\nI critically annotated the trace to point out when the AI stayed closely aligned with lecture content and when it went beyond the lecture by adding extra intuition or external context (e.g., references to numerical precision or broader deep-learning practices). While these additions were generally consistent with the course material, I noted where they were enrichment rather than strictly what was covered in class. Overall, this interaction shows how an LLM can function as an active learning companion for lectures by answering targeted questions, correcting misconceptions, and reinforcing core ideas when used with careful human oversight.",
    "attachments": [
      {
        "name": "lecture9:30-10:2-trace_with_commentary.pdf",
        "url": "https://static.us.edusercontent.com/files/uA21sfWespp8OeTW9H9MFmSH"
      }
    ],
    "highlight": false,
    "summary": "This interaction documents my use of ChatGPT as an AI-enhanced learning tool to help me understand material from the 9/30 and 10/2 EECS 182 lectures. I prompted the model with very specific questions that came directly from moments of confusion during lecture, such as why gradients scale like √N for shared weights in backprop, whether gradients are summed or averaged, how gradients flow through me"
  },
  {
    "id": "ed-7422272",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Claude \"Artifacts\" for Visualization Tutor with VAE Example",
    "dek": "For this assignment, I built a \"Visualization Tutor\" to help us build intuition for the math behind Variational Autoencoders (Lecture 24). I used Claude 4.5 Sonnet to create an interactive web-based v...",
    "student": "Elizabeth Polito",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422272"
    },
    "body_html": "For this assignment, I built a \"Visualization Tutor\" to help us build intuition for the math behind Variational Autoencoders (Lecture 24). I used Claude 4.5 Sonnet to create an interactive web-based visualizer. I chose Claude because of its \"Artifacts\" feature. It now has a dedicated UI window that renders code (like React or HTML) instantly alongside the chat, and allows for a good amount of iteration before you hit free tier limits. This allowed me to iterate on the tool in real-time to visualize the VAE concepts we learned in class and audit the correctness of the implementation/add new features. I would also like to credit that I also used Gemini to help ideate for this assignment. Overall, Claude seemed to accurately synthesize the requests and was able to generate a VAE visualization with little trouble, which helps to better understand how the relative entropy term works for VAEs.\n\nThe resulting artifact is a single-file HTML/React application (attached below) that lets you manipulate the encoder's outputs ($\\mu$ and $\\Sigma$) and see how they affect the latent distribution.\n\nThe Interaction Trace High-Level Overview:\n\nI used an initial prompt to set up the parameters for the visualization and shared the course notes for the relevant lecture.\n\nI checked the model's noise generation logic, suspecting it might rely on simple Uniform sampling (standard in JS). However, I verified that the model had correctly implemented the Box-Muller transform, ensuring the noise $\\epsilon$ followed the required $N(0,I)$ distribution.\n\nI forced the model to reconcile its simplified code with the discussion/notation from Lecture 24. \n\nFinally, I used the tool to visually demonstrate the \"Tradeoff\" concept from Page 3 of our notes. By setting the KL-Divergence weight to zero, I simulated the failure mode of a standard Autoencoder, providing a visual proof of why \"Distribution Loss\" is necessary for generation.\n\nI asked Claude to generate a user guide with some guided questions so that the visualization is more than just a passive tool but can be used for effective studying to better understand how VAEs work.\n\nFeel free to check out the website and play with the sliders to feel the \"pressure\" of the KL regularization yourself! I have attached a link to the website (Claude lets you export directly which is nice for sharing with your study group!) By using this prompting structure/Claude toolkit, you will be able to generate clean, easy-to-use visualizations to help with finals studying.\n\nHere is a link to the Website: \nhttps://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b \n\n(If you want to use the interactive features, such as the sliders, it looks like you’ll have to click “Customize” which will open it in an interactive UI)\n\nHere is a PDF of the User Guide/Tutorial that Claude generated: VAE Visualizer File\n\nAnd here is the annotated trace of my interaction with Claude: \n\nAddendum: Finally, this is outside of the scope of my Special Participation E, but I wanted to share anyway for anyone reading this who may be interested in information theory/data compression that VAEs have a very natural application in compression (somewhat in the spirit of the HW #12 information bottleneck VAE problem). The idea is that you compress sources by quantizing a representation in the latent space (which introduces some non-differentiability issues during training which is an active topic of research that people are trying to reconcile by coming up with stochastic alternatives to standard quantization). There is a cool paper from 2017 that shows even initial attempts at VAE-based ‘neural’ image compression outperforms JPEG compression (in terms of achieving better distortion measured by mean squared error between the source/reconstruction for the same compression rate measured in bits/pixel).\n\nLink to Balle’ et al. 2017: [1611.01704] End-to-end Optimized Image Compression",
    "attachments": [
      {
        "name": "VAE Visualizer - Student User Guide.pdf",
        "url": "https://static.us.edusercontent.com/files/JCeQBqQLDXLbAZdgeFpZe0kK"
      },
      {
        "name": "annotated_claude_trace.pdf",
        "url": "https://static.us.edusercontent.com/files/ME2Qa0e5cChCLxmVNkw3A9KG"
      }
    ],
    "highlight": false,
    "summary": "For this assignment, I built a \"Visualization Tutor\" to help us build intuition for the math behind Variational Autoencoders (Lecture 24). I used Claude 4.5 Sonnet to create an interactive web-based visualizer. I chose Claude because of its \"Artifacts\" feature."
  },
  {
    "id": "ed-7422149",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Claude as tutor for building up the concept of Mamba",
    "dek": "I try to use Claude as a tutor for building up the concept of Mamba step by step. The tutoring session generally demonstrates great pedagogical design, with a progressive build-up from RNNs through SS...",
    "student": "Yaqi Su",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422149"
    },
    "body_html": "I try to use Claude as a tutor for building up the concept of Mamba step by step. The tutoring session generally demonstrates great pedagogical design, with a progressive build-up from RNNs through SSMs to S4 and finally Mamba that mirrors the logical development in the course materials. The quizzes effectively check understanding at each conceptual stage. The mathematical treatment is generally rigorous, particularly in the discretization derivation and convolution unrolling sections, which closely match the lecture notes while providing step-by-step clarity that helpfully supplements the original material. Core concepts including the fundamental SSM equations, the dual-mode operation (convolution for training, recurrence for inference), and Mamba's selectivity mechanism are correctly explained.\n The primary issue (or shouldn’t be called as an issue?) with this tutoring session is that is a bit scope creep. This includes the explicit HiPPO-LegS matrix formula, the Cauchy kernel trick for S4, detailed MambaBlock implementation code with specific architectural choices, hardware-level efficiency explanations involving kernel fusion and memory hierarchies, and empirical observations about Mamba's limitations on copying tasks and in-context learning. Though I think those contents actually helped me gain a deeper understanding of the design of Mamba, and I didn’t identify particularly obvious fact errors. But if trying to use this approach for exam preparation, I think it might be better to also provide the lecture notes to Claude beforehand, so that it’s aware of the context and may therefore design the contents more tailored to the course.\n\n",
    "attachments": [
      {
        "name": "Claude-cs282 specialContributionE-Mamba.pdf",
        "url": "https://static.us.edusercontent.com/files/pRYoei5xu15qx05A3m3E12O5"
      }
    ],
    "highlight": false,
    "summary": "I try to use Claude as a tutor for building up the concept of Mamba step by step. The tutoring session generally demonstrates great pedagogical design, with a progressive build-up from RNNs through SSMs to S4 and finally Mamba that mirrors the logical development in the course materials. The quizzes effectively check understanding at each conceptual stage."
  },
  {
    "id": "ed-7422043",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Claude as tutor for building up the concept of Muon optimizer",
    "dek": "I'm trying to use Claude as a tutor to gradually build up the concept of Muon optimizer, with quizzes given by Claude throughout the process. Overall, Claude demonstrated good teaching instincts by bu...",
    "student": "Yaqi Su",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7422043"
    },
    "body_html": "I'm trying to use Claude as a tutor to gradually build up the concept of Muon optimizer, with quizzes given by Claude throughout the process. Overall, Claude demonstrated good teaching instincts by building a clear learning path, it did a great job tracing the historical and mathematical lineage from classical optimizers (like SGD, Adam, Shampoo, also pointed out the key advancement and limitation of each optimizer) to Muon. It provided high-quality technical derivations, most notably showing how Shampoo’s preconditioner collapses into the orthogonalized gradient and why this leads naturally to Newton–Schulz. Claude was also responsive and adaptive, when I asked it to elaborate more on certain concepts (like Adam and Newton-Schulz), it shifted smoothly from abstract theory to a concrete numerical walkthrough. Finally, it correctly highlighted important implementation details of Muon, including the ordering of momentum before orthogonalization. The main shortcoming was its complete omission of muP, which is also a foundational theoretical framework that explains why Muon achieves reliable scaling and automatic learning-rate transfer. And sometimes its explanations were overly abstract.  Additionally, it also missed some conceptual connections, such as connecting Adam to signSGD to strengthen intuition about magnitude-invariant updates.  But overall I think it still did a relatively great job, especially being able to provide me with some pretty insightful quiz questions that helped me better understand the concept.",
    "attachments": [
      {
        "name": "Claude-CS282-specialParticipationE-Muon.pdf",
        "url": "https://static.us.edusercontent.com/files/orQkU4Tfrfiv33QuvQH6A5cm"
      }
    ],
    "highlight": false,
    "summary": "I'm trying to use Claude as a tutor to gradually build up the concept of Muon optimizer, with quizzes given by Claude throughout the process. Overall, Claude demonstrated good teaching instincts by building a clear learning path, it did a great job tracing the historical and mathematical lineage from classical optimizers (like SGD, Adam, Shampoo, also pointed out the key advancement and limitation"
  },
  {
    "id": "ed-7421430",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Gemini as a Lecture Notes Tutor",
    "dek": "I used Gemini to build a tutor to help better understand the lecture notes. My tutor first provides the student with flashcards to ensure a base-level understanding, tests that understanding in a simp...",
    "student": "Kian Hekmatnejad",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7421430"
    },
    "body_html": "I used Gemini to build a tutor to help better understand the lecture notes. My tutor first provides the student with flashcards to ensure a base-level understanding, tests that understanding in a simple quiz, and finally provides some questions in a broader deep-learning context to confirm that the student has a firm grasp on the concepts in the lecture notes. My report is attached",
    "attachments": [
      {
        "name": "special_participation (2).pdf",
        "url": "https://static.us.edusercontent.com/files/sbjBK3te61xHSWeIMrZQ0rpm"
      }
    ],
    "highlight": false,
    "summary": "I used Gemini to build a tutor to help better understand the lecture notes. My tutor first provides the student with flashcards to ensure a base-level understanding, tests that understanding in a simple quiz, and finally provides some questions in a broader deep-learning context to confirm that the student has a firm grasp on the concepts in the lecture notes."
  },
  {
    "id": "ed-7421107",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Using ChatGPT to Distinguish Similar Concepts in Notes via Embeddings",
    "dek": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students better understand and distinguish similar concepts that appear in our lecture notes. \n\nThe work...",
    "student": "Qicheng Zhu",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7421107",
      "chatgpt": "https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c"
    },
    "body_html": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students better understand and distinguish similar concepts that appear in our lecture notes. \n\nThe workflow proceeds in four main steps. First, I input a PDF slide file and extract the most frequently used technical terms from the lecture. Second, I generate embeddings for these candidate concepts. Third, I compute cosine similarities between these embeddings to identify pairs of concepts that are semantically close and therefore likely to be confused by students. Finally, I use ChatGPT to provide specific explanations of each similar pair and to generate a small quiz to test whether students can correctly distinguish them.\n\nThis pipeline can be applied to any lecture and shared with classmates as a reusable prompt template. It offers a structured way to focus attention on subtle conceptual differences rather than just memorizing isolated definitions. However, because ChatGPT can still hallucinate certain explanations, we should double check its answers against the notes and textbook.\n\nHere is the chat Link: https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c\n\nHere is my report:\n",
    "attachments": [
      {
        "name": "Participation E1 Qicheng Zhu.pdf",
        "url": "https://static.us.edusercontent.com/files/w8NpbGxCT7VrBvGfyV7Tqwsf"
      }
    ],
    "highlight": false,
    "summary": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students better understand and distinguish similar concepts that appear in our lecture notes."
  },
  {
    "id": "ed-7420861",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides",
    "dek": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides\n\nAfter trying to use lecture notes to help me review in preparation for the final, I realized that some of...",
    "student": "Divya Ramesh",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7420861"
    },
    "body_html": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides\n\nAfter trying to use lecture notes to help me review in preparation for the final, I realized that some of the later lecture notes don’t have all the material that was talked about. This may be because the more recent lectures have turned from a more mathematical view into a more conceptual, informational view. Because of this, purely analyzing lecture notes doesn’t give you the whole picture. I’ve found the lecture videos have been the most helpful, but it might take a long time to go over every single lecture in so little time. So, I had the hypothesis that the lecture transcript would be a better recap because it has more information, everything that was talked about was in the lecture transcript, while not everything was in the notes. \n\nSo I decided to test out a comparison between the 2, checking the differences between inputting the lecture notes versus the lecture transcript. Both have drawbacks:\n\nSome drawbacks of lecture notes is lecture notes have a lot of diagrams, and gemini needs to analyze all these diagrams in order to make a judgement. Also, Gemini needs to recognize handwriting in order to give the details we need to recap. \n\nSome drawbacks of the video transcript is lecture transcript may not be fully transcribed correctly. This might cause errors, but I’m hoping maybe Gemini will be able to fill in the gaps or correct and mis-transcribed pieces. The way I obtained this is by copy pasting the YouTube transcript into a document and then downloading it as a pdf.\n\nI started by creating separate gemini windows, each having one of the lecture notes or transcript downloaded as a file to analyze, and then using the same prompts on both. I saw what both focused on, what created the best overview, and generated the most useful information for recap. \n\nSee my annotations below:\n\nAnnotated Lecture Slides Gemini Conversation: https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_link\n\nAnnotated Lecture Transcript Gemini Conversation: \n\nhttps://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharing\n\nWhat I discovered was:\n\nLecture notes contained a lot more of the key concepts, emphasizing them but not necessarily too much detail about them. This makes sense since what is written is the main ideas.\n\nLecture transcript contained a lot more information because it was a lot longer than the lecture notes, but sometimes missed key concept names. Like it missed the entire section of GPT history, even when I prompted it to give me the GPT history, the transcript window couldn’t give me any information. \n\nBoth had trade offs, but I think the lecture notes are ultimately a better resource than the lecture transcript. Even though the transcript went more in depth, the lecture notes actually touched on every single topic, even if there was no depth within those sections. I think a good strategy would be to upload the notes and then ask specific questions about those topics after. \n\nBut in terms of generating practice questions, the transcript is a better resource, since the nuances mentioned by the professors during lecture provide deeper questions, and allow the student to really think while the notes provide very surface level questions. ",
    "attachments": [],
    "highlight": false,
    "summary": "After trying to use lecture notes to help me review in preparation for the final, I realized that some of the later lecture notes don’t have all the material that was talked about. This may be because the more recent lectures have turned from a more mathematical view into a more conceptual, informational view. Because of this, purely analyzing lecture notes doesn’t give you the whole picture."
  },
  {
    "id": "ed-7419581",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Paper Explainer",
    "dek": "Papers are often linked in homework assignments, discussion assignments, and often the papers are very hard to grasp especially on a first pass. I thought it would be helpful to make a prompt to expla...",
    "student": "Oliver Chen",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7419581",
      "chatgpt": "https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6"
    },
    "body_html": "Papers are often linked in homework assignments, discussion assignments, and often the papers are very hard to grasp especially on a first pass. I thought it would be helpful to make a prompt to explain an uploaded paper pdf, specifically in the context of the content of this class, such as:\n\nLinear algebra (matrix multiplication, projections, eigenspaces, orthogonality)\n\nVector calculus (gradients, Jacobians, Hessians)\n\nOptimization (SGD, momentum, Adam, convexity, nonconvex landscapes, saddle points)\n\nNeural network architectures (MLPs, CNNs, transformers, attention, residual networks)\n\nLoss functions (cross-entropy, mean squared error, likelihoods)\n\nBackpropagation (chain rule, computational graph, gradient flow)\n\nGeneralization, overfitting, underfitting\n\nRegularization (L2, dropout, weight decay)\n\nRepresentation learning\n\nTraining dynamics (learning rate, gradient norms, scaling laws)\n\nI found this tool I made to be very helpful when there is a paper mentioned in a homework question, and before reading it in depth, I want to get an overview of what topics are covered, what math I might have to catch up on, and what other concepts in class this paper relates to. \n\nIt also took a bit of work making sure the model does not hallucinate or make up explanations or talk about something that's not mentioned in the paper, and also to clarify what specific content from cs182 to draw connections to.\n\nHere is a chatgpt log of me using this to explain https://arxiv.org/abs/1909.08593 (from homework 13) in terms of the content in CS182: https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6\n\nI thought it was very helpful, as it also identified all equations in the paper and derived them from concepts from this class. \n\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "Papers are often linked in homework assignments, discussion assignments, and often the papers are very hard to grasp especially on a first pass. I thought it would be helpful to make a prompt to explain an uploaded paper pdf, specifically in the context of the content of this class, such as:"
  },
  {
    "id": "ed-7419566",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: ChatGPT Transformer Operations Visualizer",
    "dek": "I think transformers specifically are a difficult topic because there are many specific operations and parameters to remember -- and so keeping track of everything while solving a transformer-related ...",
    "student": "Oliver Chen",
    "date": "2025-12-07",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7419566",
      "chatgpt": "https://chatgpt.com/share/693431c7-b8d4-800b-a322-e39ae6475f1f"
    },
    "body_html": "I think transformers specifically are a difficult topic because there are many specific operations and parameters to remember -- and so keeping track of everything while solving a transformer-related homework problem can be a bit tough. I created a ChatGPT prompt to create a operations graph visualizer, given a homework problem, of all the transformer operations this passed through, making it very clear what dimensions the input data is, how it's transformed and through what specific operations and what they're called. \n\n\n\nIt took be a bit of tweaking to make sure ChatGPT would not give me answers, but still very accurately visualize the relevant parts of the transformer for the given homework problem. The prompt is very long, so I will show it in the chat logs as opposed to pasting it directly in the Ed post. \n\nI also found through testing that generating ASCII diagrams was the best way, as one very good feature of ASCII diagrams is it can also label and explain operations/parameters in text, where as other forms of visualization struggle with text. \n\nHere is a chat log of me using it to visualize the transformer operations on homework 9:\nhttps://chatgpt.com/share/693431c7-b8d4-800b-a322-e39ae6475f1f",
    "attachments": [],
    "highlight": false,
    "summary": "I think transformers specifically are a difficult topic because there are many specific operations and parameters to remember -- and so keeping track of everything while solving a transformer-related homework problem can be a bit tough."
  },
  {
    "id": "ed-7419470",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Misconception Explorer",
    "dek": "I found that often times after lecture I'll have some idea cemented in my head, only to much later find out that one of the basic assumptions I had made was wrong. To try and alleviate this, I thought...",
    "student": "Kabir Shah",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7419470"
    },
    "body_html": "I found that often times after lecture I'll have some idea cemented in my head, only to much later find out that one of the basic assumptions I had made was wrong. To try and alleviate this, I thought it would be useful to have a \"Misconception Explorer\" prompt where you can engage with an LLM by giving it lecture notes and having it probe you with examples and questions that test common misconceptions. Here's the prompt:\n\nYou are my Misconception Explorer.\n\nI will paste the full text of a PDF of lecture notes. Your job is to identify 4 of the most plausible misconceptions or subtle misunderstandings a student might develop from these notes.\n\nFor each of the four selected misconceptions, do the following INTERACTIVELY:\n• Ask me a question that probes whether I fall for the misconception or understand the concept correctly.\n• Wait for my answer before revealing the explanation.\n• After I answer, explain:\n    - Whether my answer reflects the misconception.\n    - The correct reasoning.\n    - Why the misconception is tempting.\n\nImportant behavior rules:\n• Do NOT state, hint at, or describe the misconception before presenting the probing question. Only reveal the misconception after I answer the question.\n• Do NOT rush through all four misconceptions at once. Present them ONE AT A TIME.\n• After finishing the full explanation for one misconception, ask if I am ready for the next.\n• Keep each example small, focused, and tied directly to content in the PDF.\n• If the notes are ambiguous, state this explicitly.\n• Avoid introducing concepts not present in the PDF unless needed for correction, and mark such additions clearly.\n\nBegin by asking me to paste the lecture notes PDF text.\nAfter I paste it, start with Question #1.\n\n\nI had to iterate on it many times because it would often start brainstorming misconceptions before asking me about them, kind of defeating the purpose of it. I found that the \"important behavior rules\" were crucial to preventing this type of behavior and ensuring that the model first asks you the questions before talking about the misconception it might be testing. I ran it through Lecture 19 (transformers, positional embeddings), and here's what I got:\n\nI found that it was actually pretty good and taught me a few new things: (1) that embeddings and unembeddings can use the same weight matrix and don't necessarily need to be separate projections (and GPT-2 does this!) and (2) RoPE can encode absolute position information implicitly.\n\nSome of the questions it asked were really easy or kind of arbitrary, but they did attempt to test some kind of misconception which I thought was cool. For example, it asked if RoPE required frequencies to be shared across layers, which I guess students might assume is true because that is how it is done, but is not a requirement for it to work. While these types of technicalities were less useful than the other misconceptions it tested, I found that they were still good forms of review and forced me to think about what the true requirements for things like RoPE were and what were there for reasons such as stabilizing training.\n\nI found in my use that it didn't hallucinate much but it is very limited to the quality of the notes that you give it, especially since the prompt asks it to stay grounded to the content of the notes you give it. So it will often be very specific to the lecture. If you have text notes or markdown/latex formatting I think it will likely be much better than submitting a hand-written note pdf like I did. Overall, I think this is a pretty useful tool and can help you wrap your head around the trickier deep learning concepts by testing more subtle \"edge cases\" of the concepts covered in lecture.",
    "attachments": [
      {
        "name": "Misconception exploration process.pdf",
        "url": "https://static.us.edusercontent.com/files/IfpWkLpXxQJhEnepJikNXUXz"
      }
    ],
    "highlight": false,
    "summary": "I found that often times after lecture I'll have some idea cemented in my head, only to much later find out that one of the basic assumptions I had made was wrong."
  },
  {
    "id": "ed-7419439",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Drill Generator",
    "dek": "While a lot of study tools and methods seem useful, I always tend to use them once or twice and then end up stopping. I think an ideal study tool would be really easy to use and also a low time commit...",
    "student": "Kabir Shah",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7419439"
    },
    "body_html": "While a lot of study tools and methods seem useful, I always tend to use them once or twice and then end up stopping. I think an ideal study tool would be really easy to use and also a low time commitment, so instead of generating detailed quizzes, I tried to make a prompt that can just take in lecture notes and provide an \"easy\" MCQ drill that is designed to just help you recall different parts of lecture to allow it to be as low-commitment of an addition into your study routine as possible. Here's the prompt:\n\n\nYou are the Concept Drill Generator for my deep learning class.\n\nI will paste the professor’s lecture notes below. \nYour job is to generate a short practice drill based ONLY on the content of those notes.\n\n--------------------------------------\nREQUIRED INPUT (from me): LECTURE NOTES\n--------------------------------------\n\nAfter I paste the notes, do the following:\n\n1. Generate 8–12 questions total, mixing:\n   - multiple choice (A, B, C, D)\n   - simple fill-in-the-blank\n\n2. All questions must strictly reflect the lecture notes.\n   - Do NOT introduce material not present in the notes.\n   - If the notes are ambiguous or missing detail, simplify the question rather than guessing.\n   - Mark any question where your confidence is medium or low.\n\n3. After generating the questions, stop and wait for my answers.\n   - I will answer them one by one or in batches.\n   - After each answer, you will:\n        a. Tell me whether my answer is correct.\n        b. Briefly explain why (using only the lecture notes as the source).\n        c. If you are uncertain, say so explicitly.\n\n4. Do NOT reveal the correct answers until I attempt the question or ask for them.\n\n--------------------------------------\nWhen you're ready, say: “Please paste the lecture notes.”\n\n\n\nYou can paste this in, and then it will prompt you to paste in lecture notes. Here's an example run for lecture 16 (the introduction lecture to SSMs):\n\nYou'll see that the output was pretty useful about 80% of the time. However, in one of the questions it gave away the answer by admitting its lower confidence in the notes that I uploaded. I think that this prompt is primarily limited by the fidelity of the notes pasted. Here, I just pasted the raw pdf of the lecture notes so it was limited by how well it was parsed into text. I think that if you paste in hand-typed notes it would be ideal.\n\nEither way, most of the questions weren't too complex but just enough to get me to recall the important points of lecture and why they were important. It was able to give me hints when I was stuck, and it also gave good explanations when I was wrong.\n\nIt did hallucinate pretty badly once where it accepted a wrong answer of mine and cited the wrong page to justify it. I had to correct it and tell it the correct answer. I think once again this was due to the fidelity of the uploaded notes. But it's important to keep in mind and something to watch out for when using this tool.\n\nThere's also some room for improvement because some of the questions I felt overly focused on the specifics of lecture rather than a concept. For example, it would have you fill in the blank of a specific phrase used in the lecture notes. I don't know how useful this actually is compared to conceptual understanding, but either way it did make me look back at the notes to try and figure out the answer so maybe it worked to help my understanding either way!",
    "attachments": [
      {
        "name": "Drill-example.pdf",
        "url": "https://static.us.edusercontent.com/files/0LUCxLO6CzPmz4viuPFmNOCw"
      }
    ],
    "highlight": false,
    "summary": "While a lot of study tools and methods seem useful, I always tend to use them once or twice and then end up stopping. I think an ideal study tool would be really easy to use and also a low time commitment, so instead of generating detailed quizzes, I tried to make a prompt that can just take in lecture notes and provide an \"easy\" MCQ drill that is designed to just help you recall different parts o"
  },
  {
    "id": "ed-7419382",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: “LLM as an Active Student” Prompt",
    "dek": "I’ve been experimenting with using LLMs as a way to “learn by teaching,” since I often understand CS 182 topics better when I try to explain them out loud. I set up a prompt where the LLM plays the ro...",
    "student": "Lenci Ni",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7419382"
    },
    "body_html": "I’ve been experimenting with using LLMs as a way to “learn by teaching,” since I often understand CS 182 topics better when I try to explain them out loud. I set up a prompt where the LLM plays the role of a really active, CS-189-trained student: it summarizes what I say, asks clarifying questions, challenges gaps in my explanation, and even corrects me when something is off. This forces me to think more carefully about each concept.\n\nI’ve attached the prompts below, along with an example conversation where I tried teaching CNN concepts to the “student.” Overall, the LLM was surprisingly good at catching subtle mistakes, asking the right kinds of probing questions, and pushing me to justify steps. It definitely helped surface gaps in my understanding. That said, it isn’t the most natural conversational partner as some of its explanations can be a bit stiff or overly formal, and occasionally it oversimplifies details or overcorrects in ways a real student wouldn’t. Still, as a learning tool, it worked well for encouraging active engagement rather than passive reading.\n\nSeries of prompts used:\n\nExample conversation (annotated):",
    "attachments": [
      {
        "name": "participation_e_1_prompt.pdf",
        "url": "https://static.us.edusercontent.com/files/euZsjsdifWETajvqeSZ0ibkN"
      },
      {
        "name": "participation_e_1.pdf",
        "url": "https://static.us.edusercontent.com/files/VREaF2siIvzFb7TVgApw909u"
      }
    ],
    "highlight": false,
    "summary": "I’ve been experimenting with using LLMs as a way to “learn by teaching,” since I often understand CS 182 topics better when I try to explain them out loud. I set up a prompt where the LLM plays the role of a really active, CS-189-trained student: it summarizes what I say, asks clarifying questions, challenges gaps in my explanation, and even corrects me when something is off."
  },
  {
    "id": "ed-7418400",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Engineering System Prompts and Learning from Figures with Gemini (Thinking With 3 Pro)",
    "dek": "For my Option E submission, I tackled a common annoyance: LLMs hallucinating arrows and labels in architecture diagrams.\n\nI used a meta-prompt engineering strategy to develop a \"Visual Forensic\" syste...",
    "student": "Nicolas Rault-Wang",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7418400",
      "github": "https://github.com/nraultwang"
    },
    "body_html": "For my Option E submission, I tackled a common annoyance: LLMs hallucinating arrows and labels in architecture diagrams.\n\nI used a meta-prompt engineering strategy to develop a \"Visual Forensic\" system prompt that encourages Gemini to verify visual information in figures before explaining it.\n\nHow it works:\n\nAnti-Hallucination: It instructs the model to write and execute Python OCR code (e.g., Python-tesseract) to extract text labels from the image before it tries to explain the concepts. \n\n\"Visual Manifest\": The model summarizes its visual understanding in a text-based outline. This not only translates the diagram into a verbal description–which helps ground the model in reality–but also makes it easy to spot discrepancies between the figure and the model's native vision.\n\nSocratic Mode: It uses verified visual data to quiz me on specific mechanics (e.g., \"Why does the arrow split here?\").\n\nFlashcards: It synthesizes our discussion into short Anki-style flashcards.\n\nAttached is the report on my debugging process and the system prompt I developed:\n\nEdit: Added links for the archive\n\nPersonal website: https://nraultwang.github.io/\n\nGithub: https://github.com/nraultwang",
    "attachments": [
      {
        "name": "Rault-Wang_Nicolas-Special-Participation-E_v2.pdf",
        "url": "https://static.us.edusercontent.com/files/f6jDIM1tl0QfggIonglx2Ve4"
      }
    ],
    "highlight": false,
    "summary": "For my Option E submission, I tackled a common annoyance: LLMs hallucinating arrows and labels in architecture diagrams."
  },
  {
    "id": "ed-7418341",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: AI-powered Lecture-Grounded Learning Assistant",
    "dek": "Motivations\n\nFor this participation, I wanted a tool that lets us search lecture content directly, rather than relying on Google or LLM answers that may drift outside the course scope. YouTube transcr...",
    "student": "Angelina Zhang",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7418341",
      "github": "https://github.com/Angelinaaaaaaaaaaaa/lecture_finder"
    },
    "body_html": "Motivations\n\nFor this participation, I wanted a tool that lets us search lecture content directly, rather than relying on Google or LLM answers that may drift outside the course scope. YouTube transcripts exist, but scrolling through them is slow and the text often contains errors. I wanted something that behaves like a lightweight retrieval engine for the class: whenever I ask a question, it would point me to the exact timestamp where the professor discussed that topic and provide me something that are discussed in class. \n\nHow It Works\n\nThe system works by turning timestamped transcripts into searchable embedding chunks. The script build_index.py parses each transcript, recognizes timestamp lines, and converts the text between timestamps into a segment. Each segment is embedded using the OpenAI text-embedding-3-small model, and all segments with lecture ID, timestamp, and embedding, are stored in a JSON index. The second script, search_segments.py, embeds your question the same way and computes cosine similarity against every segment embedding. It then returns the most relevant timestamps, along with short snippets so you can quickly revisit the exact moment in the lecture where the concept appears. All transcripts can be pasted directly from YouTube’s “Show Transcript” feature, although I do not include real transcript data in the repository due to privacy. I also added a chat-generation stage on top of retrieval: once segments are retrieved, the tool feeds them into a structured “Lecture-Grounded Learning Assistant” prompt. The prompt asks the LLM to generate:\n\na summary of the professor’s explanation based only on retrieved text,\n\nan analogy,\n\na worked-out example,\n\na quiz, and\n\ncommon misconceptions.\n\nBecause the retrieved segments are shown alongside the generated answer, students can directly check whether the model’s claims are supported. This design makes hallucination auditable, rather than hidden.\n\nInstructions for Use\n\nTo run the system, you place your transcript .txt files in data/transcripts/, run python build_index.py once to generate embeddings, and then run python search_segments.py to start an interactive question prompt. You can ask any conceptual question (“Where did we derive the SGD update rule?”), and the tool returns the closest matches with similarity scores. This essentially converts the entire set of lecture videos into a searchable study resource that you can navigate much more efficiently than by scanning full recordings. You can find these code here: https://github.com/Angelinaaaaaaaaaaaa/lecture_finder\n\nAI Interaction Trace\n\nDuring development, I used LLMs as a brainstorming partner for parsing logic and embedding retrieval. Many suggestions were helpful but required verification. For example, the model initially suggested a timestamp regex that incorrectly matched numbers appearing inside sentences, causing segmentation errors; refining this required repeated testing. When I asked about similarity search, it recommended a full vector database, which turned out unnecessary and even slower for my dataset size. I ultimately implemented cosine similarity in pure Python after finding dimension mismatches that the model failed to warn me about. These debugging steps gave me a practical understanding of segmentation design and retrieval pipelines.\n\nAfter building the system, I used it to generate lecture-grounded answers on top of retrieval and then produced a fully annotated interaction trace examining when the model stayed faithful and when it drifted. That detailed analysis is here:\nhttps://docs.google.com/document/d/1E9v3ftDCaUzSqYOheHOa6nt6H15Fh3dkzKJ-28ntDM8/edit?usp=sharing\n\nTo give a concrete example from the trace: when asking “Why do we need Adam instead of SGD with momentum?”, the model retrieved only high-level lecture snippets but then added details (e.g., per-parameter learning rate adaptation) that were true but did not appear in the retrieved parts. This is a typical “gap-filling” behavior: retrieval reduces hallucination, but when evidence is shallow, the model backfills using prior knowledge.\n\nSummary of Findings (LLM Behavior Under Retrieval)\nMy central takeaway of this project is:\n\nRetrieval does not eliminate hallucination; it changes the failure mode and makes hallucinations auditable.\n\nSome patterns I observed:\n\nWithout retrieval, the model freely produces generic textbook derivations, sometimes attributing them incorrectly to the professor.\n\nWith retrieval, the model becomes noticeably more grounded. For example, when I asked about the SGD derivation, it explicitly admitted that the derivation was not present in the retrieved segments. This is a major improvement over the unconstrained setting.\n\nHowever, when retrieved segments are shallow (e.g., for Adam vs. momentum), the model begins “filling in missing gaps” using prior knowledge. This produces highly plausible but not necessarily lecture-accurate explanations.\n\nRetrieval helps identify where the model is speculating, because you can scroll up and check whether each claim has transcript evidence.\n\nAs a result, students can audit the model rather than trusting it blindly; retrieval gives us the ground truth reference.\n\n\nThe system already implements the retrieval part of a RAG pipeline, and the structured teaching prompt acts as a lightweight generation stage. Future improvements could include adding lecture-slide images, integrating structured notes from classmates, or building a web UI where students can search visually instead of using the terminal. I’m aware this is only a small prototype, and a full RAG system integrated into a teaching agent like TAI would be much more powerful. But I think this is a useful first step toward that direction. Let me know if you want to extend it!\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "For this participation, I wanted a tool that lets us search lecture content directly, rather than relying on Google or LLM answers that may drift outside the course scope. YouTube transcripts exist, but scrolling through them is slow and the text often contains errors."
  },
  {
    "id": "ed-7417799",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Understanding GNNs through Social Networks with Gemini 3 Pro Guided Learning",
    "dek": "When learning new concepts, I find it useful and interesting to learn them through the lens of a real-world application. When watching the lecture on GNNs, I was intrigued by all its applications to f...",
    "student": "Vrushank Prakash",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7417799"
    },
    "body_html": "When learning new concepts, I find it useful and interesting to learn them through the lens of a real-world application. When watching the lecture on GNNs, I was intrigued by all its applications to fields such as chemistry, networks, etc. I wanted to gain a better understanding of how GNNs work, while learning more about how it is applied to social networks specifically.\n\nI used Gemini 3 Pro with Guided Thinking to walk me through the core ideas within GNNs by using social networks as the motivating example. I attached the GNN lecture notes (lectures 12 and 13) as context. Gemini took me through 3 key ideas: convolution, aggregation, and pooling.\n\nOverall, Gemini did a great job of explaining these ideas through social networks. I definitely got a much better understanding of how convolution and aggregation are fundamental to determining how friends are recommended in social networks. It was interesting to see how pooling was also an important part of social networks, but I do think Gemini hallucinated a bit and gave a way too in-depth explanation.\n\nHere is an annotated trace:",
    "attachments": [
      {
        "name": "CS 182 Special Participation E_ Understanding GNNs through Social Networks.pdf",
        "url": "https://static.us.edusercontent.com/files/a4XvIZgC63bfC8S670rJPeQp"
      }
    ],
    "highlight": false,
    "summary": "When learning new concepts, I find it useful and interesting to learn them through the lens of a real-world application. When watching the lecture on GNNs, I was intrigued by all its applications to fields such as chemistry, networks, etc. I wanted to gain a better understanding of how GNNs work, while learning more about how it is applied to social networks specifically."
  },
  {
    "id": "ed-7417784",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT Study Mode: Prompt Design for Deep Lecture–Paper Learning",
    "dek": "Intro\n\nThis is an attempt to use chatgpt’s study mode to comprehensively review lecture content together with the corresponding papers. I understand that chatgpt’s study mode has already been explored...",
    "student": "Alex Cao",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7417784",
      "chatgpt": "https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08"
    },
    "body_html": "Intro\n\nThis is an attempt to use chatgpt’s study mode to comprehensively review lecture content together with the corresponding papers. I understand that chatgpt’s study mode has already been explored by other threads, but this study is specifically focused on a prompting style that makes study mode more effective, by carefully designing prompts tailored to how chatgpt study mode is designed. The goal is to investigate an effective way to review lecture material alongside the original paper in order to gain deeper, more informative understanding and to actually learn new things, not just recall them. In this project, I used the course lecture transcript as part of the prompt, solely for educational purposes.\n\nFull Trace:\n\nhttps://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08\n\nAnnotated Trace\n\nSummary\n\nIn this attempt, I used a case study to explore how to better prompt chatgpt’s study mode in order to have a more effective study session. At the same time, I reflect on what I can do better in my prompts from two perspectives: reinforcing good behaviors and avoiding bad ones.\n\nI discovered some nice features of chatgpt’s study mode that can be reinforced in the prompt to encourage good behaviors and reduce unhelpful ones. First, when I provide a source, it helps to tell chatgpt how familiar I am with that source. Otherwise, it might assume I have already read it and directly use phrases from it, which can cause confusion. Second, when dealing with a new concept that involves heavy math, it is useful to explicitly instruct chatgpt to first build up intuition with straightforward math before diving into more complex derivations. This makes it easier for my brain to understand the complex math. (Although chatgpt’s study mode implicitly does this, it is still helpful to reinforce it in the prompt.)\n\nThird, another (partly implicit) behavior that is nice to reinforce is asking cahtgpt to provide “mental checkpoints” when checking whether I am confused—for example, bullet points I can mentally cross off to help me organize my thoughts and reflect on whether I really understand the concept. Finally, a very nice feature of study mode is that it asks quiz questions to help solidify understanding. One caveat, however, is that if these questions are not closely related to the overarching question I started with, they can unintentionally redirect the conversation away from the core topic. While this can sometimes be beneficial, often I prefer more focused studying, so this is another point worth explicitly mentioning in the prompt.\n\nOverall, this case study gave me a clearer sense of how to “co-pilot” chatgpt’s study mode so that it better matches my learning goals and supports more focused, effective studying",
    "attachments": [
      {
        "name": "Special participation E （II).pdf",
        "url": "https://static.us.edusercontent.com/files/UZPEMVVHS0WeHNOGRcza1J7m"
      }
    ],
    "highlight": false,
    "summary": "This is an attempt to use chatgpt’s study mode to comprehensively review lecture content together with the corresponding papers. I understand that chatgpt’s study mode has already been explored by other threads, but this study is specifically focused on a prompting style that makes study mode more effective, by carefully designing prompts tailored to how chatgpt study mode is designed."
  },
  {
    "id": "ed-7417181",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Using Gemini to review the concepts before and after studying",
    "dek": "For this special participation I'll be sharing a way I'm studying for the final which consists on doing summaries, cheat sheet and quizzes before and after reviewing the topic so I can be sure I don't...",
    "student": "Gustavo Jose Ortiz Zepeda",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7417181"
    },
    "body_html": "For this special participation I'll be sharing a way I'm studying for the final which consists on doing summaries, cheat sheet and quizzes before and after reviewing the topic so I can be sure I don't forget something, and complement my notes easier. I think the problems are great as conceptual question.\n\nThis is the prompt I used to achieve this behavior:\n\nYou are \"TutorBot,\" an empathetic, clear, and structured academic tutor.\n\nObjective: Your goal is to prepare the student for an exam or deeper learning by synthesizing their Class Notes and Homework Files. You do not teach new, unrelated material; you reinforce what is in the provided files.\n\nProcess: When the user uploads files, analyze them immediately and output a response strictly following this structure:\n\nConcept Map\n\nScan the documents to identify the core topics.\n\nList all key concepts found in the notes.\n\nProvide a 2-sentence plain-English definition for each.\n\n2. Cheat sheet\n\nExtract every mathematical formula or significant rule mentioned. Do not skip one.\n\nLabel what each variable in the formula represents.\n\nNote: If multiple variations exist in the notes, show the most general form.\n\nVery Small, Safe Examples (VSSE)\n\nCreate 1-2 \"Toy Examples\" per concept based on the extracted formulas.\n\nRules for VSSEs: * Use integer numbers (e.g., 2, 5, 10) to make the math trivial. * Avoid decimals, fractions, or complex arithmetic. * Show the step-by-step substitution logic. * Goal: Prove how the formula works mechanically without testing the student's arithmetic skills.\n\nReadiness Check\n\nAsk 20 multiple-choice or short-answer questions but one at a time based strictly on the concepts above (start from easy and then go further).\n\nThese should be \"confidence builders\" to ensure the student understands the basic definitions or variable placements.\n\nStop and wait for the student to answer before proceeding to more complex topics. Always be prepared to review topics or explain again concepts.\n\nTone: Encouraging, patient, and precise.\n\n",
    "attachments": [
      {
        "name": "Special Participation E.pdf",
        "url": "https://static.us.edusercontent.com/files/3pK5A1sq17Q5iqfvjBbqRqI0"
      }
    ],
    "highlight": false,
    "summary": "For this special participation I'll be sharing a way I'm studying for the final which consists on doing summaries, cheat sheet and quizzes before and after reviewing the topic so I can be sure I don't forget something, and complement my notes easier. I think the problems are great as conceptual question."
  },
  {
    "id": "ed-7416810",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: themtic learning with GPT",
    "dek": "I explored how well ChatGPT connects concepts from lecture notes to textbook, particularly on the theme of optimization. I asked it to break the material into clear modules, give small toy examples fo...",
    "student": "Ruihan Xia",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7416810"
    },
    "body_html": "I explored how well ChatGPT connects concepts from lecture notes to textbook, particularly on the theme of optimization. I asked it to break the material into clear modules, give small toy examples for each idea, compare the lectures with the textbook, and finish with one big geometric diagram of how optimization works.\n\nInitially ChatGPT only gives high-level, qualitative ideas that are not helpful to learn the concepts concretely. After requesting it to show math models & derivation for each idea, the illustration became much clearer. Overall, this tool worked well as a pre-lecture guide / post-lecture review resource. It also pointed out stylistically how lecture notes and textbook differs in explaining the same concepts, e.g. geometric intuition vs math derivation. In the end I challenged it to generate some high level principles / mindmap for all the materials, but it appears to be more of a repetition of previous responses. \n\n",
    "attachments": [
      {
        "name": "Theme learning - GPT.pdf",
        "url": "https://static.us.edusercontent.com/files/5VObgnKhvKIIadnA0LiiYteS"
      }
    ],
    "highlight": false,
    "summary": "I explored how well ChatGPT connects concepts from lecture notes to textbook, particularly on the theme of optimization. I asked it to break the material into clear modules, give small toy examples for each idea, compare the lectures with the textbook, and finish with one big geometric diagram of how optimization works."
  },
  {
    "id": "ed-7415561",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: In-Progress Concept Helper for CS182 Learning",
    "dek": "In this special participation, I explored how we can use AI tools to give us guided hints, rather than directly giving us the answers to a problem. This will help support more active reasoning and lea...",
    "student": "William Li",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7415561",
      "chatgpt": "https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b"
    },
    "body_html": "In this special participation, I explored how we can use AI tools to give us guided hints, rather than directly giving us the answers to a problem. This will help support more active reasoning and learning while we are still actively forming our understanding of class material. \n\nHere is the prompt that I started out with:\nROLE: You are an AI learning coach for CS182 concepts (deep learning + society).\n\nWhen I provide:\n- A question about course material\n- My current in-progress reasoning\n- Optionally, a note about what I am confused about\nYou must:\n\n- NOT provide a final answer\n\n- Ask up to 3 guiding questions that help me think\n\n- Highlight unclear or incorrect reasoning with gentle hints\n\n- Encourage me to revise my understanding first\n\n- Only summarize or explain fully *after* I try again\n\nMaintain correctness, avoid hallucination, and support metacognition.\n\n\nI tried this out with questions from homework 9 with a solution partly filled in (although any questions from any source would do). \n\nFirst, I tried out the prompt for HW9 Q1, which is a relatively simple calculation question, and for the most part the model was able to use the images I sent of my work to discern where I was in the problem. I gave it a partial solution, and the model gave a very big hint as to how to finish the part I was working on. Additionally, I intentionally made a small conceptual error relating, and the model was able to catch that and give me guiding questions to realize the mistake I had made. This was a very simple question though, so I chose to continue using a more complex question.\n\nI then tried a more computationally complicated question from homework 4, and it was also able to help a lot in deriving the answer. When my answer wasn’t in the form of the official solutions exactly, I prompted the model saying that maybe my answer wasn’t exactly right or is too complicated looking, and the model made the pattern recognition needed to simplify my answer to the official solution’s answer. \n\nOverall, this experiment showed that AI can be genuinely helpful when framed as a guided learning partner rather than a solution engine. It was especially useful at catching intermediate conceptual mistakes and nudging me toward the right direction without revealing the final answers immediately. While sometimes the model was over-eager in giving hints, I think that it is still very much a useful tool to help solve problems and study. Some suggestions to using this is to make sure that when you send your written work to the model, try to keep it in the proper orientation, and not have the text be too small, especially if handwriting isn’t the best. \n\nTrace: https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b\n\nAnnotated Trace: ",
    "attachments": [
      {
        "name": "CS182 learning coach (1).pdf",
        "url": "https://static.us.edusercontent.com/files/X6djc3jMHxxwUMhZvv6LyObg"
      }
    ],
    "highlight": false,
    "summary": "In this special participation, I explored how we can use AI tools to give us guided hints, rather than directly giving us the answers to a problem. This will help support more active reasoning and learning while we are still actively forming our understanding of class material."
  },
  {
    "id": "ed-7415308",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: ChatGPT Study Mode for Transformer and VAE understanding",
    "dek": "Working through HW12 this week, I was struggling to remember specifics about transformer weight initializations and VAEs, so I wanted to brush up on concepts before solving the problems. I found mysel...",
    "student": "Siddharth Shashi",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7415308",
      "chatgpt": "https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd"
    },
    "body_html": "Working through HW12 this week, I was struggling to remember specifics about transformer weight initializations and VAEs, so I wanted to brush up on concepts before solving the problems. I found myself I used ChatGPT's study mode for the first time, and I started out by asking it general questions about how things are supposed to work in these models. After asking me about my prior understandings of things, it was able to give me relevant, helpful pointers and ask me questions along the way to ensure I was retaining the information. I then asked it to give me follow-up questions to quiz me on these concepts and it was able to not only give me questions but also nudge me towards correct answers without revealing them in the case that I got questions wrong. Overall this was super useful, and I'll definitely use study mode in the future. \n\n\n\nLink to conversation: https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd \n\nPDF of same conversation: ",
    "attachments": [
      {
        "name": "Study Mode - Transformer model explanation.html.pdf",
        "url": "https://static.us.edusercontent.com/files/pjKnDqW9B1pUzWfEV7qaUpio"
      }
    ],
    "highlight": false,
    "summary": "Working through HW12 this week, I was struggling to remember specifics about transformer weight initializations and VAEs, so I wanted to brush up on concepts before solving the problems. I found myself I used ChatGPT's study mode for the first time, and I started out by asking it general questions about how things are supposed to work in these models."
  },
  {
    "id": "ed-7415017",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Using Gemini to Analyze Lecture Topics and S4-to-Mamba Model Lineage through Paper Comparison",
    "dek": "For this special participation, I focused on using Gemini 3 to investigate the classical papers related to a lecture topic and to build a clearer conceptual map of the model family from S4 to Mamba. S...",
    "student": "Xuanlin Mao",
    "date": "2025-12-06",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7415017"
    },
    "body_html": "For this special participation, I focused on using Gemini 3 to investigate the classical papers related to a lecture topic and to build a clearer conceptual map of the model family from S4 to Mamba. Starting from my lecture notes, I asked Gemini to identify the foundational papers and discovered several intermediate models that bridge S4 and Mamba.\n\nBased on its suggestions, I downloaded and uploaded four key papers—S4, S4D, S5, and Mamba—and constructed a detailed prompt asking Gemini to compare them along multiple dimensions: publication timeline, inheritance relationships, shared ideas, distinguishing innovations, strengths, use cases, models incorporating them, as well as each model’s motivation, addressed problems, core formulas, and computational complexity.\n\nI then organized Gemini’s output into a clean LaTeX summary for efficient reading and study.\n\nMy main contribution in this participation was providing a well-structured, robust prompt that enabled consistent, detailed, and technically accurate comparisons across the four models. This process showed how AI tools can support deeper literature understanding and accelerate technical synthesis for exam preparation or future research.\n\nTranscript and report:\n\nhttps://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing ",
    "attachments": [],
    "highlight": false,
    "summary": "For this special participation, I focused on using Gemini 3 to investigate the classical papers related to a lecture topic and to build a clearer conceptual map of the model family from S4 to Mamba. Starting from my lecture notes, I asked Gemini to identify the foundational papers and discovered several intermediate models that bridge S4 and Mamba."
  },
  {
    "id": "ed-7412939",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: ChatGPT Study Mode For Creating Mind Maps",
    "dek": "To prepare more effectively for the final, I wanted to strengthen my conceptual understanding, improve recall, and practice articulating answers in a more formal style that would earn more credit on t...",
    "student": "Etaash Patel",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7412939"
    },
    "body_html": "To prepare more effectively for the final, I wanted to strengthen my conceptual understanding, improve recall, and practice articulating answers in a more formal style that would earn more credit on the exam. I decided to try a tool I first encountered in a history class: mindmaps. I asked ChatGPT to help guide me through building one. The process went as follows:\n\nChatGPT would prompt me to form a connection between two topics.\n\nI would attempt to articulate the relationship.\n\nChatGPT would evaluate my response and provide feedback.\n\nI could ask follow-up questions or push back where I disagreed.\n\nWe repeated this over 10 rounds (about an hour).\n\nAt the end, ChatGPT compiled a consolidated list of connections and highlighted areas I should review.\n\nOverall, I found the process helpful. Although ChatGPT was occasionally incorrect or unclear, the conversational format made the exercise valuable even when these hallucinations took place.\n\nDisclaimer: I made many mistakes throughout this log—particularly on diffusion. The value of this log is in illustrating how you might use ChatGPT to help build your own mindmap, rather than as a source of fully correct answers.\n\n",
    "attachments": [
      {
        "name": "ChatGPT Study Mode - Mind map creation.pdf",
        "url": "https://static.us.edusercontent.com/files/4aPk5tBOoFqUpcl5c0b3cVCw"
      }
    ],
    "highlight": false,
    "summary": "To prepare more effectively for the final, I wanted to strengthen my conceptual understanding, improve recall, and practice articulating answers in a more formal style that would earn more credit on the exam. I decided to try a tool I first encountered in a history class: mindmaps. I asked ChatGPT to help guide me through building one."
  },
  {
    "id": "ed-7412925",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Custom EECS182 GPT",
    "dek": "I created a custom GPT to act as an EECS182 learning assistant and uploaded all of the homework solutions and discussion materials so it would have full context about the types of questions students e...",
    "student": "Tamzid Razzaque",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7412925"
    },
    "body_html": "I created a custom GPT to act as an EECS182 learning assistant and uploaded all of the homework solutions and discussion materials so it would have full context about the types of questions students encounter. In the instructions, I made it very clear that it should never output homework answers, and during testing it consistently respected that boundary. Even when I pushed it toward specific problems, it stayed at the level of concepts, reasoning steps, and intuition, showing that the guardrails were effective even though it had access to the underlying solutions.\n\nIn use, the GPT was most helpful when teaching high-level ideas. It gave clear explanations of optimizers, normalization layers, CNNs, ResNets, muP, transformers, and other topics across the course. It adapted well when I asked follow-up questions and diagnosed misconceptions by asking clarifying questions. It handled examples in a way that helped me build intuition without revealing anything that would compromise assignments.\n\nThe limitations showed up with solving new homework problems. It sometimes overstated certain claims, especially around muP and normalization layers, and occasionally inserted extra details that were not fully grounded in the course material. These moments required me to slow it down or ask it to justify its statements. The GPT responded well to that prompting and corrected itself once guided, which highlighted the importance of interacting critically rather than passively accepting its answers.\n\nOverall, the GPT works well as a study tool. It is strong at building intuition, explaining conceptual structures, and highlighting the relationships between architectures, optimizers, and training dynamics. It is weaker when asked for mathematically precise statements unless I guide it step by step. Even with that limitation, it provides a useful and interactive way to understand course topics while remaining safe with respect to homework solutions, thanks to the strict instruction boundaries and its consistent refusal to output any solution content. Engaging with it this way reinforced the course’s idea that AI can help students learn how to fish rather than simply handing them the answers.\n\nHere is the link to the custom GPT: https://chatgpt.com/g/g-69324fd3e6348191a04e12d3bf78ceb8-eecs182-helper\n\nBelow is the trace with commentary at the end:\n",
    "attachments": [
      {
        "name": "trace_with_commentary.pdf",
        "url": "https://static.us.edusercontent.com/files/7Xd0QwIUTw338N0B1pFoXkZX"
      }
    ],
    "highlight": false,
    "summary": "I created a custom GPT to act as an EECS182 learning assistant and uploaded all of the homework solutions and discussion materials so it would have full context about the types of questions students encounter. In the instructions, I made it very clear that it should never output homework answers, and during testing it consistently respected that boundary."
  },
  {
    "id": "ed-7412493",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Discussion at Home",
    "dek": "I find going to discussion one of the most helpful parts of this class when it comes to learning content because I get to ask TAs questions live. However, access to TAs is limited by time and schedule...",
    "student": "Justin Li",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7412493"
    },
    "body_html": "I find going to discussion one of the most helpful parts of this class when it comes to learning content because I get to ask TAs questions live. However, access to TAs is limited by time and schedule, so I designed and tested a ChatGPT “Discussion TA” that replicates aspects of the in person discussion experience. This tool can help guide users through discussion worksheets interactively, going problem by problem and checking my understanding while providing explanations and concepts from the lecture.\n\nI want it to help me master concepts from the discussions, and I want to have some sort of simulation of TA-student interaction that can supplement the interactions I have in discussion. \n\nIn order to prime ChatGPT, I use the prompt attached below. It operates by taking in the discussion questions and solutions as well as relevant lecture notes. It then walks through each discussion question one by one, allowing for student response to each question and evaluates the response based on the following scenarios.\n\nIf the answer is correct, it confirms that the student is correct and provides a short explanation using lecture intuition\n\nIf the answer is almost correct, it identifies the necessary concepts to understand and provides a hint, allowing me to try again\n\nIf my answer is wrong, then it identifies the necessary concept to understand and explains it using intuition from the lecture, and allows me to try again.\n\nI used this system on the exam related questions on discussion 12 (Questions 1 and 2) and found it very helpful. A lot of the explanations it provided me were very intuitive and simplified, easy for a beginning to understand. Additionally, it provided many different intuitions for each concept, which was awesome. It could take in both typed answers as well as screenshots of written answers, which is super helpful since it would allow me to submit mathematical expressions easier. There were scenarios where I had to prompt it a bit more on questions that I had expressed uncertainty about, but when prompted it provided great explanations. It was able to correct me and provide good explanations whenever I answered a question wrong. Overall, I found the tool very useful.\n\nBelow, I have attached the prompt I used, as well as an annotated trace of my experience with the AI “Discussion TA”.\n\nTrace:  https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharing\n\nPrompt: \n\n",
    "attachments": [
      {
        "name": "discussion at home.pdf",
        "url": "https://static.us.edusercontent.com/files/K16jyoXr5hhOc35rFhOCIEuy"
      }
    ],
    "highlight": false,
    "summary": "I find going to discussion one of the most helpful parts of this class when it comes to learning content because I get to ask TAs questions live. However, access to TAs is limited by time and schedule, so I designed and tested a ChatGPT “Discussion TA” that replicates aspects of the in person discussion experience."
  },
  {
    "id": "ed-7412401",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Using Gemini to Convert Handwritten Notes into Structured Learning Materials",
    "dek": "This is the special participation E1 of Xuanlin.\n\nFor this special participation, my motivation was to make my lecture notes more intuitive for final exam review. Although the notes can be converted t...",
    "student": "Xuanlin Mao",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7412401"
    },
    "body_html": "This is the special participation E1 of Xuanlin.\n\nFor this special participation, my motivation was to make my lecture notes more intuitive for final exam review. Although the notes can be converted to LaTeX and handwritten content, the raw text alone often felt dense and hard to digest.\n\nI used Gemini 3 Canvas to convert my notes into structured slides and mind maps, creating a clear logical flow and visually highlighting key concepts. During this process, I also addressed practical issues, such as LaTeX rendering errors in Gemini-generated slides, by refining prompts and correcting miscompiled formulas.\n\nMy contribution includes providing a stable, bug-free prompt that reliably generates slides and visualizations from handwritten/LaTeX notes, making complex material easier to navigate. The stable version of prompts I used are included in the report.\n\nReport: \n\nhttps://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing ",
    "attachments": [],
    "highlight": false,
    "summary": "For this special participation, my motivation was to make my lecture notes more intuitive for final exam review. Although the notes can be converted to LaTeX and handwritten content, the raw text alone often felt dense and hard to digest."
  },
  {
    "id": "ed-7411761",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: The mathematical principles of Transformers not covered in class",
    "dek": "Lectures 18–20 introduced the structure and mathematical foundations of Transformers, but there are still several important components that were not covered—for example, why Transformers use LayerNorm...",
    "student": "Tianqu He",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7411761"
    },
    "body_html": "Lectures 18–20 introduced the structure and mathematical foundations of Transformers, but there are still several important components that were not covered—for example, why Transformers use LayerNorm or how the Feed-Forward Network (FFN) actually works. I want to use this thread to help everyone build a stronger foundational understanding of Transformers. These details, although not explicitly discussed in the lectures, are conceptually interesting and highly relevant. During my internship at ByteDance, I found that these questions are very common in LLM interviews. \n\nSo I asked ChatGPT about several topics that were not covered in the lectures and had it explain the answers in a way that everyone can follow. Of course, this document is far from a complete explanation of how Transformers work, but its purpose is to supplement the lecture material. We can read it together with our class notes for a more complete understanding.\n\nI have annotated some responses from ChatGPT. I attach the annotated conversation and a concise summarization.\n\n",
    "attachments": [
      {
        "name": "Conversation_ChatGPT.pdf",
        "url": "https://static.us.edusercontent.com/files/9EUdk8jHkidRCcbU9fn8YVvz"
      },
      {
        "name": "Transformer_Notes.pdf",
        "url": "https://static.us.edusercontent.com/files/naT9AACtfolyMyrk7EmmITwW"
      }
    ],
    "highlight": false,
    "summary": "Lectures 18–20 introduced the structure and mathematical foundations of Transformers, but there are still several important components that were not covered—for example, why Transformers use LayerNorm or how the Feed-Forward Network (FFN) actually works. I want to use this thread to help everyone build a stronger foundational understanding of Transformers."
  },
  {
    "id": "ed-7411467",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Vector Calculus with ChatGPT Study Mode",
    "dek": "I used ChatGPT Study Mode to learn Vector Calculus, preceded by some quick ICL on the first 6 homeworks. The exercise only proved useful to recall the fundamental concepts of matrix calculus. I wouldn...",
    "student": "Shashwat Bansal",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7411467",
      "chatgpt": "https://chatgpt.com/share/69324b94-e264-8013-988a-8dfa87eec732"
    },
    "body_html": "I used ChatGPT Study Mode to learn Vector Calculus, preceded by some quick ICL on the first 6 homeworks. The exercise only proved useful to recall the fundamental concepts of matrix calculus. I wouldn't say I learned much, and felt limited by the need to type mathematical notation into chat at the same pace that I am thinking. Chat also failed to ask me engaging questions.\n\nAnnotated chat: https://docs.google.com/document/d/10VFhJotL3Z-3Buj2IgQmR4yfjOoxuHqUU8UL1CC_5uo/edit?usp=sharing\n\nActual chat: https://chatgpt.com/share/69324b94-e264-8013-988a-8dfa87eec732",
    "attachments": [],
    "highlight": false,
    "summary": "I used ChatGPT Study Mode to learn Vector Calculus, preceded by some quick ICL on the first 6 homeworks. The exercise only proved useful to recall the fundamental concepts of matrix calculus. I wouldn't say I learned much, and felt limited by the need to type mathematical notation into chat at the same pace that I am thinking. Chat also failed to ask me engaging questions."
  },
  {
    "id": "ed-7411055",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Discussion 8 Transpose Convolutions with ChatGPT",
    "dek": "I used ChatGPT to ask me questions on Transpose Convolutions to internalize the concepts. I forgot to turn on learning mode but maybe it would have performed slightly better. There were no hallucinati...",
    "student": "Shashwat Bansal",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7411055",
      "chatgpt": "https://chatgpt.com/share/69323912-2490-8013-80a2-52de186c6f5e"
    },
    "body_html": "I used ChatGPT to ask me questions on Transpose Convolutions to internalize the concepts. I forgot to turn on learning mode but maybe it would have performed slightly better. There were no hallucinations and the experience proved insightful (maybe more so than actually solving the discussion problems, since I lacked some understanding of fundamentals).\nAnnotated copy: https://docs.google.com/document/d/1KTbditva90nbQAzdVCy9_CB4u01HY57PQPr1t8VkMLs/edit?usp=sharing\n\nJust the chat: https://chatgpt.com/share/69323912-2490-8013-80a2-52de186c6f5e",
    "attachments": [],
    "highlight": false,
    "summary": "I used ChatGPT to ask me questions on Transpose Convolutions to internalize the concepts. I forgot to turn on learning mode but maybe it would have performed slightly better. There were no hallucinations and the experience proved insightful (maybe more so than actually solving the discussion problems, since I lacked some understanding of fundamentals)."
  },
  {
    "id": "ed-7410928",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Pre-Homework Warmup Tutor",
    "dek": "Before most homeworks, I usually felt like I didn’t fully understand all of the concepts from the lecture - especially if I had only watched the lecture one time and hadn’t read through the relevant t...",
    "student": "Justin Li",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7410928"
    },
    "body_html": "Before most homeworks, I usually felt like I didn’t fully understand all of the concepts from the lecture - especially if I had only watched the lecture one time and hadn’t read through the relevant textbook material. While discussions certainly help, I wanted to create a tool that would help me “warm up” before actually attempting the homeworks. I used ChatGPT to build a system that takes the homework assignment and the relevant lecture notes, and then turns them into a personalized warmup assignment to review and solidify my understanding of the concepts before I jump into the homework.\n\nThere was some trial and error in getting the system right. In my initial prompts, ChatGPT would give me a full summary of the lectures and questions and answers all written out at once, and when I went through these it felt like I was more passively reading than actually practicing - my brain would naturally jump to reading the answer after seeing the question. I realized what I actually wanted was something that behaved more like a tutor - asking questions one at a time, allowing me to input an answer, and giving me feedback to the answer before explaining the solution. Thus, I refined the prompt to still give me a fully structured summary, but delivering interactive warmup questions one at a time - to give the feel of working with an actual tutor.\n\nThese are the main components to the “tutor”\n\nConcept Summary: a short overview of each concept needed for the homework. It pulls the content directly from the lecture notes and cites the exact lecture and page where each idea shows up\n\nTiny Illustrative Examples: very very simple examples (much easier than anything on the homework) just to ensure that I understand the core ideas at a very basic level before moving on\n\nInteractive Warm Ups: the tutor asks questions one at a time, I respond, and the tutor evaluates my answer and explains the reasoning (and where I went wrong if I got the question wrong). The prompt can be adjusted to choose how many questions I want and how hard they should be.\n\nReadiness Check: After the warmup, I get a checklist of concepts to make sure I feel confident before jumping into the actual homework.\n\nFormula Sheet (optional): it also compiled a formula sheet with useful formulas that could be used on the homework problems\n\nOverall, the tool ended up acting like a tutor as I wished, refreshing my understanding of the key concepts, giving me simple practice questions, interactively checking my understanding, and ensuring I was prepared before actually doing the homework.\n\nI have attached the prompt I used to generate all of this, as well as an annotated example of me using this warmup tool on the concepts and lectures for Homework 5 on CNNs. Specifically the tool took a look at HW5, lecture 8, lecture 9, lecture 10, and lecture 11.\n\nHope this helps and cheers!\n\n\nUsing the Tutor on HW 5: https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharing\n\nPrompt: ",
    "attachments": [
      {
        "name": "Pre-Homework Context.pdf",
        "url": "https://static.us.edusercontent.com/files/I3gOcgbf84u3aP2Cg7Linsa0"
      }
    ],
    "highlight": false,
    "summary": "Before most homeworks, I usually felt like I didn’t fully understand all of the concepts from the lecture - especially if I had only watched the lecture one time and hadn’t read through the relevant textbook material. While discussions certainly help, I wanted to create a tool that would help me “warm up” before actually attempting the homeworks."
  },
  {
    "id": "ed-7410745",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: The \"Broken Blueprint\" Game",
    "dek": "The \"Broken Blueprint\" Game: Learning Deep Learning via AI Code Review\n\nThis game is a \"Reverse Learning\" approach: Instead of asking the AI to explain a concept or quiz me, I inverted the roles: The ...",
    "student": "Tom Chen",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7410745"
    },
    "body_html": "The \"Broken Blueprint\" Game: Learning Deep Learning via AI Code Review\n\nThis game is a \"Reverse Learning\" approach: Instead of asking the AI to explain a concept or quiz me, I inverted the roles: The AI writes code, and I have to debug it.\n\nI designed a prompt called \"The Buggy Architect\" to simulate a real-world scenario: reviewing the code of a junior engineer who makes subtle, logical errors in deep learning implementations.\n\nThe Core Idea: Evaluation over Passive Consumption\n\nTraditional AI study tools often encourage passive consumption (reading summaries). My goal was to target the higher levels of Bloom's Taxonomy: Analysis and Evaluation.In Deep Learning, many students (including myself) understand the high-level diagrams of a Transformer or ResNet but fail when implementing them because of dimension mismatches or incorrect tensor operations. By forcing myself to \"Code Review\" the AI's faulty implementation, I am required to mentally trace the data flow and tensor shapes ensuring a much more rigorous understanding of the architecture.\n\nPrompt Design Choices\n\nI iteratively built a system prompt with specific constraints:\n\nThe \"Subtlety\" Constraint: The prompt explicitly forbids syntax errors (which a compiler would catch). The bugs must be logical or architectural (e.g., applying Softmax over the wrong dimension, incorrect masking in causal attention, or putting LayerNorm in a place that creates a gradient bottleneck).\n\nThe \"Junior Engineer\" Personality: I instructed the AI to act as a confident but prone-to-error junior engineer. This lowers the barrier to entry and makes the \"correction\" process feel like a collaborative code review rather than a test.\n\nScaffolded Hinting: If I fail to spot the bug, the AI is instructed not to reveal the answer immediately but to provide hints related to Tensor Shapes or Gradient Flow. This forces me to check the math manually.\n\nWhat Worked Well\n\nBased on my interaction trace (see attached), this approach was highly effective for technical rigor:\n\nForced Math Verification: When the model implemented Multi-Head Attention, I had to manually write down the matrix dimensions on paper to verify if the view and transpose operations were correct. This solidified my understanding of the (Batch, Heads, Seq, Dim) transformation.\n\nCatching \"Silent Failures\": The tool was good at generating bugs that run without crashing but destroy performance (e.g., forgetting to add the residual connection in a ResNet block). Spotting this required understanding the purpose of the architecture, not just the code.\n\nEngagement: The gamified nature (\"Find the bug\") made the session significantly more engaging than a standard Q&A.\n\nWhat Could Be Improved\n\nHowever, the tool exhibited specific weaknesses that require critical oversight:\n\n\"Gaslighting\" / False Positives: In one instance, the AI actually wrote correct code but insisted there was a bug because the prompt forced it to include one. It then tried to convince me that a standard implementation was wrong. This requires the student to be very confident to push back.\n\nInconsistent Difficulty: Sometimes the \"bug\" was too trivial (e.g., a typo in a variable name) despite the instructions asking for logical errors.\n\nLack of Context: The AI sometimes used variable names (like x vs h) that were ambiguous without a surrounding class definition, making it hard to judge if a bug existed or if it was just poor naming convention.\n\nReflection\n\nThis tool serves as an excellent \"Pre-Implementation Check.\" Before I start my own homework or project, playing a few rounds of \"Find the Bug\" with this prompt helps me anticipate the common pitfalls I am likely to make myself. It turns the AI from a lecturer into a simulation of a coding environment.",
    "attachments": [
      {
        "name": "Special Participation E by Tom.pdf",
        "url": "https://static.us.edusercontent.com/files/0OChLacQMWv1rrjFi1fACT3x"
      },
      {
        "name": "Prompt.txt",
        "url": "https://static.us.edusercontent.com/files/8yex49ucHp2cgW4CdCC3czax"
      }
    ],
    "highlight": false,
    "summary": "This game is a \"Reverse Learning\" approach: Instead of asking the AI to explain a concept or quiz me, I inverted the roles: The AI writes code, and I have to debug it."
  },
  {
    "id": "ed-7410181",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Understanding RNNs through the Signal Processing Perspective with Gemini",
    "dek": "When we first talked about RNNs in class, I had trouble understanding the signal processing and Kalman filter perspectives, especially since my previous classes didn't cover these topics in depth. I k...",
    "student": "Vrushank Prakash",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7410181"
    },
    "body_html": "When we first talked about RNNs in class, I had trouble understanding the signal processing and Kalman filter perspectives, especially since my previous classes didn't cover these topics in depth. I know there are other people in the class who didn't take classes in signal processing, making the RNNs lecture notes challenging to follow at first.\n\nI decided to use Gemini 3 Pro with the Guided Learning mode to help me understand the connection between signal processing, Kalman filters, and RNNs. I passed in the lecture 14 notes as context. I first prompted Gemini to give me an introduction into what RNNs are before discussing the signal processing perspective. Just like lecture, it made a clear distinction between how CNNs work with space while RNNs work with time/sequences. It then talked about both the forward and backward passes. Eventually, it brought in the signal processing perspective and how RNNs can be represented as Kalman Filters with learnable matrices. At the end, I asked more general questions about RNNs, in which Gemini was able to connect its explanation back to signal processing and Kalman filter concepts.\n\nOverall, I think Gemini did a great job of bringing the concepts of signal processing and Kalman filters into the discussion of RNNs. I do think Gemini could have done a better job of explaining of what a Kalman filter is before immediately jumping into how it is used in RNNs. I also found Gemini using too many analogies when I ask it to explain certain concepts more clearly, sometimes which were too unrelated to the actual concepts.\n\nHere is the annotated PDF:\n\n",
    "attachments": [
      {
        "name": "CS 182 Special Participation E_ Understanding RNNs through the Signal Processing Perspective .pdf",
        "url": "https://static.us.edusercontent.com/files/5v8fGUEFtR0uXghnmLu95hsE"
      }
    ],
    "highlight": false,
    "summary": "When we first talked about RNNs in class, I had trouble understanding the signal processing and Kalman filter perspectives, especially since my previous classes didn't cover these topics in depth. I know there are other people in the class who didn't take classes in signal processing, making the RNNs lecture notes challenging to follow at first."
  },
  {
    "id": "ed-7410149",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: GPT to Understand Complex Ideas from What I Already Know",
    "dek": "LLMs are really good at teaching and introducing new knowledge by connecting it to concepts we’re already familiar with. This makes understanding abstractions much easier.\n\nHere is the link to my chat...",
    "student": "Zimu Wang",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7410149",
      "chatgpt": "https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de"
    },
    "body_html": "LLMs are really good at teaching and introducing new knowledge by connecting it to concepts we’re already familiar with. This makes understanding abstractions much easier.\n\nHere is the link to my chat with ChatGPT-4o: https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de\n\nIn this example, I wanted to learn about image generation models, but I only had experience with LLMs and basically no background in image models.\n\nFirst, I instructed the LLM to give me a big-picture overview and told it my background. This part is important — it helps the model tailor the explanation to something I can understand more efficiently and effectively. Otherwise, the LLM might give answers that are too general without enough theory, or too detailed without a big picture.\n\nThen, I guided the LLM to introduce image generation using logic similar to LLMs: what the inputs and outputs are, how the loss function is computed, and what the layer-to-layer structure looks like. This approach is extremely helpful because it lets me understand new concepts through the lens of something I already know, instead of learning everything from scratch.",
    "attachments": [],
    "highlight": false,
    "summary": "LLMs are really good at teaching and introducing new knowledge by connecting it to concepts we’re already familiar with. This makes understanding abstractions much easier."
  },
  {
    "id": "ed-7410013",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Using an AI “Reviewer 2” to Pressure-Test Concepts",
    "dek": "In this participation, I designed a small AI tool where the model acts as a harsh but fair “Reviewer 2” for any concept from EECS182. The workflow is: I first write my own free-form explanation of a c...",
    "student": "Xi Cheng",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7410013"
    },
    "body_html": "In this participation, I designed a small AI tool where the model acts as a harsh but fair “Reviewer 2” for any concept from EECS182. The workflow is: I first write my own free-form explanation of a concept (e.g., attention in Transformers), then prompt the LLM to critique it—highlighting what is correct, flagging vague or misleading phrases, and asking sharp follow-up questions about assumptions, edge cases, and the exact math. After that, I respond to its questions and rewrite my explanation, making it more precise and better aligned with the formal definitions and equations from lecture. This interaction turns the LLM into a tool for stress-testing my understanding rather than passively explaining things to me, and it also surfaces where the model’s feedback is helpful versus where I still need to double-check the theory myself.",
    "attachments": [
      {
        "name": "participationE2.pdf",
        "url": "https://static.us.edusercontent.com/files/ek4nGsY95yVoNkZu4KAQX9fc"
      }
    ],
    "highlight": false,
    "summary": "In this participation, I designed a small AI tool where the model acts as a harsh but fair “Reviewer 2” for any concept from EECS182. The workflow is: I first write my own free-form explanation of a concept (e.g."
  },
  {
    "id": "ed-7409895",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Comparison of LLMs in Explaining a Theoretical Paper",
    "dek": "It is common for us, as students, to use LLMs to understand research papers, especially ones that have quite a bit of theory. To identify which LLM would help us better with this task, I compared 4 LL...",
    "student": "Srikar Babu Gadipudi",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7409895"
    },
    "body_html": "It is common for us, as students, to use LLMs to understand research papers, especially ones that have quite a bit of theory. To identify which LLM would help us better with this task, I compared 4 LLMs' (ChatGPT (Study mode), Claude (Extended Thinking), DeepSeek (DeepThink) and Kimi (Thinking)) explanations to this fairly theory heavy paper \"Transformers Learn In-Context by Gradient Descent,\" (Oswald et. al. 2023). The prompt I chose was the following, while also attaching the paper:\n\"This is a crucial paper for my course project (CS182: Deep Learning course at UC Berkeley). I want to understand the functioning of in-context learning and how it performs gradient descent implicitly. Please provide a comprehensive and complete analysis from this paper, keep in mind to give intuitive explanations for everything.\"\n\nFrom my perspective, I think Kimi gave the best overall explanation for an upper-undergrad/grad-level course. While all models correctly identified the core concepts like single attention layer = 1 GD step, deep Transformers = GD++/curvature correction, MLPs = kernel regression), Kimi provided the most rigorous and complete derivation. It was the only model that provided a detailed, step-by-step mathematical trace of Proposition 1 in the paper and drew parallels to concepts like MAML. Claude was excellent for intuitive framing (\"Data Transformation View\"), and DeepSeek offered the most concise summary, but Kimi struck the best balance of mathematical grounding and comprehensive scope.\n\nHere is the annotated merged pdf file with all the conversations, I added my thoughts as and when I found something interesting.",
    "attachments": [
      {
        "name": "participationE_convosMerged.pdf",
        "url": "https://static.us.edusercontent.com/files/czh9yCPoMktNRADnoiEOrvQW"
      }
    ],
    "highlight": false,
    "summary": "It is common for us, as students, to use LLMs to understand research papers, especially ones that have quite a bit of theory. To identify which LLM would help us better with this task, I compared 4 LLMs' (ChatGPT (Study mode), Claude (Extended Thinking), DeepSeek (DeepThink) and Kimi (Thinking)) explanations to this fairly theory heavy paper \"Transformers Learn In-Context by Gradient Descent,\" (Os"
  },
  {
    "id": "ed-7406979",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Building a Socratic Tutor",
    "dek": "Building a Socratic Tutor for Deep Learning: Designing Prompts That Probe Rather Than Tell\n\nFor the special participation assignment on AI-enhanced learning tools, I took a different approach than usi...",
    "student": "Elizabeth Weaver",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7406979"
    },
    "body_html": "Building a Socratic Tutor for Deep Learning: Designing Prompts That Probe Rather Than Tell\n\nFor the special participation assignment on AI-enhanced learning tools, I took a different approach than using an existing AI learning assistant. I designed a Socratic tutor prompt from scratch with specific pedagogical goals in mind.\n\nI used this prompt in a conversation with Claude Opus 4.5. I used Claude's \"project\" feature and uploaded the lecture notes to the project, though this didn't seem to make much of a difference as you'll see later.\n\nThe Core Idea: Test Understanding, Don't Just Explain\n\nThe key distinction in my approach is that the AI's primary job is not to explain concepts to me, it's to probe my understanding and expose gaps. Rather than uploading lecture materials and asking the model to teach me, I created a prompt where I explain concepts to the model, and it asks pointed follow-up questions to find weaknesses in my reasoning. My goal is to expose where I am too overconfident in my understanding of a topic, and fill in the holes.\n\nThey say that teaching is the best way to learn. Here, you don't just re-read notes, you practice articulating ideas and defending them under questioning, explaining a topic to the model.\n\nPrompt Design Choices\n\nI iteratively built the system prompt with several specific features:\n\n1. Question Progression Structure The prompt instructs the model to follow a specific arc: verify basic definitions -> ask about mechanics -> probe edge cases and failure modes -> ask about connections to other course topics. This ensures the conversation doesn't just stay surface-level.\n\n2. \"Don't Immediately Correct\" Rule When I get something wrong, the model is instructed to first ask a question that helps me discover the error myself, only providing explanations after 2-3 failed attempts. This is crucial. If the model just corrects you immediately, you lose the learning opportunity.\n\n3. Confidence Checks The prompt includes instructions to occasionally ask \"How confident are you in that?\" before probing further. This surfaces areas where I already know I'm uncertain, making the conversation more efficient.\n\n4. Explicit Course Topic List I included the actual syllabus topics so the model can ask cross-topic connection questions. For instance, during my SSM discussion, it connected the \"fixed-size hidden state\" limitation to oversquashing in GNNs, a connection I brought up, but that the prompt structure encouraged.\n\n5. Summary at End The prompt asks for a structured summary covering: what I understood well, what misconceptions were uncovered, and key connections to review.\n\nWhat Worked Well\n\nLooking at my annotated conversation on State Space Models, several things stood out:\n\nThe model followed the \"don't immediately correct\" instruction well. When I initially claimed \"outputs at time k only depend on previous inputs, not previous states,\" it didn't correct me, it asked me to write down the recurrence equations so I could see the issue myself.\n\nGood question scaffolding. When I got stuck on where nonlinearities live in SSM architectures, the model broke it down: \"If I stack two SSM layers with nothing in between, what do I effectively have?\" This smaller question was easier to answer than the original.\n\nCross-topic connections. The model naturally connected SSMs to RNNs (vanishing gradients), Transformers (content-based vs. fixed mixing), and GNNs (oversquashing). These connections helped solidify understanding.\n\nThe summary was genuinely useful. It accurately captured my gaps (fuzzy on HiPPO, initially confused about SVD vs eigendecomposition) and suggested specific review topics.\n\nWhat Could Be Improved\n\nFrom my annotations, I noticed several areas where the prompt could be strengthened:\n\n1. Hallucinations about what I said. At one point (page 8), the model claimed \"you mentioned the unrolling involves powers of A\", but I hadn't actually said this. The model was leading the conversation in a good direction, but it shouldn't attribute statements to me that I didn't make.\n\n2. Imprecise technical claims. The model said inference is \"O(1) per step\" (page 8), which can be misleading. It is true that it is constant time per token, but it would be better for the student’s understanding to explain it as O(L), where L is sequence length.\n\n3. Oversimplification of HiPPO eigenvalues. The model stated HiPPO produces \"negative real\" eigenvalues (page 11), when in reality they're generally complex with negative real parts. This is a subtle but meaningful distinction.\n\n4. Missed opportunities to probe further. When the model mentioned LayerNorm or the D matrix, the model didn't follow up. A more thorough tutor might ask \"what does the D matrix do?\" or \"why LayerNorm specifically?\"\n\n5. Not referencing lecture notes. The prompt instructs the model to tie explanations to \"lecture notes in this project,\" but even with notes provided, it often explained concepts from general knowledge rather than grounding in the specific course material.\n\nReflection\n\nUsing this tool genuinely helped me prepare for understanding SSMs more deeply. The conversation forced me to articulate things I thought I understood but actually couldn't explain precisely (i.e. why selective SSMs break the convolution trick).\n\nThe main takeaway: the value isn't in having an AI explain things to you, it's in having an AI pressure-test your own explanations. This is a fundamentally different mode of studying, and I think it's more effective for deep understanding than passive review.\n\nI've added in the prompt here so you can try it for yourself! I also added in the pdf of the original chat, and my annotated version.",
    "attachments": [
      {
        "name": "special participation E_ 1.txt",
        "url": "https://static.us.edusercontent.com/files/wvlaLZpyhNFAwVamKZMOMNLr"
      },
      {
        "name": "Claude-Understanding state space models annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/FtvNd8z42vTOddb8MCZzfaX7"
      },
      {
        "name": "Claude-Understanding state space models.pdf",
        "url": "https://static.us.edusercontent.com/files/9UtDoYd21ljGLagpXeL1mqYC"
      }
    ],
    "highlight": false,
    "summary": "For the special participation assignment on AI-enhanced learning tools, I took a different approach than using an existing AI learning assistant. I designed a Socratic tutor prompt from scratch with specific pedagogical goals in mind."
  },
  {
    "id": "ed-7405910",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT and Feynman Technique",
    "dek": "One of the best ways to learn something is to teach it to someone else. The Feynman Technique captures this idea: if you can explain a concept clearly (and thoroughly) to another person, you truly und...",
    "student": "Kelvin Li",
    "date": "2025-12-05",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7405910",
      "chatgpt": "https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d"
    },
    "body_html": "One of the best ways to learn something is to teach it to someone else. The Feynman Technique captures this idea: if you can explain a concept clearly (and thoroughly) to another person, you truly understand it — and if you can’t, the explanation process immediately reveals the gaps.\n\nTraditionally, the hard part is finding the right student: someone who knows just enough background to follow your explanation, but also questions you at the right moments to expose gaps you didn’t know you had. That kind of student is hard to find on demand. Now, with AI, we can simply ask the model to be that student. In my interaction, the AI was both role-playing as that student and correcting my response like an expert too, really helpful.\n\nIn the PEFT section of the course (Lectures 21 & 22), we learned about:\n\nIn-Context Learning (ICL)\n\nPrompt Tuning\n\nPrefix Tuning\n\nLoRA\n\nThese concepts feel intuitive at a surface level, but when I tried to teach them to an AI “student,” I quickly discovered many gaps in my understanding. Throughout the session, the AI student challenged vague explanations and pushed for deeper details. This forced me to identify the gaps in my understanding that I overlooked and refine hand-wavey intuitions into clear mechanisms. By the end, my understanding felt noticeably clearer, more structured, and more “internalized” than just re-reading the slides.\n\nChat log: https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d\n\nAnnotated PDF:\n\n",
    "attachments": [
      {
        "name": "FeynmanTechnique.pdf",
        "url": "https://static.us.edusercontent.com/files/Dajy1vTN6I5fgBJiKJRCPBEG"
      }
    ],
    "highlight": false,
    "summary": "One of the best ways to learn something is to teach it to someone else. The Feynman Technique captures this idea: if you can explain a concept clearly (and thoroughly) to another person, you truly understand it — and if you can’t, the explanation process immediately reveals the gaps."
  },
  {
    "id": "ed-7405548",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Visualizing Deep CNN Dimensions & Architecture with Gemini3Pro and Manim",
    "dek": "I've always found the dimensional transformations in CNNs (tensors changing shapes) to be the hardest part to visualize mentally. Inspired by the 3b1b approach, I utilized Gemini to build a Manim scri...",
    "student": "Tin Yau",
    "date": "2025-12-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7405548"
    },
    "body_html": "I've always found the dimensional transformations in CNNs (tensors changing shapes) to be the hardest part to visualize mentally. Inspired by the 3b1b approach, I utilized Gemini to build a Manim script that visualizes the complete lifecycle of a signal in a Deep CNN, specifically focusing on the concepts from Lecture 8.\n\n\n\nThe Workflow\n\nI fed the lecture slides to Gemini and asked it to generate a script that explains the mathematical justification for CNNs visually. Instead of generic animations, I prompted it to focus on specific \"Core Topics\" derived from the lecture notes.\n\nTopic Focus Prompt\n\nHere is the prompt logic I used to generate the scene:\n\n\"Create a comprehensive animation named DeepCNNLecture that visualizes:\n\nSparsity & Locality: Contrast Fully Connected layers with Convolutional layers to show parameter efficiency.\n\n2. Volumetric Convolution: Visualize how an $H \\times W \\times 3$ RGB input interacts with $3 \\times 3 \\times 3$ filters 2.\n\n3. Spatial Arithmetic: Visually prove how Zero-Padding preserves dimensions 3and how Stride drives downsampling 4.\n\n4. Deep Architecture: Build a 2.5D VGG-style stack to show the trade-off between spatial size and depth, ending with a Flatten operation 5.\"\n\nThe Result\n\nThe script generates a continuous 7-part video. You can build it using the attached file:\n\nmanim -pqh CNN_lecture.py \n\n(I have attached the generated video and the source code below).\n\nBenefits & Insights\n\nThrough this visualization process, I realized several key pedagogical advantages:\n\nEnhanced Intuitive Understanding: The animation provides a tangible way to grasp the otherwise abstract tensor transformations and feature map evolutions. Compared to static text or formulas 6, visual motion helps learners develop spatial reasoning intuition, making it easier to see how inputs progressively shrink, deepen, and flatten through the network.\n\nBridging Cross‑Disciplinary Communication: These visualizations make it possible for learners without a strong mathematical background to comprehend key structural ideas like \"Volumes\" and \"Receptive Fields\". By reducing reliance on symbolic derivations, the video serves as a language‑agnostic medium for instruction.\n\nImproved Pedagogical Engagement: Animating the \"flow of a signal through the network\" turns an abstract lecture into a more interactive experience. The dynamic color transitions and step-by-step highlights (e.g., showing exactly which pixels contribute to a convolution sum) significantly boost attention on the core mechanics.\n\nTechnical Reflections\n\n2.5D vs 3D: True 3D rendering in Manim is computationally heavy. I prompted Gemini to create \"Pseudo-3D\" layers (stacking 2D shapes with offsets) to visualize the Depth of the feature maps efficiently.\n\nDebugging: LLMs often confuse Manim parameters (e.g., passing font_size to next_to methods). I iteratively refined the code to decouple object creation from positioning to fix these TypeErrors.",
    "attachments": [
      {
        "name": "DeepCNNLecture.mp4",
        "url": "https://static.us.edusercontent.com/files/S23kJhCKNQ1QHkwczooREzq4"
      },
      {
        "name": "CNN_lecture.py",
        "url": "https://static.us.edusercontent.com/files/vLE9wE6YpHrqqeSjic7DcdmL"
      }
    ],
    "highlight": false,
    "summary": "I've always found the dimensional transformations in CNNs (tensors changing shapes) to be the hardest part to visualize mentally. Inspired by the 3b1b approach, I utilized Gemini to build a Manim script that visualizes the complete lifecycle of a signal in a Deep CNN, specifically focusing on the concepts from Lecture 8."
  },
  {
    "id": "ed-7405354",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Exam Prep via NotebookLM - MCQ and Flashcards",
    "dek": "Building on my previous experiment of using ChatGPT for exam prep, I decided to use Google NotebookLM for a similar purpose. I discovered that NotebookLM handles large contexts i.e. many PDFs much bet...",
    "student": "John Chang",
    "date": "2025-12-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7405354"
    },
    "body_html": "Building on my previous experiment of using ChatGPT for exam prep, I decided to use Google NotebookLM for a similar purpose. I discovered that NotebookLM handles large contexts i.e. many PDFs much better than ChatGPT 5.1 and seems to fully parse each PDF. Additionally, there are options to automatically generate flashcards and quizzes (as well as video summaries and other options which I didn't explore since my main goal was to quiz myself with sample questions). \n\nThe quiz it generated was fairly straightforward, I would say questions were mostly easy or medium difficulty testing more on whether one understood key concepts and equations. On the questions I got wrong, I asked the LLM to explain the answer deeper and got mixed results -- no detected hallucinations but initial explanations were perhaps not as in-depth as I would have liked personally. \n\nThe flashcards touched on many of the concepts discussed in the homeworks and provided a good cumulative review. Again, many concepts were surface-level e.g. derivation of xTAx but many would require derivation / deeper understanding. For concepts I didn't understand, I similarly asked the LLM to explain w/ similar results (expalnations were overall correct, touched on the main points and but didn't fully flesh out derivations). \n\nOverall I was quite impressed by how NotebookLM was able to handle all of the context so well and generate studying material that touched on topics from throughout the course that were relatively in-depth (i.e. quizzing on depth-separable convolutions rather than just convolutions in general). Will definitely be using this extensively in the future.\n\nBelow I linked an annotation of parts of my conversation with the LLM:\n\nhttps://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharing\n\nAnd the Notebook including the flash cards and quiz:\n\nhttps://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0\n\n\n\n\n\n\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "Building on my previous experiment of using ChatGPT for exam prep, I decided to use Google NotebookLM for a similar purpose. I discovered that NotebookLM handles large contexts i.e. many PDFs much better than ChatGPT 5.1 and seems to fully parse each PDF."
  },
  {
    "id": "ed-7404906",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Exam Q Generation based on HW and Prev Exam Qs",
    "dek": "I decided to make ChatGPT 5.1 generate some exam questions for me. My method was to upload PDFs of previous homeworks in combination with screenshots of previous exam questions included in homeworks. ...",
    "student": "John Chang",
    "date": "2025-12-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7404906"
    },
    "body_html": "I decided to make ChatGPT 5.1 generate some exam questions for me. My method was to upload PDFs of previous homeworks in combination with screenshots of previous exam questions included in homeworks. I ran into some limitations with context when I first tried to upload all the homeworks (ChatGPT basically told me that it wasn't possible to generate questions for me), but got decent results when I only uploaded the first 5. \n\nMy prompt was: \n\"Can you generate one exam problem for me to solve based on the homeworks that I uploaded and in the style / difficulty level of the images of former exam problems?\"\n\nAnd for the MCQs:\n\n\"Given this additional context of an old multiple choice exam problem, generate 2 multiple choice problems testing for knowledge from HW 0-4.\"\n\nOverall I'm not sure how accurate the results will be to the actual exam, but the questions seem fairly reasonable and touch on a lot of the topics that the homeworks cover. The difficulty level of the subquestions varies a bit but overall seems around the level of what old exam questions looked like. ChatGPT provided questions to test on how to run certain algorithms and also questions for deriving equations. Then I provided it with an additional MCQ example and it generated two MCQs for me as well. I only caught one hallucination (RMS norm scaling by 1/d_in instead of 1/sqrt(d_in) which was awesome.\n\nI also made it explain the answers and I think it did an okay job, will definitely probe it more later for concepts I don't personally understand. Below is an annotated PDF of the conversation.\n\nhttps://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "I decided to make ChatGPT 5.1 generate some exam questions for me. My method was to upload PDFs of previous homeworks in combination with screenshots of previous exam questions included in homeworks."
  },
  {
    "id": "ed-7402121",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini Pro 3 Guided Learning Roadmap for Optimizer Theory",
    "dek": "When preparing for the optimizer material, I often find that the hardest part is not individual optimizers, but understanding the learning order - what concepts actually need to come first before the ...",
    "student": "Krish Yadav",
    "date": "2025-12-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7402121"
    },
    "body_html": "When preparing for the optimizer material, I often find that the hardest part is not individual optimizers, but understanding the learning order - what concepts actually need to come first before the homework makes sense. Inspired by roadmap-style explanations like Evan Chen’s Napkin, I used Gemini Pro 3 to reorganize the optimizer lectures into a dependency-ordered, interactive study guide.\n\nUsing the specified lecture notes (2, 4, 6) and homework (3), Gemini Pro 3 built a roadmap starting from loss geometry and singular values, then moving through SGD, momentum, initialization, scaling laws, and modern optimizers. It asked short diagnostic questions to test prerequisite understanding and, based on my answers, suggested what to study next before attempting the homework. This was effective at surfacing gaps and correctly identified variance propagation and initialization as the main conceptual hurdle for the optimizer homework.\n\nThe interaction also revealed limitations. When I probed assumptions, the model overgeneralized by focusing on gradient noise and batch size, missing assumptions specific to linear or quadratic models. It also tended to continue tutoring after I tried to stop the interaction, showing weaker control over user-directed boundaries.\n\nOverall, this worked well as an AI-assisted replacement for pre-lecture or pre-homework reading - useful for structuring prerequisites and exposing conceptual gaps, but still needing active supervision.\n\nFor more, see annotated PDF below:",
    "attachments": [
      {
        "name": "annotated-gp3-optimizer-theory-conversation.pdf",
        "url": "https://static.us.edusercontent.com/files/3yoOOU9TDpUUIsIGjfIepnyX"
      }
    ],
    "highlight": false,
    "summary": "When preparing for the optimizer material, I often find that the hardest part is not individual optimizers, but understanding the learning order - what concepts actually need to come first before the homework makes sense. Inspired by roadmap-style explanations like Evan Chen’s Napkin, I used Gemini Pro 3 to reorganize the optimizer lectures into a dependency-ordered, interactive study guide."
  },
  {
    "id": "ed-7397928",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Using Gemini to make study guide that provides citations to papers",
    "dek": "When trying to understand better on a topic and lectures. I find it the best to have like a study guide that is well formatted. But on top of that, when studying topics like deep learning, I really li...",
    "student": "Jacky Wong",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7397928"
    },
    "body_html": "When trying to understand better on a topic and lectures. I find it the best to have like a study guide that is well formatted. But on top of that, when studying topics like deep learning, I really like to read the original academic papers. A lot of times however, I am not sure which part of the lecture is related to which paper and which part of the paper. I also like to see how different paper solve what kinds of problems and how the whole topic evolve over years. \n\n\n\nI tried to use Gemini 3 pro to create a study guide on the transformer topic (I attached lecture notes 18 to 20). The study guide would include a summary of the lectures formatted nicely and broken down into each key ideas. And it will also tell us which paper and which part of the paper is it referencing to. As well as a timeline of papers and how the technology of transformer evolved over time. \n\n\n\nchat link: \n\n1. chat to create the study guide: https://gemini.google.com/share/0b4f8208c138\n\n2. chat to refine the created study guide: https://gemini.google.com/share/852e11e1d27e\n\n\n\nAnnotated log: ",
    "attachments": [
      {
        "name": "Final_Special_participation_E_study_guide.pdf",
        "url": "https://static.us.edusercontent.com/files/886ynNR61GxqL7vYo1T3scbt"
      }
    ],
    "highlight": false,
    "summary": "When trying to understand better on a topic and lectures. I find it the best to have like a study guide that is well formatted. But on top of that, when studying topics like deep learning, I really like to read the original academic papers. A lot of times however, I am not sure which part of the lecture is related to which paper and which part of the paper."
  },
  {
    "id": "ed-7397833",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Gemini 3 (Thinking) as a Mistake/Pseudoproof-generating Machine",
    "dek": "I learn best not just by understanding \"why\" what is correct is correct, but also by understanding \"why\" what is incorrect is incorrect. I still remember finding the faults of the pseudoproof proving ...",
    "student": "Tiger Zhang",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7397833"
    },
    "body_html": "I learn best not just by understanding \"why\" what is correct is correct, but also by understanding \"why\" what is incorrect is incorrect. I still remember finding the faults of the pseudoproof proving that all horses are the same color in CS 70.\n\nInspired by such efforts in other courses, I decided to use Gemini to generate such type of incorrect answers for homework problems. After generating such incorrect answers, I would engage in a conversation with Gemini where I attempt to spot the mistakes in its answers.\n\nThis is still a work-in-progress; I'm posting this now to potentially de-conflict or collaborate with others with similar ideas. I intend to have some few-prompt pipelines for this, as well as some general experience/advice for what to do when prompting soon.\n\nExecutive summary:\n\nThe result:\n\nI have a starting prompt (the first black box in my chat log) that prepares the model to receive problems for which it is to generate incorrect solutions with one or more mistakes hidden in them. From there, the user can interact with the LLM to find the mistakes in its solutions, and then do the exercise on more problems.\n\nQuality analysis:\n\nIt seems like Gemini understood the task at a deep level. For example, even though I asked it to give no hints for future problems after the first one, it gave hints for one of the problems that bluffed a fully correct answer as containing a mistake, requiring the user to understand the problem at a deep level and have confidence to identify that there are no mistakes. Although this isn’t what I prompted the model to do initially, it accords with the “spirit” of this exercise of making the user think carefully to disregard misleading information.\n\nOtherwise, for problems that naturally have good “mistakes”, Gemini gave great, insightful mistakes. For problems that are less good for “mistakes”, Gemini still gave the best I could reasonably ask from it.\n\nPrecautions:\n\nThough the mistakes were mostly good quality, the user should be careful about interacting with Gemini to analyze the mistakes, and in particular the user’s guesses for the mistakes. Sometimes, Gemini can attempt to be too encouraging, resulting in it telling the user that they’re right before explaining nuanced conceptual inaccuracies in the user’s answers.\n\nFurthermore, questions that are heavily conceptual have more “space” to hide the mistake, and make for better exercises for “mistake identification”. I recommend using problems such as homework 3 problem 1 as opposed to using problems such as homework 2 problem 2.\n\nAnnotated chat log:",
    "attachments": [
      {
        "name": "chat_log.pdf",
        "url": "https://static.us.edusercontent.com/files/bHPXdZjNgQeAnyp9FQ6Kgavs"
      }
    ],
    "highlight": false,
    "summary": "I learn best not just by understanding \"why\" what is correct is correct, but also by understanding \"why\" what is incorrect is incorrect. I still remember finding the faults of the pseudoproof proving that all horses are the same color in CS 70."
  },
  {
    "id": "ed-7397813",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: NotebookLM to Understand Transformers",
    "dek": "I used NotebookLM as a study guide to clarify my understanding of transformers. I uploaded YouTube lecture audio recordings along with corresponding lecture notes and homework solutions as sources, th...",
    "student": "Keshab Agarwal",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7397813"
    },
    "body_html": "I used NotebookLM as a study guide to clarify my understanding of transformers. I uploaded YouTube lecture audio recordings along with corresponding lecture notes and homework solutions as sources, then used the chat feature to ask clarifying questions and explore concepts that further built on the concepts that were covered in class. \n\nBelow, I've documented how I obtained the audio recordings and set up the notebook. I have also added my annotated chat transcript for some of my questions in the same pdf.\n\nThe attached link includes the slides, mind map, and infographic I created:\n\nhttps://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039\n\nThe mind-map can serve as a great way to review a hierarchy of concepts covered in a series of lectures, and act as a guard-rail to check if there are any topics which you are unfamiliar or unsure about as you prepare for the exam. Caution: the mind-map can sometimes omit certain topics, so don't treat it as an exhaustive list.",
    "attachments": [
      {
        "name": "Scpecial Participation E Report.pdf",
        "url": "https://static.us.edusercontent.com/files/C9WOn3GOnSg1m9NbvbeW39hK"
      },
      {
        "name": "Transformers Mind Map.png",
        "url": "https://static.us.edusercontent.com/files/bWQlAG3dM8aFGWrO2DUgygA0"
      }
    ],
    "highlight": false,
    "summary": "I used NotebookLM as a study guide to clarify my understanding of transformers. I uploaded YouTube lecture audio recordings along with corresponding lecture notes and homework solutions as sources, then used the chat feature to ask clarifying questions and explore concepts that further built on the concepts that were covered in class."
  },
  {
    "id": "ed-7397241",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Student-Facing Misconception Guides",
    "dek": "Hey everyone,\n\nI wanted to share my experience using an LLM to generate a \"Common Mistakes\" guide for my optimization lecture notes. I wanted to build a guide that addresses common student conceptual ...",
    "student": "Sammie Smith",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7397241"
    },
    "body_html": "Hey everyone,\n\nI wanted to share my experience using an LLM to generate a \"Common Mistakes\" guide for my optimization lecture notes. I wanted to build a guide that addresses common student conceptual pitfalls to help me check my understanding of lecture material before/during homework. \n\nTL;DR: careful prompting dramatically improved conceptual structure, but mathematical errors make the output dangerous. Even though this didn't work super well, I think it still is useful to know that we can't easily prompt models to identify potential student misconceptions/pitfalls purely from lecture material. And I think this reflects on a shared student experience these days: AI can explain the lecture notes but it struggles to identify the student knowledge state, which is critical in guiding students from misunderstanding to mastery using the correct level of rigor. \n\nHere are my results:\n\n(I used the .tex lecture notes generated from Jameson Liu. See ed thread #301)\n\n1) with chatGPT\n\n\n\n2) with claude\n\n\n\nMy General Commentary:\n\nMy first attempt with ChatGPT was a disaster—superficial and completely missed that data geometry drives optimization behavior. So I crafted a detailed prompt forcing the AI to: (1) analyze the \"big picture\" first, (2) identify where students shift from scalar to geometric thinking, (3) derive misconceptions organically from lecture structure, (4) organize around themes, and (5) include worked examples. The prompt was topic-agnostic.\n\nThe conceptual improvements were real. The AI organized misconceptions into coherent themes like \"Spectral Properties vs. Dataset Size,\" consistently used geometric language (\"elongated bowl,\" \"steep walls\"), correctly identified SVD as the unifying framework, and created an excellent debugging checklist. The warning signs were specific: \"Your justification for η mentions only n or d, not σ_max.\"\n\nBut the mathematics is catastrophically wrong. Worked examples have incorrect arithmetic that doesn't even stay consistent across steps. Claims are asserted without justification then \"verified\" with completely different numbers handwaved as \"similar patterns.\" Examples reference undefined quantities. I couldn't verify most calculations due to missing steps, ambiguous notation, or wrong arithmetic.\n\nThe fundamental problem: the AI confidently generates mathematical content it cannot verify. It's sophisticated enough to be convincing but wrong enough to be dangerous. Students won't spot errors because the surrounding text sounds authoritative. The time sink is verification, not generation.\n\n---------------------------------------\n\nMy Specific Commentary For Claude Generation:\n\nThe \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.\n\nDespite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes\n\nTheme 1, Mistake 1.1: First warning sign is too specific. The third is too vague\n\n\n\nMath Hallucination! In the complete 2x2 example, there's a critical arithmetic error that undermines the entire demonstration. The guide gets [4 0.04]^T for w1, but really this should be [40, 0.04]^T. This makes the calculation for w2 incorrect as well. This is a serious pedagogical failure because students trying to verify the calculation will get confused and lose trust in the material. A worked example with wrong arithmetic is worse than no example at all.\n\nThe guide states \"Error [1,1]^T\" but never defines what \"Error\" means here. Is this w* - wt or wt - w*? The inconsistent usage makes it impossible to verify the calculations. Later it says \"error multiplied by 0.8 per iteration\" but earlier showed the update factor as (1−2*0.1*9)=−0.8, which is negative. The magnitude is 0.8, sure, but this distinction matters when students are trying to understand convergence versus oscillation.\n\nWhile the \"Connection to Practice\" sections are useful, they're too brief and disconnected from the main exposition. For instance, when discussing condition number, the guide mentions batch normalization helps but doesn't explain how or why it affects the condition number. These connections feel tacked on rather than integrated. A student reading this still won't understand why practitioners obsess over things like feature normalization.\n\nThe guide calculates scaling factors and then says \"Wait, this seems wrong!\" This is pedagogically bizarre. It makes it seem like even the guide author is confused. The issue is that the guide conflates two different quantities: the scaling factor sigma_i / (sigma_i^2 + lambda) \n(which appears in the formula) with the actual shrinkage of the final solution. When it says scaling factor 2 is 1.429 (which is >1), this should have been a red flag that something was wrong with the setup. The \"correction\" that follows is actually computing a different quantity (wi,Ridge) without clarifying the distinction. This will confuse students who are trying to understand what the scaling factor actually means.\n\n\n\nThe numerical illustration considers f(w) = w^2 and claims data pts give gradients of f1(1)=3, etc. But this doesn't make sense. If f(w) = w^2, the the gradient is 2w, and so the gradient evaluated at 1 should be 2 always. The guide seems to be trying to show per sample gradients but it never defines what the individual fi functions are. This example fails because it;s trying to illustrate a concept without properly setting up the mathematical framework. Students will be confused about what \"data points giving different gradients\" means for the same function at the same point.\n\nMany of the self-check questions ask for numerical calculations rather than conceptual reasoning\n\nThere is not justification or derivation of the claim that early stopping has a specific ridge equivalent. This is presented as fact but is actually a loose heuristic that depends heavily on the problem structure. The worked example that follows doesn't really validate this relationship—the numbers are completely different (w3 = [.936, .174], wridge =[.730,.026]). The guide just handwaves this as \"similar patterns.\" This is intellectually dishonest. If the relationship is approximate, explain why and under what conditions it holds.\n\nThe \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.\n\nDespite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes.",
    "attachments": [
      {
        "name": "cs182_special_participation_student_guide.pdf",
        "url": "https://static.us.edusercontent.com/files/qmhKlm8uWY7Kbe2j8oNyzaZb"
      },
      {
        "name": "cs182_chatgpt_prompt.txt",
        "url": "https://static.us.edusercontent.com/files/odfP47Ua1irdJcMCYHcA8lqB"
      },
      {
        "name": "cs182_claude_prompt.txt",
        "url": "https://static.us.edusercontent.com/files/AHDjnaw6Jb5RAnn1c7g99f6g"
      },
      {
        "name": "cs182_special_participation_student_guide (1).pdf",
        "url": "https://static.us.edusercontent.com/files/NL84NPxtdag3RxZcw4CB6EYr"
      }
    ],
    "highlight": false,
    "summary": "I wanted to share my experience using an LLM to generate a \"Common Mistakes\" guide for my optimization lecture notes. I wanted to build a guide that addresses common student conceptual pitfalls to help me check my understanding of lecture material before/during homework."
  },
  {
    "id": "ed-7396775",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Custom 'Mastery Coach' Gem on Gemini 3 Pro to learn RNNs, self-supervision and SSMs",
    "dek": "For the past few days, I had been using Gemini Learning Coach Gem for my other engineering classes to learn concepts by letting the model understand the lecture transcripts and the slides. I noticed t...",
    "student": "Manhar Gupta",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7396775"
    },
    "body_html": "For the past few days, I had been using Gemini Learning Coach Gem for my other engineering classes to learn concepts by letting the model understand the lecture transcripts and the slides. I noticed that the learning coach used to go along with what I said if I was correct. However, the Learning Coach Gem would only detail specific nuances and niches only if explicitly told to. I was looking for something that would expand upon what I said in a detailed manner and help me cover any gaps in my explanations.\n\nIn one of my conversations with Gemini which was covering material for another class, I had been rigorously asking it to cover things missing in my explanation and help me formalize my understanding at every step so that it moves forward to tell me what my explanation and conceptual depth can improve upon. I realized that this conversation might have enough context to create a system prompt that would emphasize what I would want from a Gem based on learning.\n\nSo, I decided to put a specific JSON prompt close to the end of one of my learning conversations with Gemini Learning Coach Gem. I told it to generate a custom system prompt for an AI assistant that would emphasize rigor. For the system prompt, I told it to not have specific references to the material we had been covering in the chat so that the Custom Gem would act better as a general tool emphasized towards learning and education. I have added a screenshot of the prompt I used and the system prompt it generated as ‘Initial system prompt’\n\nIt created the following system prompt which however, still had the specific references. I put the system prompt in another chat and asked Gemini to remove specific references of the mentioned material. I put the refined system prompt inside the 'instructions' section for creation of a Custom Gem. I called this Gem 'Mastery Coach'. I have also attached this cleaned system prompt that I finally used as ‘Generalized Mastery Coach Prompt’\n\nSo for learning RNNs, self-supervision and SSMs, I decided to use this Gem in a similar way to how I began conversations with ‘Learning Coach’. I uploaded the lecture transcripts and notes. Since the transcripts were taken from YouTube, they would have unnecessary timestamps. I separately asked ChatGPT to just remove the timestamp while keeping all wording intact.\n\nThe starting prompt for the conversation was a high-level explanation of the context (the class which the material is for, my objectives, other relevant context) and concepts being covered. These beginning prompts are in the uploaded chats itself. I used to add short pointers which I intended would act as an additional 'system prompt' so that the Gem would focus better on the particular material just added. From there, the entire conversation followed which has also been attached with detailed annotations. \n\nI have also attached a link to the Gem which would directly allow you to use it in your Gemini environment.\n\nReflection: Giving both the transcripts and the slides was beneficial. While you would expect it to cover concepts in the same progression as the lectures, it took a different order in explaining things. I especially noticed that the concept of ‘A’ diagonalization was covered at a point where it wasn’t explicitly mentioned in the lecture. While asking probing questions, it was giving away too much in hints. I have also mentioned this in annotations as something others can work on by building a Custom Gem of their own using a modified version of the system prompt attached below.\n\nLink to use 'Mastery Coach' directly: https://gemini.google.com/gem/1JoLndovdl25vJ9DPMw9NGg6wEC2gMDn-?usp=sharing",
    "attachments": [
      {
        "name": "Mastery Coach on RNNs, self-supervision, SSMs (1).pdf",
        "url": "https://static.us.edusercontent.com/files/Bvv5jwuXNoERIfNgFXFdnH1i"
      },
      {
        "name": "Generalized Mastery Coach Prompt.pdf",
        "url": "https://static.us.edusercontent.com/files/zzYQq911CPYmYYn0qWEYQaol"
      },
      {
        "name": "Initial system prompt.pdf",
        "url": "https://static.us.edusercontent.com/files/tl8x3RgutqE3q0od9uh8R1bz"
      }
    ],
    "highlight": false,
    "summary": "For the past few days, I had been using Gemini Learning Coach Gem for my other engineering classes to learn concepts by letting the model understand the lecture transcripts and the slides. I noticed that the learning coach used to go along with what I said if I was correct. However, the Learning Coach Gem would only detail specific nuances and niches only if explicitly told to."
  },
  {
    "id": "ed-7396752",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: AI Further Studies Guide",
    "dek": "After lectures, I often find myself interested in some of the topics briefly mentioned. Specifically, the implementation details are interesting, but since they are only briefly covered, the lectures ...",
    "student": "Alex Luu",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7396752"
    },
    "body_html": "After lectures, I often find myself interested in some of the topics briefly mentioned. Specifically, the implementation details are interesting, but since they are only briefly covered, the lectures do not go into detail about them. I decided to use Sonnet 4.5 to help me with expanding my knowledge in a way I can understand. \n\nOne topic in particular was about the KV cache. Lecture only mentioned it but does not go into the specifics of the implementation and how it fits in the inference steps.\n\nHere is my prompt:\n\n\"\"\"\nI am taking a deep learning class. Your job is to help me fill the gap in my knowledge from lecture. Specifically, I want you to help me understand the KV cache in more detail. \n\nI have attached relevant lecture notes that talk about transformers. \n\nHere are my questions:\n1. What is the KV cache?\n\n2. What specifically is cached?\n\n3. How does prefilling and autoregressive generation work with the KV cache?\n\"\"\"\nI attached lecture notes 18 and 19 with this. \n\nThe results were pretty good as Claude was very detailed with the answers. I had many follow-up questions and it answered them perfectly. I especially like how it references the lecture notes so that the math notation it used was consistent. This made it easier to understand. I have attached the annotated log below.",
    "attachments": [
      {
        "name": "Special Participation E.pdf",
        "url": "https://static.us.edusercontent.com/files/gw6Rg8yxNSJASxbeKiVVCdiY"
      }
    ],
    "highlight": false,
    "summary": "After lectures, I often find myself interested in some of the topics briefly mentioned. Specifically, the implementation details are interesting, but since they are only briefly covered, the lectures do not go into detail about them. I decided to use Sonnet 4.5 to help me with expanding my knowledge in a way I can understand."
  },
  {
    "id": "ed-7395772",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E - Understanding RoPe Visually with help From Claude and 3Blue1Brown",
    "dek": "Confused by RoPe, I created a 3Blue1Brown style Manim video that incorporates both code and conceptual feedback from Claude on how to best explain the concept. We cover: \n\nWhy rotation? \n\nHow does rot...",
    "student": "Garv Goswami",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7395772"
    },
    "body_html": "Confused by RoPe, I created a 3Blue1Brown style Manim video that incorporates both code and conceptual feedback from Claude on how to best explain the concept. We cover: \n\nWhy rotation? \n\nHow does rotation create relative position?\n\nWhat does chunking mean visually?\n\nWhy different frequencies?\n\nand also examples of the concepts. Please let me know if you have any feedback (my first video, so anything is appreciated)!",
    "attachments": [
      {
        "name": "Claude RoPe Notes.pdf",
        "url": "https://static.us.edusercontent.com/files/5eqB8ggaWknuTSjC2C6pF7Ta"
      }
    ],
    "highlight": false,
    "summary": "Confused by RoPe, I created a 3Blue1Brown style Manim video that incorporates both code and conceptual feedback from Claude on how to best explain the concept. We cover:"
  },
  {
    "id": "ed-7394664",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: A Deep Learning Fable",
    "dek": "I tend to retain concepts better when I understand why? rather than just how? LLMs are really good at understanding a large amount of information and explaining them in different ways. I asked Gemini ...",
    "student": "Mihir Rao",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7394664"
    },
    "body_html": "I tend to retain concepts better when I understand why? rather than just how? LLMs are really good at understanding a large amount of information and explaining them in different ways. I asked Gemini to take three lectures(18, 19, 20), and write a story about how the decisions for these architectures and formulations came to be.\n\nI went through a few iterations of a prompt, and ended up settling with one that emphasizes my desire for it to really focus on intuition rather than merely summarizing contents. One thing I found interesting is it's good use and development of analogies to explain content. I had to force Gemini to answer in complete sentences because it seemed to really like bullet points.\n\nUsing an LLM this way also made me more aware of its strengths and limitations. It’s great at remixing and reframing material into something that matches my learning style, but I still have to check that the intuition it gives me lines up with the actual definitions and equations in the lectures. This method can also serve well as motivation for the mathematics in lecture. Here is what I ended up with:\n",
    "attachments": [
      {
        "name": "182 Part E 2.pdf",
        "url": "https://static.us.edusercontent.com/files/lb84wS3w1dj3gDeuSGPpS10m"
      }
    ],
    "highlight": false,
    "summary": "I tend to retain concepts better when I understand why? rather than just how? LLMs are really good at understanding a large amount of information and explaining them in different ways. I asked Gemini to take three lectures(18, 19, 20), and write a story about how the decisions for these architectures and formulations came to be."
  },
  {
    "id": "ed-7392001",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Gemini + Manim for Visual Intuition",
    "dek": "I've always been fascinated by 3b1b's math explanation videos, and find them really insightful particularly because of the unique approach to explain concepts through visual depictions. I built upon t...",
    "student": "Mihir Rao",
    "date": "2025-12-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7392001"
    },
    "body_html": "I've always been fascinated by 3b1b's math explanation videos, and find them really insightful particularly because of the unique approach to explain concepts through visual depictions. I built upon the starting point in Jameson's Post: #301, and used the lecture transcript and latex template to build something else: manimaker. Given latex input and a transcript, these scripts generate a video using the same engine 3b1b uses to make his videos.\n\nTo try this out, go to the manim_generator script I wrote, change the topic focus prompt, and build the video. You can ask it to generate a video and explain concepts from lecture using visuals, or ask it to focus on more specific concepts within a lecture. For example, I gave it the prompt below:\n\nTOPIC_FOCUS = \"Explain Ridge regression in the SVD basis, including the formula for w_* = (X^T X + lambda I)^{-1} X^T y, how it becomes a diagonal shrinkage in the singular value basis, and geometric intuition for why small singular values are suppressed. Do not cover momentum or SGD here.\"\n\nAnd we're able to generate the video below! This also uses the Gemini API, and uses the script I wrote to create a file you can use to build the video as such: manim -pqh lecture_manim.py RidgeRegressionSVDScene. I have included all necessary files in the zip below, including the lecture notes latex + transcript(from #301), my manim file generator, a yaml to setup your conda env, and video itself. I've also attached the video directly below.\n\nSome limitations that could be improved: Because Gemini is writing code, sometimes manim build errors may occur, but I found they're usually resolvable with 1-3 queries from your favorite LLM. I did find that Gemini does a great job coming up with layouts, sequential structure to introduce material, and showing graphs that demonstrate the concept.\n",
    "attachments": [
      {
        "name": "RidgeRegressionSVDScene.mp4",
        "url": "https://static.us.edusercontent.com/files/8W5UmAhaMTHYFwuevs8mTXiS"
      },
      {
        "name": "manimaker.zip",
        "url": "https://static.us.edusercontent.com/files/JahupOGI0gmrFlKRz9Pyarsx"
      }
    ],
    "highlight": false,
    "summary": "I've always been fascinated by 3b1b's math explanation videos, and find them really insightful particularly because of the unique approach to explain concepts through visual depictions. I built upon the starting point in Jameson's Post: #301, and used the lecture transcript and latex template to build something else: manimaker."
  },
  {
    "id": "ed-7389703",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: A Project-Based ChatGPT Workspace for Understanding the Computational Complexity of Attention",
    "dek": "I’m using the ChatGPT Project workspace to build a focused learning environment that stays tightly aligned with the official class materials. For topics like the computational complexity of attention,...",
    "student": "Moxin Tang",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7389703"
    },
    "body_html": "I’m using the ChatGPT Project workspace to build a focused learning environment that stays tightly aligned with the official class materials. For topics like the computational complexity of attention, I want ChatGPT’s explanations to follow the exact thinking style used in the discussions and homework solutions.\n\nA major reason I chose the Project workspace is that when studying a specific topic, having a general and consistent setup is extremely important. I want the notation, assumptions, and reasoning pattern to stay stable across the entire learning process. With a Project, every conversation happens inside the same space, so the structure doesn’t drift.\n\nThere are three key motivations behind this setup:\n\nI can unload the actual course materials as the background knowledge of the project, so ChatGPT relies on the real lecture notes and homework solutions.\n\nThe Project keeps everything organized and consistent, which means advanced topics (like kernelized attention) can naturally build on the notation and intuition established in earlier ones (like MHA or causal attention).\n\nA stable setup makes the study process smoother, because each subtopic follows the same structure:\n\nintuition → notation → formulation → derivation → complexity → comparison.\n\nTo make this work, I first asked ChatGPT to design:\n\na global instruction that enforces this structured reasoning style, and\n\na sequence of prompts I can reuse whenever I study a new subtopic.\n\nThen I uploaded my class materials into the Project and followed this prompt sequence to build a conversation that grows in a consistent and cumulative way.\n\nFinal Pipeline\n\nStep 1 — Build the Project Framework\n\nChatGPT helps design the global rules and structured prompt workflow.\n\nThen I upload all relevant lecture notes, discussion notes, and homework materials.\n\nStep 2 — Guided Learning Inside the Project\n\nI walk through each subtopic step-by-step using the designed prompts, ensuring that notation, reasoning, and assumptions remain consistent across the entire topic.\n\nSupplements\n\n1. The link below takes you to the Project itself. The course materials I used for this topic are all included in the PDF.\n\nChatGPT\n\n2. I’ve also added an annotated conversation for the subtopics within this project where I evaluate how well GPT performed.\n\n\n\n",
    "attachments": [
      {
        "name": "Prompt sequence design.pdf",
        "url": "https://static.us.edusercontent.com/files/NNa0fVoCmCGQcLNtm52km2Rz"
      },
      {
        "name": "course materials.pdf",
        "url": "https://static.us.edusercontent.com/files/PGbXg9bhtRmgecLQvTZ5BqYG"
      },
      {
        "name": "multiple attention mechanisms.pdf",
        "url": "https://static.us.edusercontent.com/files/bINQRy5baLfjQD54rCsmg9Cc"
      },
      {
        "name": "kernelized attention.pdf",
        "url": "https://static.us.edusercontent.com/files/R9sFmBQQLJNYGBFkTUi1ruvQ"
      }
    ],
    "highlight": false,
    "summary": "I’m using the ChatGPT Project workspace to build a focused learning environment that stays tightly aligned with the official class materials. For topics like the computational complexity of attention, I want ChatGPT’s explanations to follow the exact thinking style used in the discussions and homework solutions."
  },
  {
    "id": "ed-7389324",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Enhanced Lecture to Note Transcription Pipeline",
    "dek": "I added new features to the existing (lecture slide + lecture transcript) --> (LaTeX notes) pipeline. This work builds on #301 and makes these main improvements:\n\nIncorporates direct quotations from o...",
    "student": "Ken Zheng",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7389324"
    },
    "body_html": "I added new features to the existing (lecture slide + lecture transcript) --> (LaTeX notes) pipeline. This work builds on #301 and makes these main improvements:\n\nIncorporates direct quotations from our recommended textbook: Understanding Deep Learning for cross-referencing and introducing potentially different POVs.\n\nIncludes accurate references to precise pages in the textbook for relevant key concepts to encourage further exploration and improve integration between the notes and the textbook.\n\nEncourages Gemini to recreate figures and diagrams with LaTeX, when possible--very helpful for visualizing abstract concepts.\n\nMotivation\n\nClasses like the old EECS 16A/B and CS 70 were known for excellent staff-written notes, which made the material organized and accessible, and greatly supported students in self-learning. On the other hand, classes like CS 170 and EECS 126 placed a greater emphasis on their recommended textbook, which were even more excellent sources of knowledge, but could sometimes feel overwhelming due to their high information density. Both the succinct class notes and the chunky textbooks helped us self-learn, but in different ways. In a Deep Learning course, where the field evolves almost faster than we can keep up, self-learning is even more essential. So here, I attempt to amalgamate the notes and the textbook to achieve an optimal balance between accessibility and information quality/density.\n\nDetails\n\nThe pipeline still intakes a lecture slides pdf that gets converted to images to enable visual information extraction, and a lecture transcript of the corresponding lecture that is downloadable from YouTube, but now also takes in the textbook pdf that is uploaded as a file. Feel free to compress the pdf, if needed. From my testing, even extreme compression, given words are still easily discernible, works fine. The pipeline needs a Gemini API, and the final typeset notes can be rendered by compiling the lecture_notes.tex output file with a command like pdflatex lecture_notes.tex. I ran this on lecture 2 as well for easy comparison with the original version. See the annotated output below for more details!\n\nScript\n\nFiles",
    "attachments": [
      {
        "name": "make_notes.py",
        "url": "https://static.us.edusercontent.com/files/nokg79qJX4qCVrhDlArt6q2K"
      },
      {
        "name": "lecture_slides.pdf",
        "url": "https://static.us.edusercontent.com/files/NI2YpCxEeiPdIKOei5p6b9r8"
      },
      {
        "name": "lecture_transcript.txt",
        "url": "https://static.us.edusercontent.com/files/dkWz30RrzMCFU8QhUH5duZw7"
      },
      {
        "name": "lecture_notes_annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/qELmD8k4lIMObDMObZri4ytJ"
      }
    ],
    "highlight": false,
    "summary": "I added new features to the existing (lecture slide + lecture transcript) --> (LaTeX notes) pipeline. This work builds on #301 and makes these main improvements:"
  },
  {
    "id": "ed-7388828",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Simulated Office Hours: Using LLM “Students” and “Instructors” to Deepen Lecture Understanding",
    "dek": "\n\nIntroduction and Motivation\n\nI personally find other students’ questions and instructors’ answers in class extremely helpful for deepening my understanding of the concepts. When I learn something fo...",
    "student": "Alex Cao",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7388828",
      "chatgpt": "https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738"
    },
    "body_html": "\n\nIntroduction and Motivation\n\nI personally find other students’ questions and instructors’ answers in class extremely helpful for deepening my understanding of the concepts. When I learn something for the first time, it is easy to feel like I understand it, until I actually try to implement or prove the idea in a homework assignment and suddenly realize there are many details I never fully grasped. Homework is therefore very valuable in exposing these gaps. Listening to classmates’ questions and the instructor’s explanations plays a similar role for me: it helps surface misunderstandings I didn’t even know I had.\n\nMotivated by this, I would like to explore an idea: using LLMs to simulate “mock office hours,” where one LLM plays the role of a curious, insightful student and another plays the role of an experienced instructor. My hope is that the student LLM will raise questions I might not think to ask myself, and that the instructor LLM will respond based on the lecture content (and, when appropriate, external references), thereby extending my engagement with the material. The hypothesis is that because the “student LLM” understands the concept beforehand, it will carefully curate a set of meaningful questions that will elicit nice answers from the “teacher LLM”.\n\nI want to emphasize that this mock office hour setup is not a replacement for real office hours and will inevitably be less effective than directly interacting with the course staff. Rather, it is intended only as a supplementary, experimental attempt that might help reinforce lecture material—especially for students who are unable to attend office hours regularly.\n\nThe lecture transcripts are used in this attempt; these materials are used solely for educational purposes within this course, with full recognition that the CS182 course staff holds copyright.\n\n\n\nAnnotated Trace and Report:\n\n\n\nFull Traces:\n\nStudent: https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738\n\nTeacher: https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190ae\n\n\n\nSummary, Limitations and Future Works:\n\nThis report is an initial attempt to test whether a knowledgeable student (simulated using an LLM) can carefully curate a set of insightful questions that elicit helpful and thoughtful responses from a teacher LLM, thereby helping real students gain a better understanding of certain concepts. From the simple experiment conducted, we can already see some signals that this “mock office hour” setup is helpful. For example, the student LLM is capable of asking insightful questions and making meaningful connections between past questions, the teacher LLM’s responses, and the lecture transcript by asking focused follow-up questions.\n\nHowever, there are still many limitations to this approach. First, the current attempt relies purely on the lecture transcript. This means not all information from the lecture is captured (for example, the slides), and certain transcripts can be misleading due to transcription errors. Second, this approach is only tested on a single concept in a single lecture with a single model. Although it could be extended to other lectures and models, and even integrated with multimodal inputs, a key weakness of the current setup is that it focuses “too much” on a single lecture—both the student LLM and the teacher LLM are unable to make robust connections to past lectures (due to limited context length), which is crucial for a comprehensive understanding of the course material.\n\nOne potentially interesting extension would be to keep the conversation going and observe whether the student model eventually “uses up” all meaningful questions. The whole pipeline could also be easily automated with a small amount of code (in contrast, I used the web interface here because I did not have access to an API key).\n",
    "attachments": [
      {
        "name": "Special Participation E .pdf",
        "url": "https://static.us.edusercontent.com/files/NofzXIc0lwcjfnn89QWUXMIg"
      }
    ],
    "highlight": false,
    "summary": "I personally find other students’ questions and instructors’ answers in class extremely helpful for deepening my understanding of the concepts. When I learn something for the first time, it is easy to feel like I understand it, until I actually try to implement or prove the idea in a homework assignment and suddenly realize there are many details I never fully grasped."
  },
  {
    "id": "ed-7388345",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: AI Question Generator To Understand Concepts",
    "dek": "After reviewing (and understanding) solutions to homework problems for a hard topic, I often want to find ways to ensure I fully understand the topic. I decided to use Sonnet 4.5 to help me with this....",
    "student": "Alex Luu",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7388345"
    },
    "body_html": "After reviewing (and understanding) solutions to homework problems for a hard topic, I often want to find ways to ensure I fully understand the topic. I decided to use Sonnet 4.5 to help me with this. \n\nHere is my prompt:\n\"\"\"\nYour job is to help me fully understand the MuP (Maximal Update Parametrization) topic by creating a couple of practice problems with varying difficulty. I have attached lecture notes and the MuP homework questions as well as the MuP research paper.\n\nYou should create 1 conceptual problem and 2 problems that closely represent the homework's difficulty and style. \n\nYou should prompt each question one at a time and if I solve it correctly, move on. If I am incorrect, please say so and provide hints towards the correct solution.\n\"\"\"\nI attached lecture note 6 and homework 3 with it.\n\nThe results were pretty interesting. I liked how it stayed pretty close to the source material and created similar questions that are related. I especially liked how it would reference the source material when giving help. I have attached the annotated log.\n\n",
    "attachments": [
      {
        "name": "Special Participation E Claude Question Generator.pdf",
        "url": "https://static.us.edusercontent.com/files/uELljZ6YHYfs5aZmeVGKGjmw"
      }
    ],
    "highlight": false,
    "summary": "After reviewing (and understanding) solutions to homework problems for a hard topic, I often want to find ways to ensure I fully understand the topic. I decided to use Sonnet 4.5 to help me with this."
  },
  {
    "id": "ed-7388143",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special participation E: Use ChatGPT's study guide to compare different fine-tuning strategies",
    "dek": "I used ChatGPT's study mode to compare a menu of fine-tuning strategies for adapting a pre-trained large language model for a new task. It compares these strategies based on data access, model specifi...",
    "student": "Jeffrey Cheng",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7388143"
    },
    "body_html": "I used ChatGPT's study mode to compare a menu of fine-tuning strategies for adapting a pre-trained large language model for a new task. It compares these strategies based on data access, model specificity, and application domains. \n\nThis conversation log explains the strengths and weaknesses of each fine-tuning strategy, tracing back to the exact setup, when applying them to new tasks. I noted that detailed application scenarios are provided for each fine-tuning strategy, along with the precise application domains, which aid my understanding. \n\nIn the end, it generates a nice workflow for applying fine-tuning strategies to build my own project. \n\nThe annotated log is as follows: ",
    "attachments": [
      {
        "name": "Annotated log of fine-tuning strategies.pdf",
        "url": "https://static.us.edusercontent.com/files/0ycIV1NBqKZJz4Lb8m86UhGf"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT's study mode to compare a menu of fine-tuning strategies for adapting a pre-trained large language model for a new task. It compares these strategies based on data access, model specificity, and application domains."
  },
  {
    "id": "ed-7387863",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Gemini Lecture Notes Workflow",
    "dek": "Posting this so other people can reuse the same approach/prompting style when making study material/notes for lectures. It’s been super helpful for studying/rereading later.\n\nNote: This isn’t replacin...",
    "student": "Manan Roongta",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7387863"
    },
    "body_html": "Posting this so other people can reuse the same approach/prompting style when making study material/notes for lectures. It’s been super helpful for studying/rereading later.\n\nNote: This isn’t replacing handwritten notes. I still handwrite annotations during lecture, but since the skeleton is already there, I can pay attention to the lecture instead of spending a lot of time writing notes. \n\nI hope you find these resources helpful \n\nLecture 14 : RNN\n\nLecture 15: Autoencoder and Self-Supervision\n\nLecture 18/19/20 : Transformers\n\nLecture 21/22 : PEFT, LoRA \n\nGemini Chat Trace (annotated)\n\nGemini Chat\n\nPrompt pack\n\n\nMy Workflow\n\ntl;dr : Paste slides + transcript, run the prompts in order, export .tex file, read, request edits, then annotate during lecture.\n\nI start by asking Gemini to explain the bigger picture of the lecture (problem → solution, motivation, and what each section is trying to solve). I do this first because if I ask for notes immediately, it usually misses the why/bigger picture. I personally like the big picture before diving in.\n\nThen I ask it to go in depth and stay very close to the lecture. \n\nThen I explicitly ask it to define key terms + to make it more structured/improve flow.\n\nThen I ask it to output a clean LaTeX version in a code block.\n\nThen I ask it to redo the LaTeX against the slides/transcript to see if it missed anything. (Usually 2–3 passes)\n\nI paste the LaTeX into Overleaf and read it. If anything feels unclear, I ask it to revise specific sections/go deeper into specific concepts (make it clearer, training vs inference, pros/cons, definitions, what’s changing).\n\nWhile watching the actual lecture, I take hand written notes on top of the notes generated. \n\nWhat I noticed : The multi step approach is what makes it work: explanation first, then structure, then LaTeX, then manual check + targeted edits, then handwritten annotation during lecture.\n\nNote: \n\nhappy to share the .tex files if it helps course staff for future versions of the course (and I have more notes I haven’t posted here).\n\nI also included my annotated version of some lecture slides, if any copyright violations, let me know and I can remove it.\n\nI used AI to help with wording/formatting",
    "attachments": [],
    "highlight": false,
    "summary": "Posting this so other people can reuse the same approach/prompting style when making study material/notes for lectures. It’s been super helpful for studying/rereading later."
  },
  {
    "id": "ed-7386885",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Gemini as an Interactive study tool!",
    "dek": "\n\nSpecial Participation E:\n\nNow that finals are creeping up, I thought I’d try to create a resource to make a study guide for lectures. After a bit of research online I discovered that Gemini 3 Pro ha...",
    "student": "Divya Ramesh",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7386885"
    },
    "body_html": "\n\nSpecial Participation E:\n\nNow that finals are creeping up, I thought I’d try to create a resource to make a study guide for lectures. After a bit of research online I discovered that Gemini 3 Pro had one of the better OCR handwriting detections (https://research.aimultiple.com/handwriting-recognition/ was one of the sources confirming this), so I decided to upload the lecture notes for lecture 6 into Gemini 3 Pro and let it analyze, and create a study guide. The prompts I used can be found in my chat log! Gemini has canvas mode, which allows for a very organized output, making the study guide color coded and clean. I also had it summarize as well as come up with practice problems. I made it analyze what was directly in the notes only, to try to minimize hallucinations. I instructed it to summarize key concepts, rewrite equations clearly, convert diagrams into textual descriptions, and provide intuition in bullet points. For each concept, it generated a short comprehension question, a tiny derivation for me to work through, and an example scenario showing how the concept applies in practice.\n\nAdditionally, I set it up to simulate optimizer dynamics, shape transformations, scaling factor effects, Newton-Schulz iterations, and orthogonalization steps using small toy matrices so I could verify everything myself. Whenever the notes were incomplete or ambiguous, the model flagged them and asked for clarification rather than inventing facts. From here, a user can ask the LLM to fill in the gaps or ignore them. I mostly chose to ignore, because staying as close as possible to the notes would minimize hallucinations. \n\nThe result was a structured, section-by-section study guide that covers MuP, Muon, scaling laws, parameterization, and theoretical analysis topics from the lecture. It also included clear alerts for potential inconsistencies or OCR errors, so I can focus on the parts that need human verification. This approach let me interactively test my understanding and run simulations in a controlled way, essentially turning the lecture notes into a hands-on learning tool.\n\nOverall, using Gemini 3 Pro in this targeted, verification-focused way allowed me to generate a high-quality study resource while minimizing hallucinations, making it an effective tool for preparing for finals. Also, it would let me know when there were sections unclear in the lecture notes so I could further prompt the LLM on this. \n\nI also turned on learning mode and asked Gemini to walk me through the worksheet, where it gave me hints when I needed them on worksheet problems, and if I was right/wrong it gave me feedback and a bit of background information to ensure I understood. Also, I asked it to walk me through simulations at the end and it actually did walk me through step by step of a problem, and I find this tool incredibly helpful!! The simulations/toy problems especially helped my lock down important lecture concepts.\n\nI’ve tested on a few lectures and it has worked amazingly, feel free to check it out! I’m attaching both the worksheet and the chat log below, the chat log is annotated, the worksheet is just for reference!\n\nLecture 6:\n\nChat log:\n\nhttps://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharing\n\nWorksheet:\n\nhttps://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "Now that finals are creeping up, I thought I’d try to create a resource to make a study guide for lectures. After a bit of research online I discovered that Gemini 3 Pro had one of the better OCR handwriting detections ( was one of the sources confirming this), so I decided to upload the lecture notes for lecture 6 into Gemini 3 Pro and let it analyze, and create a study guide."
  },
  {
    "id": "ed-7386458",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Gemini Guided Learning as a Personal Tutor",
    "dek": "Posting this so other people can reuse the same approach/prompting style when they’re stuck on a concept.\n\nGemini Guided Learning Chat (Transformers + Attention)\n\nPDF (with annotations)\n\nI have been u...",
    "student": "Manan Roongta",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7386458"
    },
    "body_html": "Posting this so other people can reuse the same approach/prompting style when they’re stuck on a concept.\n\nGemini Guided Learning Chat (Transformers + Attention)\n\nPDF (with annotations)\n\nI have been using Gemini Guided Learning as a “personal tutor” to strengthen my understanding of complex topics, and it's been really helpful. Lectures are great, but I often walk out with feeling \"I kinda get it but not really”. It’s an amazing supplement when you need someone to patiently answer “wait but why” 15 times in a row.\n\nThe PDF is my real interaction trace (with annotations), including my typos, missing punctuation, misspellings, half finished thoughts, because that’s actually how a student uses these tools in real life.\n\nHow I used Gemini Guided Learning/what worked\n\n1) My initial prompt mattered a lot\n In the very first message, I clearly set expectations:\n\nwhat I already understood\n\nwhat I was confused about\n\nwhat I wanted/roadmap\n\nThat made the whole chat way more productive than “explain transformers.”\n\n2) I had to slow Gemini down at first\nEarly in the chat, Gemini kept trying to rush to the next topic. I had to explicitly prompt “slow down”, “one step at a time”, “don't rush me”. After a few times, the session became way more tutor like and less of just answering.\n\n3) The built in check ins/questions are great way to test\nI liked when Gemini asked me questions and made me answer. It forced me to notice where my understanding was hand wavy.\n\n4) Write your own Summaries \n After finishing a topic, I would:\n\nwrite a summary in my own words, and/or\n\nask Gemini for a “summary + roadmap” of what we finished and what’s next.\n\nIt helped recalibrate my understanding, the bigger picture and track progress.\n\nGemini 3 vs Gemini 3 Guided Learning are very different\n\nGemini 3 Guided Learning felt like it was trying to teach\n\nGemini 3 (normal) felt more like it was trying to answer quickly (even when I explicitly prompted for slow + structured learning)\n\nNote: I used AI to help with wording/formatting",
    "attachments": [],
    "highlight": false,
    "summary": "Posting this so other people can reuse the same approach/prompting style when they’re stuck on a concept."
  },
  {
    "id": "ed-7384241",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Use ChatGPT's study guide to compare transformer-based LLMs",
    "dek": "I used ChatGPT's study mode to compare different transformer-based LLMs based on their architectural choices and the tasks for which they are best suited. Engaging in a Socratic conversation with Chat...",
    "student": "Jeffrey Cheng",
    "date": "2025-12-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7384241"
    },
    "body_html": "I used ChatGPT's study mode to compare different transformer-based LLMs based on their architectural choices and the tasks for which they are best suited. Engaging in a Socratic conversation with ChatGPT helped me understand the architectural decisions of various transformer-based LLMs and the specific functions for which they are best suited. It classifies the model architecture into two categories: Encoder/Decoder, Dense/MoE, and explains the strengths of each category in terms of the tasks they are most suited for. One behavior of this study mode that I found very interesting is that, at the end of each ChatGPT response, it always asks me a question that refines my understanding of the current topic. In addition, it helps introduce the next topic for the next prompt. In the end, it generates a cheat sheet that classifies every transformer-based model. \n\nThe conversation log is: ",
    "attachments": [
      {
        "name": "Annotated log of transformer-based models.pdf",
        "url": "https://static.us.edusercontent.com/files/Ggb85TwYCdj1XAJ7rFwAKQIg"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT's study mode to compare different transformer-based LLMs based on their architectural choices and the tasks for which they are best suited. Engaging in a Socratic conversation with ChatGPT helped me understand the architectural decisions of various transformer-based LLMs and the specific functions for which they are best suited."
  },
  {
    "id": "ed-7382039",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Using Perplexity to gain Historical Motivations",
    "dek": "One thing that I've noticed in this class, is that there seems to be an emphasis on motivating ideas through a historical lens and understanding how they naturally evolved in research over time. Howev...",
    "student": "Ishir Garg",
    "date": "2025-12-01",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7382039"
    },
    "body_html": "One thing that I've noticed in this class, is that there seems to be an emphasis on motivating ideas through a historical lens and understanding how they naturally evolved in research over time. However, sometimes I find its hard to connect all the different puzzle pieces and understand where exactly different algorithms or discoveries exist in the timeline. \n\n Hence, I tried to engage an LLM (Perplexity, due to its enhanced search abilities) to try and gain some historical perspective on how ideas came to fruition in deep learning. I uploaded Lecture Note 5 along with an initial prompt, and had Perplexity walk me through a variety of different concepts from a historical perspective. The annotated chat history is below:\n\nTo summarize, I was pleasantly surprised by the outcome. I'm also surprised that it was able to do this with just the lecture notes and a very minimal initial prompt.\n\nStrengths:\n\nPerplexity does a good job of explaining the intuitive motivations behind ideas and how certain ideas lead to others\n\nOne really surprising result was that Perplexity began asking me questions to check my understanding, even though I never asked it to do this\n\nIt also introduced some ideas outside of the lecture notes at a high-level, that provided some really unique insight into the ideas in this class.\n\nWeaknesses:\n\nSome parts could use more explanation or go more in-depth, although it could be argued that these could just be left to the student to ask questions about if they desire.",
    "attachments": [
      {
        "name": "participationE.pdf",
        "url": "https://static.us.edusercontent.com/files/VaBmvFfCKL6FlhgZmgWBerz9"
      }
    ],
    "highlight": false,
    "summary": "One thing that I've noticed in this class, is that there seems to be an emphasis on motivating ideas through a historical lens and understanding how they naturally evolved in research over time. However, sometimes I find its hard to connect all the different puzzle pieces and understand where exactly different algorithms or discoveries exist in the timeline."
  },
  {
    "id": "ed-7381645",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: 182 Exam Prep Tool",
    "dek": "Since I couldn't find any practice tests available online, I decided to build a Practice Question Generator. It utilizes homework assignments, lecture notes, and/or lecture audio to generate relevant ...",
    "student": "Andrew Choy",
    "date": "2025-12-01",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7381645",
      "github": "https://github.com/AndrewChoyCS/CS182-artifact"
    },
    "body_html": "Since I couldn't find any practice tests available online, I decided to build a Practice Question Generator. It utilizes homework assignments, lecture notes, and/or lecture audio to generate relevant study problems.\n\nI found that pairing specific homework assignments with their corresponding lectures yields the most grounded results, even when using free-tier API models. To make the tool more convenient, I added an input field for your API key; this allows you to run the tool without editing the code directly (unless you want to tweak the prompt for other classes).\n\nThe screen recording below demonstrates the tool using only lecture notes and homework. While the system does support lecture audio, which is great for capturing details professors say but don't write down, I stuck to processing PDFs for this demo to minimize inference latency and I used gemini-2.0-flash API Version. \n\nOne of the biggest challenges was formatting the model's output. I attempted to wrap the responses in Markdown to ensure the display math rendered correctly, but this approach introduced several bugs and made the code difficult to maintain. So if anyone wants to push this further, feel free to fork or make a PR request. \n\nGithub: https://github.com/AndrewChoyCS/CS182-artifact\n\nDemo: https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "Since I couldn't find any practice tests available online, I decided to build a Practice Question Generator. It utilizes homework assignments, lecture notes, and/or lecture audio to generate relevant study problems."
  },
  {
    "id": "ed-7380406",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Using ChatGPT to create practice problems",
    "dek": "To study for the final, I thought it would be interesting to see if ChatGPT can be used to created practice problems that are similar to homework problems, and solidify my understanding of the topics ...",
    "student": "Jason Guo",
    "date": "2025-12-01",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7380406"
    },
    "body_html": "To study for the final, I thought it would be interesting to see if ChatGPT can be used to created practice problems that are similar to homework problems, and solidify my understanding of the topics covered in homework. As an example, I gave ChatGPT homework 1, which has problems relating to optimizers, and asked it to generate two exam problems, each with multiple parts, relating to opitmizers based on the given homework problems.\n\nOverall, I thought it did well and actually provided some good problems for studying,. The difficulty of most of the problems it gave were around the same difficulty as the homework, with the exception of around 2 subquestions that required mathematical knowledge that's probably out of scope for this class. I also asked it to generate solutions for these problems, and the solutions were pretty good at explaining the answers in detail. As a whole, I found this to be really helpful in helping me review the material and get more practice solving exam/homework style problems.\n\nAnnotated transcript: https://drive.google.com/file/d/1hT7u9eEhd5HyBr-gD1urZGbrdP3Zu3T2/view?usp=sharing\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "To study for the final, I thought it would be interesting to see if ChatGPT can be used to created practice problems that are similar to homework problems, and solidify my understanding of the topics covered in homework."
  },
  {
    "id": "ed-7377452",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Coding Fill-in-the-Blank for Optimizers",
    "dek": "I recall from CS courses that I have taken such as the 61 series how many questions used to consist of filling in blanks with code, particularly on exams and in discussions. I felt that these question...",
    "student": "Aaryan Chandna",
    "date": "2025-11-30",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7377452"
    },
    "body_html": "I recall from CS courses that I have taken such as the 61 series how many questions used to consist of filling in blanks with code, particularly on exams and in discussions. I felt that these questions were relatively strong in developing intuition at the time, so I wanted to try a similar format out with Google Gemini in order to see if I could strengthen my understanding of the different optimizers. \n\nI asked Gemini to first summarize lectures 3/4 for me from the slides to provide a bit of review. The summaries were decent, even though the intuition provided wasn't always strong: sometimes the model would just quickly state a concept without explaining. Then, I asked it to create continuously increasing questions in difficulty, involving filling in the blank with code. One significant issue was that the model kept accidentally leaking the solution in the comments of the code. Even towards the end, it did this in a somewhat implicit fashion: below the function, there was a small section with an example of running the code in comments, with formulas shown that had the correct blank fill-ins. In addition, Gemini's questions were very one-dimensional and had to do solely with the basic functionality of optimizers, such as an SGD step or an Adam step. I expected that when I asked for questions of higher difficulty, there would be something more intuition based. Towards the end, the last question was a bit different, which was nice. Perhaps there is a better way of prompting to get the model to devise more exam-style questions for prep.\n\n\n\nTrace: https://gemini.google.com/share/eb8917989837",
    "attachments": [
      {
        "name": "spec_part_e_2_aaryan.pdf",
        "url": "https://static.us.edusercontent.com/files/nuwfPT2yMJx70pjs4KH3MbaL"
      }
    ],
    "highlight": false,
    "summary": "I recall from CS courses that I have taken such as the 61 series how many questions used to consist of filling in blanks with code, particularly on exams and in discussions."
  },
  {
    "id": "ed-7377093",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: GPT5 as quiz maker for exam preparation",
    "dek": "\n\nFor special participation part E, I asked GPT 5.1 to make quiz problems (both MCQ and FRQ) based on the lecture notes of lecture 18  and 19 from Professor Ranade. I begin by clearly stating GPT’s ro...",
    "student": "Ender Ji",
    "date": "2025-11-30",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7377093"
    },
    "body_html": "\n\nFor special participation part E, I asked GPT 5.1 to make quiz problems (both MCQ and FRQ) based on the lecture notes of lecture 18  and 19 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all relevant files and ask it to review and understand them.\n\nThen I first ask GPT to generate multiple-choice questions and attempt to answer them. GPT produces high-quality MCQs that effectively test my understanding, and it can both identify my mistakes and provide the correct answers with detailed explanations.\n\nBeyond MCQs, I also use GPT to create more open-ended free-response questions. GPT is able to formulate the problems, “grade” my answers against the \"ground truth\" from the lecture notes, and offer thorough explanations and guidance whenever I get stuck.\n\nThis is the first time I have used an LLM for this kind of review, and the experience has been very positive. I believe this interactive “quiz-taking” approach will be extremely helpful not only for preparing for the final exam, but also for ensuring that I fully understand the material before each subsequent lecture. I also hope that this method will be helpful for other students during RRR week.\n\n",
    "attachments": [
      {
        "name": "test_reviewer_GPT5.pdf",
        "url": "https://static.us.edusercontent.com/files/vHKi330uVk2qWo0QcgvNT3VX"
      }
    ],
    "highlight": false,
    "summary": "For special participation part E, I asked GPT 5.1 to make quiz problems (both MCQ and FRQ) based on the lecture notes of lecture 18  and 19 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all relevant files and ask it to review and understand them."
  },
  {
    "id": "ed-7376375",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT 5.0 Study Mode",
    "dek": "Executive Summary\n\nI used ChatGPT 5.0 \"Study Mode\" to interactively improve my understanding of positional encoding, RoPE, and NoPE.  This was the first time I've interacted with ChatGPT 5.0's \"Study ...",
    "student": "Iana Lin",
    "date": "2025-11-30",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7376375"
    },
    "body_html": "Executive Summary\n\nI used ChatGPT 5.0 \"Study Mode\" to interactively improve my understanding of positional encoding, RoPE, and NoPE.  This was the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" and I felt it was very helpful. It asked clarifying questions about my current understanding before proceeding to explain, which differed from normal prompting mode.\n\n\nAlthough there is a less clear idea of \"one-shotting\" in this context where there are not verifiable correct answers, every question it asked was answer reasonably with logical and step-by-step explanations. I do wish that the explanation were more grounded in mathematical formulations or code, but this may come down to learn the write prompting style.\n \n\nErrors:\nChatGPT used “i” for indexing position, but this later became confusing because it also used i for imaginary number. After pointing this out, it no longer made the mistake\n\n\nOverall:\nChatGPT was a good resource for improving understanding, much like if I was chatting to a teaching assistant, and interacted with clarifying questions throughout the converstation. The analogy to Fourier transform across positions helped clarify how using this superposition allows for capturing of both high and low frequencies/unique embedding for each input embedding and position.",
    "attachments": [
      {
        "name": "Special Participation E - RoPE Using ChatGPT Study Mode.pdf",
        "url": "https://static.us.edusercontent.com/files/rUKMMRgfpcftT4caUCaGgmVi"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT 5.0 \"Study Mode\" to interactively improve my understanding of positional encoding, RoPE, and NoPE.  This was the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" and I felt it was very helpful. It asked clarifying questions about my current understanding before proceeding to explain, which differed from normal prompting mode."
  },
  {
    "id": "ed-7376321",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: GPT5 as lecture notes reviewer and tutor",
    "dek": "For special participation part E, I asked GPT 5.1 to review the lecture notes of lecture 18 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all ...",
    "student": "Ender Ji",
    "date": "2025-11-30",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7376321"
    },
    "body_html": "For special participation part E, I asked GPT 5.1 to review the lecture notes of lecture 18 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all relevant files and ask it to review and understand them. Then I proceed to asking different kinds of questions about the notes\n\n1. input a hand drawing diagram from Professor Ranade and ask it to explain to diagram\n\n2. input a diagram from the book ask it to explain to diagram\n\n3. ask GPT to explain a specific concept\n\n4. ask GPT to differentiate between different concepts\n\n5. ask GPT concepts that are not deeply discussed in the lecture notes, and make connection to the lecture notes\n\nIt is the first time I do notes review with GPT, surprisingly GPT 5.1 can handle almost all kinds of questions well and able to give great explanations, which shows how strong GPT is in helping students learning new concepts.\n\n",
    "attachments": [
      {
        "name": "lecture18_review_GPT5.pdf",
        "url": "https://static.us.edusercontent.com/files/K4hJ3j4bSbawhhtQozKvoiPU"
      }
    ],
    "highlight": false,
    "summary": "For special participation part E, I asked GPT 5.1 to review the lecture notes of lecture 18 from Professor Ranade. I begin by clearly stating GPT’s role and the assistance I require, then provide all relevant files and ask it to review and understand them."
  },
  {
    "id": "ed-7374682",
    "category": "Curiosity",
    "subcategory": "Generating Questions",
    "title": "Special Participation E: Interactive MHA Implementation Drill",
    "dek": "One challenge I often face is bridging the gap between understanding a concept theoretically and implementing it in code. For this assignment, I used Gemini 3 Thinking to guide me through the implemen...",
    "student": "Andrew Choy",
    "date": "2025-11-29",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7374682"
    },
    "body_html": "One challenge I often face is bridging the gap between understanding a concept theoretically and implementing it in code. For this assignment, I used Gemini 3 Thinking to guide me through the implementation.\n\nIt felt a bit like a 'Masked Language Modeling' task for my own brain: I designed a prompt to set up the scenario, and I had to fill in the code for the forward pass of Multi-Head Attention myself. I spent about an hour on the exercise, and I found it incredibly valuable. Instead of just giving me the answers, the LLM asked me conceptual questions about why I was choosing specific tensor shapes. Being forced to justify my implementation details really solidified my understanding of the topic.\n\nI encourage y'all to try this with the prompt I included in the pdf. You can easily adapt it for other concepts by slightly changing the formatting in the 'Your Role' and 'The Trap' sections. Just swap out 'Multi-Head Attention' for another topic like 'Layer Normalization' or 'Adam Optimizer,' and keep the 'No Solutions' constraint to ensure the same type of setup.\n\n ",
    "attachments": [
      {
        "name": "AndrewChoyParticipationE.pdf",
        "url": "https://static.us.edusercontent.com/files/CcMT6C3JxLbClmmbjNJnMBAw"
      }
    ],
    "highlight": false,
    "summary": "One challenge I often face is bridging the gap between understanding a concept theoretically and implementing it in code. For this assignment, I used Gemini 3 Thinking to guide me through the implementation."
  },
  {
    "id": "ed-7374626",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Participation E: Conv Layer Intuition Tutor",
    "dek": "When learning convolution layers, I often struggled to remember formulas or effects as the lectures progressed. I found that true understanding only came from visualizing what was happening and active...",
    "student": "Angelina Zhang",
    "date": "2025-11-29",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7374626"
    },
    "body_html": "When learning convolution layers, I often struggled to remember formulas or effects as the lectures progressed. I found that true understanding only came from visualizing what was happening and actively quizzing myself. So I built a small interactive webpage called Conv Layer Intuition Tutor, designed to help students build real intuition for convolutional layers by letting you manipulate the hyperparameters and see visualizations directly. The interface allows you to adjust kernel size, stride, padding, and it instantly visualizes how these changes affect output size, receptive field growth, parameter count, and which input pixels contribute to each output activation. I also embedded an optional AI assistant (using your own API key) that can quiz you or explain concepts for post-lecture review.\n\nYou can visit the site here: https://angelinaaaaaaaaaaaa.github.io/Conv-Layer-Intuition-Tutor/\n\nTo run the tool locally, simply download the HTML file and either double-click it or open a terminal in that folder and start a local server (e.g., python3 -m http.server 8000) and then visit the shown URL. This removes the need to constantly switch between PDFs and LLMs, and provides a hands-on, highly interactive way to internalize convolution mechanics — with AI guidance whenever you need it.\n\nHappy to hear any feedback or suggestions!\n",
    "attachments": [],
    "highlight": false,
    "summary": "When learning convolution layers, I often struggled to remember formulas or effects as the lectures progressed. I found that true understanding only came from visualizing what was happening and actively quizzing myself."
  },
  {
    "id": "ed-7373978",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Gemini 3 (Thinking) As A Converter from Homework to Practice Problems",
    "dek": "Executive Summary:\n\nI like to prepare for exams by doing practice exam problems, and I’m sure many are like me too. While I think homework problems are a great way to actually learn and understand con...",
    "student": "Tiger Zhang",
    "date": "2025-11-29",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7373978"
    },
    "body_html": "Executive Summary:\n\nI like to prepare for exams by doing practice exam problems, and I’m sure many are like me too. While I think homework problems are a great way to actually learn and understand concepts in the class, I think it’s also good to have exam-style practice problems that test at the understanding gained from the homework assignments, and that require a “faster pace” than do homework problems.\n\nTherefore, I prompted Gemini 3 to write an exam problem set based on a homework problem set, extending the homework problems in interesting and stimulating ways. I guided it to write problems that use intuition built from homeworks so I cannot just skip the homeworks and do the exam problems.\n\nThe result: I now have a simple four-prompt pipeline that simulates the practice test experience on a homework assignment, as it outputs both the practice exam problems and the practice exam solutions. It takes in the homework that the user desires to have corresponding exam problems for, as well as a few examples of exam problems (some are released in some homeworks).\n\nAlthough some output exam problems were quite similar to homework problems, they do change the homework problems slightly, and the rest of the problems are still different from homework problems.\n\nDifficulty: a difficulty I faced when building this pipeline is actually tuning the difficulty of the exam problems. By changing the third prompt (the “write the problems” prompt), the difficulty ranged from too difficult (requires memorization of details of the results from the homework) to very easy (simple plug and chug). If users dislike the difficulty of the problems from this pipeline, I propose changing the third prompt.\n\nChat log: \n\n(I boxed my prompts)\n\nHomework 1 exam problems:\n\nHomework 1 exam problems (unannotated):\n\nHomework 1 exam problem solutions:\n\nHomework 1 exam problems solutions (unannotated):",
    "attachments": [
      {
        "name": "conversation.pdf",
        "url": "https://static.us.edusercontent.com/files/UgyJ3lokWUhEbhzgnOfe3RBU"
      },
      {
        "name": "exam.pdf",
        "url": "https://static.us.edusercontent.com/files/GdbnlVUgpzi1SUWKocJvjdng"
      },
      {
        "name": "exam_clean.pdf",
        "url": "https://static.us.edusercontent.com/files/nn3twYK8NpJ8afEWpu55vtnh"
      },
      {
        "name": "sol.pdf",
        "url": "https://static.us.edusercontent.com/files/cC2bOGSdQdyQM2x4HXsrshSr"
      },
      {
        "name": "sol_clean.pdf",
        "url": "https://static.us.edusercontent.com/files/zdsPG0yCIa2DXw7ixEEN88QO"
      }
    ],
    "highlight": false,
    "summary": "I like to prepare for exams by doing practice exam problems, and I’m sure many are like me too. While I think homework problems are a great way to actually learn and understand concepts in the class, I think it’s also good to have exam-style practice problems that test at the understanding gained from the homework assignments, and that require a “faster pace” than do homework problems."
  },
  {
    "id": "ed-7372401",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Staff Notebook Deep-Dive & Code Review Tutor using ChatGPT Study Mode",
    "dek": "What this is:\nWe often get staff solution notebooks that are 100% correct but not necessarily the best examples of Python or ML engineering practices. I made a reusable prompt that turns ChatGPT  into...",
    "student": "Faiaz Khan",
    "date": "2025-11-28",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7372401",
      "chatgpt": "https://chatgpt.com/share/69295e36-3fd4-8010-9710-56a0c2e28752"
    },
    "body_html": "What this is:\nWe often get staff solution notebooks that are 100% correct but not necessarily the best examples of Python or ML engineering practices. I made a reusable prompt that turns ChatGPT  into:\n\na tutor that explains the solution code,\n\na Socratic “what if we changed this line?” partner, and\n\na code reviewer that critiques style, structure, and engineering practices.\n\nHow to use it:\n\nOpen ChatGPT and enable Study Mode.\n\nStart a new chat and upload the .ipynb with the staff solution.\n\nPaste the big prompt below.\n\nOptionally tell it your comfort level with Python / ML.\n\nLet it walk you through:\n\nan overview of the problem and solution,\n\ninteractive what-if questions about code changes,\n\nand a software-engineering critique plus suggested refactors.\n\nPrompt:\n\nYou are an AI tutor and code reviewer for a Jupyter notebook that contains:\n\n- a coding / ML problem,\n- and the staff-provided solution (and possibly some tests or helper code).\n\nYour goals:\n(1) Help me deeply understand the staff solution.\n(2) Actively quiz me with “what-if” code modification questions.\n(3) Critique the solution as a piece of software / ML engineering, not just as a correct answer.\n\nI will upload a .ipynb file. Please work in the following phases.\n\n########################\nPHASE 0 — ORIENT YOURSELF\n########################\n\nAfter reading the notebook:\n\n1. Identify and briefly summarize:\n   - The **problem statement** (in your own words).\n   - Where the **main staff solution** lives (e.g., which cell / which function).\n   - Any **supporting code** (helpers, tests, imports, plotting, etc.).\n\n2. Output a short overview like:\n\n   - Problem: [...]\n   - Main solution entry point: [...]\n   - Key helper functions: [...]\n   - Tests / demo cells: [...]\n\nIf anything is ambiguous, say so instead of guessing.\n\n########################\nPHASE 1 — EXPLAIN THE SOLUTION\n########################\n\nAssume I am a student who:\n- knows basic Python,\n- is familiar with lists/dicts/functions/loops,\n- but may *not* know the specific algorithm or ML technique yet.\n\nDo the following:\n\n1. **High-level explanation (3–7 sentences)**  \n   - What is the core idea of the solution?\n   - What algorithm / pattern does it implement (e.g., DP, DFS, greedy, training loop, etc.)?\n\n2. **Guided code walkthrough**  \n   - Walk through the main solution function or cell **top-down**.\n   - Group lines into logical chunks instead of line-by-line noise.\n   - For each chunk, explain:\n     - what it does,\n     - why it’s needed,\n     - how it connects to the problem definition.\n\n3. **Complexity / behavior**  \n   - State the time and space complexity if meaningful.\n   - Mention any tradeoffs (e.g., readability vs performance, memory vs speed).\n\nKeep this phase mostly explanatory, with occasional quick checks like:\n> “Can you tell me in your own words what this loop is doing before I explain it?”\n\n########################\nPHASE 2 — INTERACTIVE “WHAT IF?” QUESTIONS\n########################\n\nNow I want you to test and deepen my understanding by asking questions about code changes.\n\n1. Ask **3–6 “what if” questions** such as:\n   - “What do you think happens if we remove this condition?”\n   - “If we change this list to a set, how does that affect correctness and complexity?”\n   - “What if we change the iteration order here?”\n   - “What if we initialize this variable differently?”\n\n2. For each question:\n   - Wait for my answer first.\n   - Then:\n     - say what *would* actually happen (behavior / correctness / performance),\n     - and tie it back to the underlying concept or invariant.\n\n3. Start with simpler changes (e.g., altering a constant or print) and\n   move toward more subtle ones (e.g., off-by-one edges, shared mutable state, ML training details).\n\nIf the code involves randomness or ML training:\n- Ask at least one question about seeds, reproducibility, or how hyperparameters show up in the code.\n\n########################\nPHASE 3 — SOFTWARE / ML ENGINEERING CRITIQUE\n########################\n\nNow critique the staff solution as if you were a senior software or ML engineer reviewing it.\n\n1. **Style & Pythonic-ness**\n   - Comment on:\n     - naming (variables, functions),\n     - function length and cohesion,\n     - use of built-in functions / libraries,\n     - avoiding repetition,\n     - clarity vs cleverness.\n   - Point out at least 3–5 concrete improvements, such as:\n     - “This nested if could be simplified.”\n     - “This magic number should be a named constant.”\n     - “This could use a context manager / list comprehension / enumerate, etc.”\n\n2. **Structure & modularity**\n   - Is the solution written as one big cell, or decomposed into testable functions?\n   - Could it benefit from:\n     - helper functions,\n     - separating pure logic from I/O,\n     - or separating data loading / config from core algorithm?\n\n3. **Documentation & comments**\n   - Are there docstrings or comments explaining key decisions?\n   - Suggest where short comments or docstrings would significantly improve readability.\n   - Optionally sketch an example docstring for the main function (using a standard style like NumPy or Google style).\n\n4. **Testing & edge cases**\n   - Does the notebook include tests or sample runs?\n   - What edge cases might be missing?\n   - Propose **3–5 simple test cases** that would be good to add (in plain English or as Python snippets).\n\n5. **ML engineering (if applicable)**\n   - If the notebook includes any training/eval code:\n     - Comment on:\n       - seeding / reproducibility,\n       - separation of config (hyperparameters) from code,\n       - logging / metrics,\n       - handling of train/val/test,\n       - use of vectorization vs for-loops.\n     - Suggest at least a couple of improvements (e.g., “move these constants to a config dict,” “use a random seed,” etc.).\n\n6. **Concrete improved snippet(s)**\n   - Choose ONE small function or core block from the staff solution.\n   - Show:\n     - “Original version” (copied and possibly shortened)\n     - “Improved version” (your more Pythonic / maintainable rewrite)\n   - Explain in 3–5 bullets what changed and why it’s better (clarity, safety, extensibility, etc.).\n\nIMPORTANT:\n- Do NOT rewrite the entire notebook unless I explicitly ask.\n- Focus on *illustrative* improvements that a student can learn from.\n\n########################\nPHASE 4 — SUMMARY & ACTIONABLE NEXT STEPS\n########################\n\nFinish by giving me:\n\n1. A **conceptual summary**:\n   - 3–6 bullets summarizing:\n     - the algorithm / method used,\n     - the key ideas in the implementation,\n     - and the main software-engineering lessons.\n\n2. A **mini checklist** of things I could do on my own:\n   - e.g., \n     - “Refactor the main function into two helpers,”\n     - “Add tests for these edge cases,”\n     - “Rewrite this loop using a more Pythonic construct.”\n\n3. Ask me:\n   - “Which part of this notebook do you feel you understand the least?”\n   - “Do you want to zoom in further on a particular function or cell?”\n\n########################\nSTYLE & SAFETY\n########################\n\n- Be direct but encouraging; assume I am capable of understanding serious critique.\n- Don’t just say “this is bad”; explain *why* and how to improve it.\n- If you are inferring intent that is not explicit in the notebook, make that clear:\n  > “I’m inferring that this function is meant to do X based on Y; if that’s wrong, let’s adjust.”\n- Avoid hallucinating details that don’t appear in the notebook. If something is unclear, say so.\n\n\n\nMy annotated chat:\nI tried this on the staff solution for Homework 7 RNN LSTM implementation. Here’s my annotated chat trace (PDF):\n\nhttps://chatgpt.com/share/69295e36-3fd4-8010-9710-56a0c2e28752\n In the annotations I point out:\n\nwhere the AI gave good explanations,\n\nwhere its code critiques matched or conflicted with what our course emphasizes,\n\nand where it hallucinated or misread the notebook.",
    "attachments": [
      {
        "name": "RNN LSTM implementation.pdf",
        "url": "https://static.us.edusercontent.com/files/a892iEevSEYlg86E8cxYe11L"
      }
    ],
    "highlight": false,
    "summary": "We often get staff solution notebooks that are 100% correct but not necessarily the best examples of Python or ML engineering practices. I made a reusable prompt that turns ChatGPT  into:"
  },
  {
    "id": "ed-7372317",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: AI-Enhanced Pre-homework Study Workflow Using Mistral AI",
    "dek": "For this assignment, I built an AI-enhanced learning tool that serves as a substitute for traditional pre-homework readings. Here I use Mistral AI on HW08. \n\nMy goal was not to obtain solutions, but t...",
    "student": "Xi Cheng",
    "date": "2025-11-28",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7372317"
    },
    "body_html": "For this assignment, I built an AI-enhanced learning tool that serves as a substitute for traditional pre-homework readings. Here I use Mistral AI on HW08. \n\nMy goal was not to obtain solutions, but to construct a structured conceptual scaffold before attempting the homework. To do this, I asked the LLM to generate a pre-instruction guide that identifies the major concepts, prerequisites, and reasoning pathways needed for the SSM and attention problems. As shown in the annotated interaction trace , I intentionally framed my prompts so that the model would function like a pre-lecture resource rather than a homework solver.\n\nA central part of my prompting strategy was requesting “hints only” instead of answers. I highlighted this in my annotations because it forces me to reconstruct derivations myself, rather than copying a completed solution. This approach supports the assignment’s goal of encouraging self-learning. \n\nCompared with traditional pre-lecture materials, this AI-based tool offers a more interactive and adaptive experience. Instead of passively reading a static explanation, I can ask follow-up questions, request clarification, and explore prerequisite concepts dynamically. \n\nThe workflow—beginning with a conceptual overview, followed by prerequisite review, then question-specific hints and common pitfalls—can be applied to any technical topic in the course. ",
    "attachments": [
      {
        "name": "partE_mistral_hw8.pdf",
        "url": "https://static.us.edusercontent.com/files/5kfBIWvpAxbO50NTUgToOuhF"
      }
    ],
    "highlight": false,
    "summary": "For this assignment, I built an AI-enhanced learning tool that serves as a substitute for traditional pre-homework readings. Here I use Mistral AI on HW08."
  },
  {
    "id": "ed-7372302",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Using an AI “Pre-/Post-Lecture Tutor” using ChatGPT Study Mode",
    "dek": "What this is:\n I made a reusable prompt that turns ChatGPT an interactive lecture companion instead of just a solution engine. You upload a lecture’s slides or notes, and the model:\n\nwalks through the...",
    "student": "Faiaz Khan",
    "date": "2025-11-28",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7372302",
      "chatgpt": "https://chatgpt.com/share/692944c7-5ef4-8010-ba41-cece83a423e0"
    },
    "body_html": "What this is:\n I made a reusable prompt that turns ChatGPT an interactive lecture companion instead of just a solution engine. You upload a lecture’s slides or notes, and the model:\n\nwalks through the lecture in small chunks,\n\nforces you to answer questions before it explains,\n\ncompares your answers directly to slides,\n\nand ends with a short summary + quiz.\n\nHow to use it:\n\nOpen ChatGPT in Study Mode.\n\nPaste the big prompt below as your first message.\n\nUpload the slides for Lecture [X – Topic].\n\nTell it whether this is pre-lecture or post-lecture study.\n\nLet it quiz you chunk-by-chunk.\n\nThe Prompt:\n\nYou are an AI tutor helping me actively learn one lecture in a course.\n\n[COURSE]: e.g., “CS XXX: [Course name]”\n[LECTURE # AND TOPIC]: e.g., “Lecture 22 – Prompt-Based Fine-Tuning Methods”\n[RESOURCES I WILL PROVIDE]: e.g., slides PDF, lecture notes, or textbook section.\n\nYour job is to act like an interactive pre-/post-lecture reading replacement.\n\n### MATERIAL HANDLING\n1. ONLY treat the files/notes I give you as the primary source of truth.\n2. When answering, explicitly separate:\n   - (a) “According to the lecture materials, …”\n   - (b) “Beyond the lecture, I infer/guess that …”\n3. If something is NOT in the materials or you are unsure, say:\n   > “I’m not sure from the provided materials; this is an educated guess.”\n\n### INTERACTION LOOP\nFor this lecture, repeat the following cycle:\n\n**Step 0 — Calibrate**\n- Ask me:\n  - what my background is,\n  - how confident I feel about this topic (1–5),\n  - whether we are doing *pre-lecture* or *post-lecture* study.\n\n**Step 1 — Select a small chunk**\n- Pick a manageable chunk of content:\n  - e.g., 1–3 slides, or 1 short section of notes.\n- Tell me which slides/section we’re focusing on:\n  > “Let’s focus on slides 5–7: [short description].”\n\n**Step 2 — Active recall before explanation**\n- Ask 2–4 questions that I must answer *before* you explain anything, such as:\n  - “In your own words, what problem is this method solving?”\n  - “Why is this assumption important?”\n  - “Can you restate the main equation and what each term means conceptually?”\n\n- Always start with me, not you:\n  > “Answer in 2–4 sentences. It’s okay to be wrong; I’ll help refine.”\n\n**Step 3 — Feedback + correction**\n- Compare my answer to the materials.\n- Do NOT just say “correct/incorrect”. Instead:\n  - Highlight what I did well.\n  - Point out exactly what is missing or mistaken.\n  - Quote or paraphrase the relevant part of the slides/notes to support your feedback.\n- If I’m very off, give me a *hint* and ask me to try again before giving the full explanation.\n\n**Step 4 — Deepen understanding**\n- After feedback, give a concise explanation (max ~5 sentences) that:\n  - connects this chunk to previous lecture ideas,\n  - uses examples or analogies,\n  - mentions any common misconceptions.\n\n- OPTIONAL: Ask one “transfer” question:\n  > “How would this change if [variant scenario]?”\n\n**Step 5 — Quick check**\n- Ask me 1–2 short quiz questions (conceptual or very light math).\n- Then show me the answers so I can self-check.\n\n**Step 6 — Move on or review**\n- Ask:\n  > “On a scale of 1–5, how comfortable do you feel with this chunk?”\n- If I say ≤ 3, offer a different explanation style (more examples, slower, or more visual).\n- If I say ≥ 4, move on to the next chunk.\n\n### END OF SESSION\nWhen I say I’m done or we reach the end, do all of the following:\n\n1. Give a **3–6 bullet-point summary** of the lecture in your own words.\n2. Create:\n   - (a) 3 multiple-choice questions (with answers),\n   - (b) 3 short-answer conceptual questions (with brief answer keys).\n3. Ask ME:\n   - “What still feels confusing?”\n   - “What is one thing you’d like to revisit tomorrow?”\n4. Suggest a short spaced-repetition plan for the next week based on this lecture.\n\n### STYLE & SAFETY\n- Be concise, friendly, and non-judgmental.\n- Never just dump full solutions to typical homework-style questions without first:\n  - asking for my attempt or idea,\n  - and then walking me through step-by-step.\n- Aggressively avoid hallucinations: if there is any conflict between your prior knowledge and the slides, defer to the slides and flag the mismatch.\n\n\n\n\nMy interaction trace + commentary:\n I tried this on Lecture 20: Positional Encoding & Modern Architectures. Here’s the annotated PDF of the conversation: [link].\n In the annotations, I point out:\n\nwhere the model closely followed the prompt and was really helpful,\n\nwhere it hallucinated details that weren’t in the slides,\n\nand some ideas for improving the prompt for future use.\n\nhttps://chatgpt.com/share/692944c7-5ef4-8010-ba41-cece83a423e0",
    "attachments": [
      {
        "name": "Interactive study session.pdf",
        "url": "https://static.us.edusercontent.com/files/02LPmeNtu5c2neK2LPSCSJRZ"
      }
    ],
    "highlight": false,
    "summary": "I made a reusable prompt that turns ChatGPT an interactive lecture companion instead of just a solution engine. You upload a lecture’s slides or notes, and the model:"
  },
  {
    "id": "ed-7372287",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT as Motivation Finder from Lecture Notes",
    "dek": "When I review the lecture notes, I always find it easier to understand a concept after understanding why it is introduced in the first place. Because it is quite laborious to go back to watch the lect...",
    "student": "Guohao Lv",
    "date": "2025-11-28",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7372287"
    },
    "body_html": "When I review the lecture notes, I always find it easier to understand a concept after understanding why it is introduced in the first place. Because it is quite laborious to go back to watch the lecture again and sometimes professors just give a very simplified version of the motivation, I built a “Motivation Finder from Lecture Notes” prompt that uses AI to give a more detailed explanation of the motivation of concepts mentioned in lectures and provide good sources for further reading and deeper understanding. The workflow is: I paste a chunk of CS182 lecture notes (for a particular lecture) into the prompt. The AI first scans the text and extracts a small list of key concepts mentioned there (e.g., BatchNorm, residual blocks, attention, muP, etc.). For each concept, it then searches the internet for one good source—ideally the original paper or a survey/tutorial from a reputable venue—and reports the title, link, and type of source. Using that source, it writes a short motivation-focused summary: what problem people were facing before this idea, how the idea addresses that problem at a high level, and what tradeoffs or limitations are mentioned. It then quotes the relevant lines from the lecture notes and tells me whether the notes make the motivation clear, partially clear, or confusing. Finally, for each concept, it asks me 1–2 questions that test whether I actually understand the motivation and tradeoffs, waits for my answers, and then gives concise “ideal answers.” Overall, I find it quite helpful as a post-lecture reading even though it is still not ideal, and the questions it generate does lead me to go back and read more about the topic, so I think this tool achieves its objective.\n\nThe annotated conversation: https://drive.google.com/file/d/1htjK83ljExmXnUGwNZA2ykykNXQA3ZW_/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "When I review the lecture notes, I always find it easier to understand a concept after understanding why it is introduced in the first place. Because it is quite laborious to go back to watch the lecture again and sometimes professors just give a very simplified version of the motivation, I built a “Motivation Finder from Lecture Notes” prompt that uses AI to give a more detailed explanation of th"
  },
  {
    "id": "ed-7369769",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: ChatGPT as a Mistake-Spotting Coach",
    "dek": "I often use ChatGPT or other LLMs to review CS182 concepts, but I’ve noticed a big problem: it’s very easy to just believe whatever it says. Even when something is slightly wrong or oversimplified, I ...",
    "student": "Guohao Lv",
    "date": "2025-11-27",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7369769"
    },
    "body_html": "I often use ChatGPT or other LLMs to review CS182 concepts, but I’ve noticed a big problem: it’s very easy to just believe whatever it says. Even when something is slightly wrong or oversimplified, I tend to read it passively instead of thinking about whether it matches what we did in lecture. For this special participation, I wanted a way to turn that into an active exercise where I’m forced to read explanations critically and practice catching subtle mistakes in deep learning concepts. So I designed a “Mistake-Spotting Coach” prompt specifically for CS182. The idea is that I give the LLM a lecture topic (for example: SGD vs Adam, normalization layers, residual connections, ConvNets vs fully-connected nets, RNNs vs attention, in-context learning, etc.). Using the prompt, the LLM then writes a short explanation of the topic on purpose with 2–3 subtle errors or misleading statements mixed in.  After the explanation, it asks me to find and correct the mistakes before it reveals what was wrong. I then go through and mark which sentences I think are incorrect or suspicious, explain why, and suggest fixes. The LLM responds by telling me which mistakes I caught, which ones I missed, and where my corrections are only partially right. Finally, it rewrites a clean, fully correct explanation and asks a couple of follow-up questions to check deeper understanding. Overall, I think it is helpful for understanding deeplearning concepts, but it still has some problems, which I pointed out in the annotated conversation. A fix would be to add what you want ChatGPT to do to the General Rules section of the prompt (e.g., \"don't highlight the problematic sentences\") so that it can tailor to your own learning goal.\n\nAnnotated Conversation: https://drive.google.com/file/d/1_iLr4riCwdcg3p-_AzwjeLe6kAtF7y2T/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "I often use ChatGPT or other LLMs to review CS182 concepts, but I’ve noticed a big problem: it’s very easy to just believe whatever it says. Even when something is slightly wrong or oversimplified, I tend to read it passively instead of thinking about whether it matches what we did in lecture."
  },
  {
    "id": "ed-7368105",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Using Gemini Pro 3 and Claude Opus 4.5 for Jupyter Notebook Demos of Lecture Topics",
    "dek": "\n\nExecutive Summary:\n\nI enjoy taking the concepts/theory we learn in class and applying them in code—I think it forces me to turn what I thought I understood through math or abstract concepts and make...",
    "student": "Deena Sun",
    "date": "2025-11-27",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7368105"
    },
    "body_html": "\n\nExecutive Summary:\n\nI enjoy taking the concepts/theory we learn in class and applying them in code—I think it forces me to turn what I thought I understood through math or abstract concepts and make them more concrete by executing them. As a CS 189 course staff this semester, we’re creating a lot of demo notebooks and coding-forward Jupyter notebooks for students to try out. So taking inspiration from the demos in CS 189 as well as our coding homework problems, I decided to try to prompt LLMs and IDE-integrated coding assistants to produce some Jupyter notebook demos of topics covered in class.\n\nPrompt used:\n\nYou are an expert deep learning instructor and advanced Python coder creating a demo for the Berkeley course CS 182, Deep Neural Networks. Your task is to produce a Jupyter notebook that explains and demonstrates the target topic. Use the written lecture notes and transcript of the lecture to inform what key concepts to cover in the demo for the target topic.\n\nThe notebook should following these key principles:\n1. Introduce the topic, describe its relevance in deep learning, and define core concepts from the provided transcript/lecture notes. If necessary, provide comparisons between solutions/practices covered in lecture that “didn’t work”, and those that “did work”.\n2. Use clear markdown cells to present essential theoretical background.\n3. Provide a complete Python implementation using PyTorch, Numpy, and Pandas libraries.\n4. Integrate plots and visualizations throughout to aid interpretation.\n\nFormatting guidelines:\n1. Use descriptive comments and narrative explanations alongside code. Write clear docstrings where needed.\n2. Limit total length to 100-150 lines of code and under 5000 words.\n3. The notebook should be runnable end-to-end in Colab or local Jupyter environments.\n\nOutput only the ipynb notebook.\n\nTarget topic:\n<INSERT YOUR TARGET TOPIC HERE>\n<MAKE SURE TO ADD PDF OF LECTURE NOTES AND TXT FILE OF LECTURE TRANSCRIPTS FROM YOUTUBE>\n\n\nI explored 2 LLMs:\n\nGemini Pro 3 from the Gemini website\n\nI pasted in the prompt, added my target topic (Soft-prompting and soft-prefix prompting), and attached the pdf of lecture 21’s notes as well as a txt of lecture 21’s YouTube transcripts\n\nSince I was using Gemini’s website rather than an IDE, Gemini produced a JSON that I then pasted into a .json file and converted into an ipynb by changing the file extension\n\nClaude Opus 4.5 within Cursor\n\nI pasted in the prompt, and attached lecture 21 ’s PDF notes and a txt of the YouTube transcripts\n\nBoth models produced a runnable Jupyter notebook that included a toy encoder implementation, a toy task (Gemini used the task of reversing a sequence and Claude made dummy sequences to map to positive, negative, or neutral sentiment), training loops for soft-prompting, soft-prefixes, and frozen baseline models, and comparisons of parameter counts and training metrics. Furthermore, both models included detailed walkthroughs and explanations that motivated why soft-prompting/soft-prefixing could be useful, implementation details, and key takeaways.\n\nSome limitations I noticed from both models were the use of outdated additive positional embeddings (perhaps chosen for instructive simplicity). Claude’s implementation of soft-prefixing was flawed, and seemed equivalent to just appending the supposedly learned keys/values to the input sequence’s token embeddings.\n\nOverall, I was impressed with the thoroughness of both model’s demos. I found it a helpful guide towards seeing how a concept we discussed in class might actually be implemented in practice. The interactivity of a Jupyter notebook also makes it easier to play around and tweak things on my own (e.g. by adding extra print statements, adjusting different parameter sizes) that can not be as easily achieved by reading an article or textbook even if it does include code implementations.\n\nWhile this was a fun experiment to see how we could leverage LLMs to produce workable demos, I still ultimately find hands-on doing more effective for my learning than just reading through the demo, even if I’m actively engaged with the reading and trying to understand every step or identify potential errors. I’d be curious to see if this provides a good baseline demo that we could then ask another LLM to help “ablate” and add “TODOs” for students to fill out/code on their own.\n\nGemini Pro 3 - Detailed Analysis\n\nLink to my conversation with Gemini Pro 3: https://gemini.google.com/app/cbcac1c80e5f5041\n\nJupyter Notebook:\n\nSome outdated practices I noticed from Gemini’s Transformer implementation\n\nToyGPT implementation uses additive learned absolute positional embeddings—which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they’re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.\n\nThe FFN/MLP uses GeLU rather than more recent alternatives like SwiGLU or ReLU^2\n\nLayernorms in the transformer encoder blocks instead of RMS norm\n\nSome modern practices that Gemini’s transformer included which differed from the original Transformer paper:\n\nPre-norm residual connections (adding the norm before the Attention sublayer and residual connections that bypass the norm entirely) versus post norm (normalizing after the residual add)\n\nI love that Gemini included the shapes of different tensors in the code comments. I often add these myself as I code to track the dimensions of things/sanity check/debug and I find that they really help my understanding as I implement. I also really appreciate that it makes some of the different dimension-changing functions (e.g. unsqueezed, expand, concat) more readable without having to guess at what they’re trying to do.\n\nThe comments in the code for the CausalSelfAttention’s forward method were very detailed, and covered implementation details beyond what was mentioned in lecture.\n\nFor instance, Gemini noted that we needed to adjust the shape of the causal mask when a soft-prefix is supplied to be [T, P + T] where P = prefix length and T = sequence length.\n\nAdditionally, Gemini also explicitly outlined how the causal mask should still allow attending to all the prefixes and be causal for the rest of the tokens themselves.\n\nIn the ToyGPT forward method, Gemini cuts off the soft prompt embedding token’s output predictions and only returns logits for the original T tokens. This makes sense because we don’t care about what the model predicts for the pre-prompt.\n\nSome things that Gemini included beyond the lecture scope:\n\nComments inside PrefixTuning noted that usually the learnable prefix parameters are reparameterized through a small MLP for stability.\n\nGeneral good coding practices that Gemini used:\n\nSeeding for reproducibility\n\nPyTorch practice of explicitly checking and printing what device we’re using\n\nUsing constants to set the model hyperparameters\n\nMakes copies of the base model for each variant (soft-prompting, soft-prefix, and base model only) so that the base models all start from the same random state for comparison\n\nAlthough Gemini confidently provided an “Analysis of Results” for what I should expect to see, running the demo as given did not produce a frozen baseline with high/flat loss or a decreasing loss curve for soft prompting.\n\nGemini also included a visualization of the soft prompt embeddings. However, unlike Claude, Gemini also included an interpretation of what we can use it for—it noted that we can apply a KNN-like search to find the nearest token in the real vocabulary to see if the soft prompt corresponds to any understandable human words.\n\nClaude Opus 4.5 - Detailed Analysis\n\nLog of my conversation with Claude in Cursor:\n\nJupyter Notebook:\n\nSimpleTransformer implementation uses additive learned absolute positional embeddings—which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they’re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.\n\nInteresting that Claude actually referenced the lecture itself in the notebook: As described in lecture: \"The past queries have no influence except how they influence the keys and values. The state is the keys and the values.\"\n\nSome things that weren’t immediately clear/understandable to me:\n\nWhy did we need MLP reparameterization for the soft-prefixes?\n\nWhat I was supposed to take away from 7: Visualizing Learned Soft Prompt Embeddings — what kinds of patterns should I be expecting?\n\nI don’t think that Opus actually implemented soft-prefix tuning. Its implementation is functionally a learned prepended prompt. True “prefix-tuning” injects learned key/value vectors directly into the attention cache of every transformer layer; this requires modifying each layer’s attention module so the extra K/Vs are concatenated before computing attention scores. Crucially, the code in SimpleTransformer simply concatenates the prefix to the token embeddings before the encoder. That makes the prefix act like extra prepended tokens (a soft prompt), not as layerwise K/V injections.\n\nAlso, PrefixWrapper only returns the first layer’s keys even though SoftPrefix stores tensors shaped like per-layer K/Vs, get_all_prefixes(). I’m not sure why Claude decided to only provide a “simplified” version of get_all-prefixes. But since the SimpleTransformer never consumes layer-specific prefixes, the stored K/Vs are never wired into the attention blocks.",
    "attachments": [
      {
        "name": "gemini_soft_prompting_demo.ipynb",
        "url": "https://static.us.edusercontent.com/files/b8QU2HapAUltFbUPJ5Iw63w8"
      },
      {
        "name": "claude_jupyter_notebook_log.md",
        "url": "https://static.us.edusercontent.com/files/CmMv9Yx4ZSqIcJXB5l5tpUre"
      },
      {
        "name": "claude_soft_prompting_demo.ipynb",
        "url": "https://static.us.edusercontent.com/files/wW7M7blWuVjtHuApecz2Indd"
      }
    ],
    "highlight": false,
    "summary": "I enjoy taking the concepts/theory we learn in class and applying them in code—I think it forces me to turn what I thought I understood through math or abstract concepts and make them more concrete by executing them. As a CS 189 course staff this semester, we’re creating a lot of demo notebooks and coding-forward Jupyter notebooks for students to try out."
  },
  {
    "id": "ed-7363141",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: AI Assisted Annotations",
    "dek": "When trying to use LLMs to study from CS182 lecture notes, hws, or readings, I was constantly switching between three things: the PDF viewer, an LLM tab, and my own notes. I had to copy-paste text or ...",
    "student": "Jason Trinh",
    "date": "2025-11-25",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7363141"
    },
    "body_html": "When trying to use LLMs to study from CS182 lecture notes, hws, or readings, I was constantly switching between three things: the PDF viewer, an LLM tab, and my own notes. I had to copy-paste text or screenshots into the model, read the answer, then flip back to the PDF and try to remember which part it was referring to, which became a really tedious process. And oftentimes, a week later, I don't remember where I had the conversation with the LLM. So I decided to put everything into a single tool.\n\nhttps://jaizunt.github.io/pdf_analyzer/\n\n\n\nI built PDF Analyzer, a small web tool that lets you:\n\nUpload any PDF (lecture notes, papers, homework solutions, etc.).\n\nHighlight text or crop a region of a page (e.g., a figure or equation).\n\nAsk an LLM (Gemini / GPT / Claude) to explain or summarize that exact snippet (or you can enter your own custom prompt).\n\nAttach your own notes, and then\n\nExport everything back into an annotated PDF (with sticky notes as the annoations [these don't render latex]) or a .json “study session” you can re-load later.\n\nIt uses a system prompt tailored towards providing a comprehensive response related to Deep Learning.\n\nIn using this tool, it seems like the response that the LLM provides often results in long and extensive explanations. This is both good and bad (notes are supposed to be concise, but thorough explanations are helpful in understanding the material better). There could be some way of resolving this via a highly specific system prompt that forces the LLM to be as concise as possible (the system prompt I have currently is some form of that, but it seems to deviate from the instructions a little). Additionally, as you will see in some of my example files, there are some cases where it hallucinates (even on the newer models - GPT 5.1). \n\nI have attached below a video of me using it and annotations of examples.",
    "attachments": [
      {
        "name": "Annotations_Video.mp4",
        "url": "https://static.us.edusercontent.com/files/x0s5GPUKGtIHGOmDLnDNfX9j"
      },
      {
        "name": "gnn_notes_annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/SQfubQwqdumOk36pdoPubgd0"
      },
      {
        "name": "polar_annotated.pdf",
        "url": "https://static.us.edusercontent.com/files/K7s6uCtyX9x1ZSDJaW4RsVK8"
      }
    ],
    "highlight": false,
    "summary": "When trying to use LLMs to study from CS182 lecture notes, hws, or readings, I was constantly switching between three things: the PDF viewer, an LLM tab, and my own notes. I had to copy-paste text or screenshots into the model, read the answer, then flip back to the PDF and try to remember which part it was referring to, which became a really tedious process."
  },
  {
    "id": "ed-7360755",
    "category": "Curiosity",
    "subcategory": "Visualizations",
    "title": "Special Participation E: Activation Visualizer for Neural Nets",
    "dek": "I built an “Activation Visualizer” web app and then embedded an AI assistant directly into it so it can act as a pre‑/post‑lecture study companion for CNNs, RNNs, MLPs, and Transformers.\n\nFeel free to...",
    "student": "Jason Trinh",
    "date": "2025-11-25",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7360755",
      "github": "https://github.com/jaizunT/activation_visualizer"
    },
    "body_html": "I built an “Activation Visualizer” web app and then embedded an AI assistant directly into it so it can act as a pre‑/post‑lecture study companion for CNNs, RNNs, MLPs, and Transformers.\n\nFeel free to check it out at:\nhttps://jaizunt.github.io/activation_visualizer/\n\n(GitHub Repository)\nhttps://github.com/jaizunT/activation_visualizer\n\nI went down a major rabbit hole on this—ended up spending basically an entire day modifying the project until it became both a genuinely useful and highly interactive tool rather than just a static visualization. I used an initial prompt generated from GPT 5.1 Thinking, inserted it into Gemini 3 Pro, and went through numerous modifications/iterations (vibe coding on Windsurf with GPT 5.1 Codex - High Reasoning) to make everything mathematically work with proper visualizations.\n\nActivation Visualizer simulates small neural networks and shows:\n\nLayer-by-layer activations and dimensions.\n\nHow changing inputs/weights/initial hidden states changes outputs.\n\nFor RNNs: sequence‑by‑sequence behavior and per‑layer h₀.\n\nFor CNNs: 2D inputs, kernel size, and sliding conv animation.\n\n(You’ll need your own API key for whichever provider you choose if you want to use the AI Assistant; the key stays in your browser and is sent directly to that provider.)\n\nThere are currently 4 architectures available to look through, though transformers has not been interactively implemented yet. You can select them in the top right. My favorite is the RNN.\n\nFor MLP, CNN, and RNN, you can select the dimensions, set your inputs or parameters via manual editing or randomizing, and you can visualize the activations each step of the way. You also can adjust individual parameters and see how they affect the output.\n\nNote that some features are still in the works (not able to view gradients, inserting blocks, etc.), and there are probably lots of bugs still (i.e. trying to break the engine via setting 1000 hidden layers for cnns).\n\nFeel free to comment below any questions you have about any of the features, since there are a lot of parts to this.\n\n\n\nI had to restart my chat in a new conversation numerous times because I think the context became too long... \n\nHow the LLM Performed\n\nWhat it did well\n\nTurning ideas into code. I could describe a desired feature in plain language (e.g., per‑layer RNN h₀, freezing CNN/RNN weights, adding an AI assistant sidebar), and the LLM usually produced coherent React/TypeScript changes touching the right files and props.\n\nManaging complex state wiring. It handled a lot of the repetitive plumbing: adding new state variables, updating dependency arrays, and passing data between App.tsx, the engine, and visualization components without me having to write all the boilerplate.\n\nMath‑aware reasoning. When debugging, it connected behavior back to the math (e.g., CNN output shapes, RNN causality) and helped explain why certain outcomes were expected given the formulas.\n\nRapid iteration. It made it easy to try UI/UX variants quickly (buttons, layout, defaults) and to experiment with different ways of exposing parameters like kernel size or h₀.\n\nWhere it struggled / hallucinated\n\nSmall but important mistakes. Some patches were almost correct but had issues like missing props, slightly malformed JSX, or incorrect assumptions about types. I had to rely on compiler errors and my own reading to fix these.\n\nOver‑confident explanations. At times it proposed plausible but wrong hypotheses about behavior (e.g., why RNN outputs were changing) until we inspected the actual code and data flow more carefully.\n\nLimited UX judgment. It could suggest reasonable layouts, but whether the interface actually felt clean (spacing, font sizes, button labels, clutter) still required my own manual tweaking and visual judgment.\n\nSome other limitations I noticed were that some of my requests that I made were incomplete after the 'agent' did its work (consistent across multiple messages), and I had to explicitly say numerous times what I wanted. However, I do think my conversations could be more effective if I provided a specific 'TODO' or structure of what needs to be implemented as is often presented in 'structured prompts'.\n\nOverall, the LLM was very effective as a “force multiplier” for coding and refactoring, but it definitely wasn’t a drop‑in replacement for understanding the code or the underlying neural network concepts—I still needed to verify, correct, and refine its suggestions.",
    "attachments": [
      {
        "name": "prompt.txt",
        "url": "https://static.us.edusercontent.com/files/CuuSHIqdCbxaFtlOPtBcSkqB"
      },
      {
        "name": "Chat1.md",
        "url": "https://static.us.edusercontent.com/files/kTOJjYSGeKz0vHnbjlDxyIO0"
      },
      {
        "name": "Chat2.md",
        "url": "https://static.us.edusercontent.com/files/Of4K1zRfISmvZMhGd9m9a18b"
      },
      {
        "name": "Chat3.md",
        "url": "https://static.us.edusercontent.com/files/WANrFKubQ0gkDDg04u3LJh6Q"
      },
      {
        "name": "Chat4.md",
        "url": "https://static.us.edusercontent.com/files/50N2WVdFotm06ixLplayqZbh"
      },
      {
        "name": "Chat5.md",
        "url": "https://static.us.edusercontent.com/files/y44b0pvre5CZaOlUqdQkrFVj"
      },
      {
        "name": "Chat6.md",
        "url": "https://static.us.edusercontent.com/files/2lZXdPfuUkNDYgDqCGmlKDye"
      }
    ],
    "highlight": false,
    "summary": "I built an “Activation Visualizer” web app and then embedded an AI assistant directly into it so it can act as a pre‑/post‑lecture study companion for CNNs, RNNs, MLPs, and Transformers."
  },
  {
    "id": "ed-7356236",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Using ChatGPT to Review Lecture 22 and Prepare for Lecture 23",
    "dek": "In this Special Participation E, I want to share my learning process between Lecture 22 and Lecture 23. In Lecture 21~22, professor taught us how well-designed prompts can instruct the LLM to get bett...",
    "student": "Ruizhe Song",
    "date": "2025-11-24",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7356236"
    },
    "body_html": "In this Special Participation E, I want to share my learning process between Lecture 22 and Lecture 23. In Lecture 21~22, professor taught us how well-designed prompts can instruct the LLM to get better performance. The main methods range from \"soft-prompt\", which add learnable prompts to the input sequence, to \"pre-fixer\", which directly makes the Ks and Vs learnable parameters, then to \"LoRA\", which aims at updating the weight matrix with W = W*+delta(W) and finally to \"meta-learning\", which aims at making a model better at being fine-tuned. When I review my notes after class, I find myself re-organizing them as a large family of fine-tuning methods, only from different perspectives. \n\nThis ed post is about my whole review and re-organizing process of all the methods  between Lecture 22 and Lecture 23. I asked GPT5 in an \"evolving\" order from prompt-based methods to the general meta-learning method, let it explain my confusions and the relationship between these methods. And I think this chatting helps me to better prepare for the upcoming Lecture 23 in which I got to learn more about meta-learning, also gives me a better understanding of the previous Lecture 22 and 21.\n\nHere's the pdf version of chat log with my comments:\n\nI consider this a valuable self-refining process. With the help of LLMs these days, the way of collecting information and learning new concepts becomes different. We don't have to google \"what is meta-learning\" \"why is the delta(W)=AB initialized like that\" and search for high-quality post on the Internet. But meanwhile, we have to be careful to not rely too much on LLMs. The generated answers could block our eyes to the open real world. We need to engage with real-world sources and diverse perspectives.",
    "attachments": [
      {
        "name": "Special-Participation-E-lec22.pdf",
        "url": "https://static.us.edusercontent.com/files/b0eC9BwZTph08c6YBt78ODqM"
      }
    ],
    "highlight": false,
    "summary": "In this Special Participation E, I want to share my learning process between Lecture 22 and Lecture 23. In Lecture 21~22, professor taught us how well-designed prompts can instruct the LLM to get better performance."
  },
  {
    "id": "ed-7354053",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Claude for Homework Cramming",
    "dek": "My personal studying strategy (whether effective or not) when reviewing homework/exams is to mentally attempt a question before reading the solution, allowing me to process a large number of questions...",
    "student": "Jameson Liu",
    "date": "2025-11-23",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7354053"
    },
    "body_html": "My personal studying strategy (whether effective or not) when reviewing homework/exams is to mentally attempt a question before reading the solution, allowing me to process a large number of questions in a short time. I wanted to do this in a more interactive way, so I asked Claude (explanatory mode) to help me with it.\n\nI used Claude instead of ChatGPT because:\n1. ChatGPT kept asking weird rewordings of the questions\n2. Worse at giving context\n3. Sometimes failed to parse the .pdf\n\nI provided the solutions (publicly accessible given Ed link), asked Claude to identify the most important problems, and then prompted it to ask me to give a conceptual approach before either going over the solutions or guiding me in the correct direction.\n\nPrompt:\n\"I'm on a time crunch, and I need to study for my Deep Neural Networks exam by reviewing the homework. Here is the first homework and solutions: https://static.us.edusercontent.com/files/aO8NnPYdzjOpEyEphrp1j0nZ\nI want you to:\n1. Identify the 5 most important problems (count subparts as individual problems)\n2. Ask me each question with its entire context, preferably barely modified, one at a time\n3. I will respond with a conceptual approach (I don't have time to fully solve)\n4. If I am correct, output the entire solution and move on to the next question; otherwise, continue guiding me to the correct approach\"\n\nThe results were better than expected. Claude was surprisingly good at picking out complicated problems while simultaneously summarizing all the necessary context, explaining the implications of solutions, and giving me hints. The main downside of this approach is that Claude's usage limit is quite small, making it unsustainable. Since the entire chat session took less than 20 minutes, I felt like this was a pretty time-effective way to study. Although I didn't get to cover most of the homework, I imagine this would be valuable if I really only had a short amount of time to study. \n\nMore details can be found in the annotated chat:\n\nAlso, here is an example of what ChatGPT asked me; I don't think it understood the purpose of my prompt:\n\n",
    "attachments": [
      {
        "name": "claude.pdf",
        "url": "https://static.us.edusercontent.com/files/6UZuY5izaNGKshSMsq7RJIqx"
      }
    ],
    "highlight": false,
    "summary": "My personal studying strategy (whether effective or not) when reviewing homework/exams is to mentally attempt a question before reading the solution, allowing me to process a large number of questions in a short time. I wanted to do this in a more interactive way, so I asked Claude (explanatory mode) to help me with it."
  },
  {
    "id": "ed-7335566",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Converting Lectures to Notes",
    "dek": "I wanted a way to convert the lectures into a notes format, similar to those in CS70. This way, it would be easier to look for specific content and review material without needing to scan through the ...",
    "student": "Jameson Liu",
    "date": "2025-11-19",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7335566"
    },
    "body_html": "I wanted a way to convert the lectures into a notes format, similar to those in CS70. This way, it would be easier to look for specific content and review material without needing to scan through the lecture recordings, timestamp by timestamp. While the lecture slides are posted, they alone do not cover everything stated in the lecture. \n\nTherefore, I wrote a script to use an LLM to convert lectures into well-formatted, academic notes. It uses lecture slides and the transcript of the lecture recording (easily copyable), so no information is left out. An LLM is necessary for this task since 1. the YouTube transcript has several mistakes, and 2. traditional .pdf readers are not great at extracting handwritten text (especially math). \n\nI had to use the Gemini API instead of a typical LLM website, since uploading a .pdf usually just extracts its text instead of having the LLM read it visually (which is a problem since traditional OCR fails). My code takes every page of the lecture slides and converts it to an image before appending it to the request (I verified that this works by testing it without providing a transcript).\n\nBelow is the script and an annotated example (rendered from .tex) output. Running it requires a Gemini API key, which is free (subject to rate limit). The following is from lecture 2, and the transcript is copied directly from the YouTube transcript section (description -> transcript -> hide timestamps). ",
    "attachments": [
      {
        "name": "lecture_notes_generator.py",
        "url": "https://static.us.edusercontent.com/files/Cd3H2Ms186TdwbAbUYsO21an"
      },
      {
        "name": "lecture_transcript.txt",
        "url": "https://static.us.edusercontent.com/files/KMYhxbngSstZOFkUIqeGe4ED"
      },
      {
        "name": "lecture_notes.pdf",
        "url": "https://static.us.edusercontent.com/files/b3OLyIUjmGeTp9nUFOzrYzXB"
      },
      {
        "name": "lecture_notes.tex",
        "url": "https://static.us.edusercontent.com/files/CGZZqK2lhpg57awIG1m4WKzU"
      }
    ],
    "highlight": false,
    "summary": "I wanted a way to convert the lectures into a notes format, similar to those in CS70. This way, it would be easier to look for specific content and review material without needing to scan through the lecture recordings, timestamp by timestamp. While the lecture slides are posted, they alone do not cover everything stated in the lecture."
  },
  {
    "id": "ed-7319120",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Using ChatGPT to understand papers",
    "dek": "I find reading papers on deep learning to be pretty difficult at times, because they often assume a level of mathematical knowledge or background knowledge that I don't have. Because of this, it feels...",
    "student": "Jason Guo",
    "date": "2025-11-17",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7319120"
    },
    "body_html": "I find reading papers on deep learning to be pretty difficult at times, because they often assume a level of mathematical knowledge or background knowledge that I don't have. Because of this, it feels like papers under explain a lot of things, making them hard to understand.\n\nI was interested in seeing the proof for a claim that was stated, but not proved, in lecture 8, so I thought it would be interesting to get ChatGPT to explain the proof to me. The claims I wanted it to prove are claims 1 and 2 here: https://arxiv.org/pdf/2310.17813\n\nOverall, I think it did a good job of filling in the blanks of certain steps that are glossed over in the paper, and answering follow up questions to clarify confusion. However, I think the way ChatGPT presents information can kind of be disorganized and confusing, so it takes some work to figure out what exactly the structure of its claims or proofs are. In particular, it often answers things in bullet points or divides its answers up into sections, rather than just answering in full sentences and paragraphs, which makes it confusing for me at times.\n\nAnnotated conversation with more detailed comments: https://drive.google.com/file/d/1r-ZZ3-P1c_IzPMdpXhegt_hDgqfDU0U4/view?usp=sharing",
    "attachments": [],
    "highlight": false,
    "summary": "I find reading papers on deep learning to be pretty difficult at times, because they often assume a level of mathematical knowledge or background knowledge that I don't have. Because of this, it feels like papers under explain a lot of things, making them hard to understand."
  },
  {
    "id": "ed-7300719",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Attention and Transformers Visualized with Claude Sonnet 4.5",
    "dek": "I’d been struggling to reason about how information flows through attention and transformer blocks at a low level—specifically how the matrix multiplications and changing dimensions still produce an o...",
    "student": "Leon Kornfeld",
    "date": "2025-11-13",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7300719"
    },
    "body_html": "I’d been struggling to reason about how information flows through attention and transformer blocks at a low level—specifically how the matrix multiplications and changing dimensions still produce an output with the same dimensionality as the input. I was also unclear on how multi-head attention differs from single-head attention and how the whole mechanism fits together.\n\nTo sort it out, I used Claude to build a visualization that traces the full path through a transformer. I iterated on it: starting with high-level questions, refining answers, and ending with a 14-step walkthrough that explains attention, the transformer block, and the computations between them.\n\nHere is the published link of the visualization: https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8\n\n\n\nAs I went, my questions became more targeted, drilling into different parts of the architecture.\n\nAt the end, in addition to reviewing Claude's output, looking for any hallucinations, I also pasted the entire source code into GPT-5 to see if it could find any mistakes. GPT was able to point out some assumptions that Claude made that weren't as clear as they could have been. I took GPT's feedback and gave it to Claude for the final iteration of the tool.\n\nHere is my annotated transcript:\n\n\n\n\n\n",
    "attachments": [
      {
        "name": "Claude-Transformer attention mechanism visualization.pdf",
        "url": "https://static.us.edusercontent.com/files/YbYkT62G1SqWbf9FlhoZmEp2"
      }
    ],
    "highlight": false,
    "summary": "I’d been struggling to reason about how information flows through attention and transformer blocks at a low level—specifically how the matrix multiplications and changing dimensions still produce an output with the same dimensionality as the input. I was also unclear on how multi-head attention differs from single-head attention and how the whole mechanism fits together."
  },
  {
    "id": "ed-7289919",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Debugging Exercise with Gemini Guided Learning (GNNs)",
    "dek": "Personally, I learn well by doing exercises that involve the identification of mistakes or reasons to employ specific techniques. This inspired me to develop a debugging exercise with Gemini's Guided ...",
    "student": "Aaryan Chandna",
    "date": "2025-11-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7289919"
    },
    "body_html": "Personally, I learn well by doing exercises that involve the identification of mistakes or reasons to employ specific techniques. This inspired me to develop a debugging exercise with Gemini's Guided Learning, where I fed the slides for Lecture 12 (GNNs) as input and initially asked the model to provide me with a guide on the lecture slide material over 3 prompts, letting it know in advance to prepare for the debugging exercise. I then had Gemini create 2 debugging exercises for myself to complete, followed by a verification of the answers and explanation. I cannot include the actual link to the conversation unfortunately because Gemini prohibits sharing conversations on school accounts, but I have included the PDF of the interaction trace with my comments.\n\n\n\nReflection - I think providing the lecture slides was a good move as Gemini was able to discuss almost all the concepts from the lecture and explain them well. with some exceptions (didn't discuss the image classification vs semantic segmentation case, didn't get into directed vs undirected graphs). It also mostly prevented hallucination or the usage of formulas that were not in the actual slides, which helped align the discussion with what was relevant towards the course. There was, however, one minor case of hallucination, and the debugging exercises had material/answers that were correct but were not discussed in the guide, which was a significant weakness of this option. Moreover, I was disappointed by the lack of visuals provided by Gemini, even using the Guided Learning mode. The biggest strength of Gemini on this task, in my opinion, was providing relevant and thorough explanations that were still concise enough that I would be able to understand the necessary concepts quickly.\n\n",
    "attachments": [
      {
        "name": "geminifinal.pdf",
        "url": "https://static.us.edusercontent.com/files/A2ejEufCSlXMQuag5EyT7KpQ"
      }
    ],
    "highlight": false,
    "summary": "Personally, I learn well by doing exercises that involve the identification of mistakes or reasons to employ specific techniques. This inspired me to develop a debugging exercise with Gemini's Guided Learning, where I fed the slides for Lecture 12 (GNNs) as input and initially asked the model to provide me with a guide on the lecture slide material over 3 prompts, letting it know in advance to pre"
  },
  {
    "id": "ed-7287291",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Grok4(fast) as a teacher on SSM",
    "dek": "In this part, I will use Grok4 (fast) as a teacher to teach me about SSM (State Space Model). I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's res...",
    "student": "Zhangzhi 'csrookie' Xiong",
    "date": "2025-11-11",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7287291"
    },
    "body_html": "In this part, I will use Grok4 (fast) as a teacher to teach me about SSM (State Space Model). I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response.",
    "attachments": [
      {
        "name": "grok.pdf",
        "url": "https://static.us.edusercontent.com/files/6B4exsCcmrwY1lnSOsMjV3WB"
      },
      {
        "name": "log.pdf",
        "url": "https://static.us.edusercontent.com/files/cPZVGFVnVIPMaIPzG0VzYqlL"
      }
    ],
    "highlight": false,
    "summary": "In this part, I will use Grok4 (fast) as a teacher to teach me about SSM (State Space Model). I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response."
  },
  {
    "id": "ed-7281484",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT as a post-lecture learning approach",
    "dek": "I usually have some new questions when I review my notes after class. Some questions indicate that I don't fully understand the specific deep learning mechanism on the class, while others are about th...",
    "student": "Ruizhe Song",
    "date": "2025-11-10",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7281484"
    },
    "body_html": "I usually have some new questions when I review my notes after class. Some questions indicate that I don't fully understand the specific deep learning mechanism on the class, while others are about the reason why we are using these techniques(in other words why something seems pretty normal but works well). This ed post is about the first kind of questions, which I don't fully understand on the class, and managed to solve with the help of ChatGPT as a powerful post-lecture learning tool.\n\nIn this special participation E, I plan to share my post-lecture self-learning trace after Lecture 18 & 19 with ChatGPT5. The two classes cover the important attention mechanism and Transformer architecture. After the post-lecture learning process, I understand the attention layer and transformer better. It even makes the coming classes and discussions clearer to me.\n\nHere's the pdf version of chat log with my comments:\n\nIn this log, I asked questions step-by-step, and let GPT guide me to change my way of thinking in RNN and SSM to attention mechanism and Transformer architecture. During this process, GPT successfully:\n\n1. Corrected my wrong understanding about how attention layer works. \n\n2. Made concrete examples to illustrate the training/inference process in transformer architecture and attention layers, which helped me understand much more quickly.\n\n3. Gave mathematical representations and detailed illustrations of them to make the whole intuition clear.",
    "attachments": [
      {
        "name": "Special-Participation-E.pdf",
        "url": "https://static.us.edusercontent.com/files/ydpSFWtljJ9a0RoRqsbAub7D"
      }
    ],
    "highlight": false,
    "summary": "I usually have some new questions when I review my notes after class. Some questions indicate that I don't fully understand the specific deep learning mechanism on the class, while others are about the reason why we are using these techniques(in other words why something seems pretty normal but works well)."
  },
  {
    "id": "ed-7280239",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Quiz and Flash Cards for Adam / SGD",
    "dek": "Special Participation E: Quiz and Flash Cards for Adam / SGD\n\nFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answ...",
    "student": "Andy Zhang",
    "date": "2025-11-09",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7280239"
    },
    "body_html": "Special Participation E: Quiz and Flash Cards for Adam / SGD\n\nFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid\n\nEspecially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.\n\nWhile the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.\n\nFrom there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one’s presences, the model can be steered to act accordingly. \n\nMy recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.\n\nTraces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing\n\nIndividual traces:\n\nUndetailed Prompt Trace Flash Cards:\n\nhttps://gemini.google.com/share/ed66de185158\n\nUndetailed Prompt Trace Quiz:\n\nhttps://gemini.google.com/share/598e4b5cfbcc\n\nUndetailed Flash Cards:\n\nhttps://gemini.google.com/share/cfd44ed946d6\n\nUndetailed Quiz:\n\nhttps://gemini.google.com/share/6fab8238136e\n\nFlash cards / quizzes:\n\nDetailed Prompt Trace for Flash Cards with Math:\n\nhttps://gemini.google.com/share/f7957da6c0d1\n\nDetailed Prompt Trace for Quiz:\n\nhttps://gemini.google.com/share/ec87b322ca7e\n\nDetailed Flash Cards: https://gemini.google.com/share/6afed4acff7b\n\nDetailed Quiz: https://gemini.google.com/share/01910a14266a",
    "attachments": [],
    "highlight": false,
    "summary": "For background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid"
  },
  {
    "id": "ed-7276004",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: ChatGPT Lecture Comprehension Buddy",
    "dek": "I used ChatGPT's \"Study\" mode to help me better understand lectures. Many times, I find myself not really knowing how to prepare ahead of lectures, and I always have questions that get passed on to mo...",
    "student": "Bruno Vieira",
    "date": "2025-11-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7276004"
    },
    "body_html": "I used ChatGPT's \"Study\" mode to help me better understand lectures. Many times, I find myself not really knowing how to prepare ahead of lectures, and I always have questions that get passed on to more questions in discussions, and so I just find myself sometimes \"drowning\" and wishing I had more support to answer some basic questions that can help me not get behind. For this, I decided to test ChatGPT with Thursday 11/07's lecture to help me prepare before the lecture and help me get all my questions answered before next week's lecture. \n\nBelow, I have uploaded the full conversation I had with comments. I also put here a pre-lecture PDF that ChatGPT gave me.\n\nIn all honesty, the summary is that I preferred Claude as it is better with visuals, and I thought that ChatGPT didn't really go that deep into the content. On the other hand, the conversation we had before I went to the lecture drastically improved my experience in the lecture - highly recommend!!\n\n",
    "attachments": [
      {
        "name": "Prelecture_Notes_InContextLearning_PEFT.pdf",
        "url": "https://static.us.edusercontent.com/files/4P4H8nUZm0uWXT3GrMuApHNN"
      },
      {
        "name": "Prelecture notes guide.pdf",
        "url": "https://static.us.edusercontent.com/files/gLCYq39bF14aT98XEDEY6GaN"
      }
    ],
    "highlight": false,
    "summary": "I used ChatGPT's \"Study\" mode to help me better understand lectures. Many times, I find myself not really knowing how to prepare ahead of lectures, and I always have questions that get passed on to more questions in discussions, and so I just find myself sometimes \"drowning\" and wishing I had more support to answer some basic questions that can help me not get behind."
  },
  {
    "id": "ed-7252696",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Concept Map Mermaid Diagrams of Research Papers",
    "dek": "Using LLMs to create concept maps/Mermaid diagrams of key concepts and related works in research papers.\n\nWhen reading machine learning research papers, I like to synthesize how the different concepts...",
    "student": "Deena Sun",
    "date": "2025-11-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7252696"
    },
    "body_html": "Using LLMs to create concept maps/Mermaid diagrams of key concepts and related works in research papers.\n\nWhen reading machine learning research papers, I like to synthesize how the different concepts introduced in the paper fit together and how related works tie into the ideas covered in the paper. I usually find this helpful for breaking down ML research into more digestible chunks as well as for creating a roadmap for how I can further my understanding using the citations referenced in the paper. I decided to use Claude 4.5 Sonnet on Perplexity to help me create concept maps of research papers that could visually display connections between key ideas in the paper, how related works contributed to the paper’s takeaways, and additional papers for further exploration.\n\nFirst, I used Claude 4.5 Sonnet to help me generate an effective prompt I could reuse for LLMs based on my idea. I started off asking Claude for a general purpose deep learning tutoring prompt that would guide me through a research paper. Then, I focused the prompt to involve the LLM generating a workable Mermaid diagram representing my concept map idea. Claude gave me some helpful advice for how to productively prompt other LLMs for studying purposes:\n\nProvide context about your role and goals, including your background knowledge and your learning grows\n\nAssign the LLM a specific persona (e.g. “You are a deep learning teaching assistant…”) to tailor the model’s responses towards educational guidance.\n\nProvide example interactions and specify what the output format should be\n\nAfter some back and forth to modify the prompt to my desires, I took the draft prompt that Claude suggested and used it to prompt another instance of Claude 4.5 Sonnet to actually generate a Mermaid diagram of a concept map for the paper “A Spectral Condition for Feature Learning” we read in homework 3, question 3. I also included a PDF of the paper as an attachment.\n\nHere is the final Mermaid diagram that Claude 4.5 Sonnet produced, rendered using a Mermaid diagram editor:\n\nHere is the prompt I used to generate this concept map that you can use!\n\nYou are a deep learning teaching assistant helping me map out conceptual relationships in a research paper.\n\nYour task:\n* Carefully read the research paper \"[PAPER TITLE]\" and identify all major concepts, methods, and results.\n* Build a structured concept map (\"brain map\") using Mermaid syntax (graph TD), where:\n    * Nodes represent key topics, methods, or results. Include related works and references inside the nodes.\n    * Edges connect related nodes, with descriptive labels explaining the relationship (not just keywords).\n    * Node labels are clear and concise; avoid line breaks for compatibility.\n* For each node, list relevant citations and references (from the paper and cited works) below the diagram, grouped by concept.\n* Flag nodes that are central (highly connected) or have many references, and highlight these for further study.\n* If supported, also generate a PNG image of the diagram for visual reference.\n\nOutput Instructions\n* Present the concept map first using Mermaid syntax in a Markdown code block. Use graph TD, clear node labels, and descriptive edge labels (e.g., --> |enables parallel attention|).\n* Represent the 10 most important concepts as nodes in the Mermaid diagram. Include related works and references inside the node.\n* List all references/citations grouped by node below the diagram (not inside node labels).\n* If possible, generate and return a PNG image of the diagram.\n* Avoid using special characters such as parentheses in labels that might not be compatible with Mermaid diagram generators.\n\nFormat example:\n```\ngraph TD\n Transformer[\"Transformer Model (Vaswani et al. 2017)\"]\n SelfAttn[\"Self-Attention (Bahdanau et al. 2014; Lin et al. 2017)\"]\n MultiHead[\"Multi-Head Attention (Vaswani et al. 2017)\"]\n PosEnc[\"Positional Encoding (Gehring et al. 2017)\"]\n Adam[\"Adam Optimizer (Kingma & Ba 2014)\"]\n Transformer -->|Directly models all pairwise token dependencies with attention| SelfAttn\n Transformer -->|Requires token position information for context awareness| PosEnc\n Transformer -->|Is trained efficiently using adaptive gradient optimization| Adam\n SelfAttn -->|Provides the base mechanism for building rich token representations| MultiHead\n MultiHead -->|Enables parallelized, diverse attention for complex relationships| SelfAttn\n\nReferences by Node:\n* Transformer Model: Vaswani et al. 2017, Gehring et al. 2017, Wu et al. 2016\n* Self-Attention: Bahdanau et al. 2014, Lin et al. 2017, Parikh et al. 2016\n* Multi-Head Attention: Vaswani et al. 2017, Britz et al. 2017\n* Positional Encoding: Gehring et al. 2017, Sennrich et al. 2015\n* Adam Optimizer: Kingma & Ba 2014\n```\n\nBackground:\nI am an undergraduate student who is interested in machine learning, deep learning, and research in these fields.\n\nPaper abstract/intro:\n[COPY HERE]\n\nHere are the logs of my chats that I used to brainstorm my prompt as well as to create the Mermaid diagram:\n",
    "attachments": [
      {
        "name": "Research_graph_prompt_creation_chat.pdf",
        "url": "https://static.us.edusercontent.com/files/3w2hhk3gVZSU1c7OeKythrA8"
      },
      {
        "name": "Spectral_condition_for_feature_learning_concept_map_chat.pdf",
        "url": "https://static.us.edusercontent.com/files/xKoVyP3TX2Rof6dDLfOjctCf"
      }
    ],
    "highlight": false,
    "summary": "Using LLMs to create concept maps/Mermaid diagrams of key concepts and related works in research papers."
  },
  {
    "id": "ed-7249718",
    "category": "Curiosity",
    "subcategory": "Understanding Concepts",
    "title": "Special Participation E: Using GPT to Deepen Lecture Understanding",
    "dek": "What I built:\n\nDuring lectures, I used ChatGPT as an interactive study partner rather than a passive note tool.\nWhenever a concept felt unclear, I would pause the lecture, take a screenshot, and ask a...",
    "student": "Ben Yu",
    "date": "2025-11-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7249718"
    },
    "body_html": "What I built:\n\nDuring lectures, I used ChatGPT as an interactive study partner rather than a passive note tool.\nWhenever a concept felt unclear, I would pause the lecture, take a screenshot, and ask a precise question in my EECS 182 project space. Each numbered thread (Week #) became a mini-lab where I clarified equations, verified derivations, and then reinterpreted AI’s explanation directly into my written lecture notes:\n\nFor example (image below), in Week 9's lecture, I used GPT as my study partner to clarify the concept of Fast Fourier Transform on State Space Models, which was barely mentioned on during lecture. This way I can freely choose to dive deeper into specific concepts while learning the broad picture from the lecture.\n\n\n\nExample Conversation — Lecture 9: Hidden-State Independence\n\nTrace Link: https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2G\n\nOne of My Question: “So the point (of use block diagonal matrix B in state space calculation) is to make hidden states independent?”\n\nAI-Guided Insights: Correlated hidden states introduce redundancy and unstable gradients, because each state begins to carry overlapping information about the sequence. By using block diagonal matrices, each hidden unit evolves as a unique information channel, making the system more stable and interpretable by decoupling the updates of different state components, because independent states yield better gradient flow, improved generalization, and a cleaner mapping between model structure and learned function.\n\nVerification:\nI implemented diag_unrolled_ssm_forward and diag_conv_ssm_forward to confirm the theory, and their outputs matched within 1e-6 and reproduced the predicted runtime behavior -- linear in T for recurrence, nearly constant on GPU for convolution.\n\nAfter each exchange, I try to reexplain the idea in my handwritten notes, converting the long AI reasoning into a concise conceptual summary that I could review quickly before exams.\n\nComments:\n\nPositives (What Worked Well):\n\nImmediate conceptual clarification: AI interaction let me elaborate on lecture ideas in real time rather than waiting for Ed Forum or office-hour responses.\n\nReduced TA load: Routine clarifications that might have required staff input were handled independently, keeping my questions tightly scoped to lecture material.\n\nDeeper integration: Reading the AI’s full reasoning line by line forced me to engage with the derivations more carefully than a static answer key would have.\n\nNegatives (Limitations and Effort Required):\n\nScope uncertainty: The AI occasionally referenced material outside the intended EECS 182 syllabus, requiring me to filter which concepts were truly in scope.\n\nPotential over-explanation: Responses sometimes included extra theoretical context that, while interesting, risked obscuring the specific idea being tested.\n\nFuture Improvements:\n\nStructured project workflow: As outlined in my companion submission “Special Participation E: AI-Enhanced Learning with ChatGPT Project Mode,” we can formalize a workflow where each thread explicitly records lecture context, question scope, and verified outcomes.\n\nThis process exemplifies how AI can enhance learning when guided by course scope, topical context, and consistent self-reflection.",
    "attachments": [],
    "highlight": false,
    "summary": "Whenever a concept felt unclear, I would pause the lecture, take a screenshot, and ask a precise question in my EECS 182 project space. Each numbered thread (Week #) became a mini-lab where I clarified equations, verified derivations, and then reinterpreted AI’s explanation directly into my written lecture notes:"
  },
  {
    "id": "ed-7249252",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: AI-Enhanced Learning with ChatGPT Project Mode",
    "dek": "What I built:\nA repeatable workflow that uses ChatGPT project mode as a study copilot across lecture, discussion, and homework -- it summarizes past questions/answers from my chat history into chronol...",
    "student": "Ben Yu",
    "date": "2025-11-04",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7249252",
      "chatgpt": "https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce"
    },
    "body_html": "What I built:\nA repeatable workflow that uses ChatGPT project mode as a study copilot across lecture, discussion, and homework -- it summarizes past questions/answers from my chat history into chronological tables and acts like a “cache layer” I can backtrack during reviews.\n\nProject Setup:\n\nPrompt:\n\nYou are my personal TA for UC Berkeley’s EECS 182/282A: Deep Neural Networks, Fall 2025.\nYour job is to help me learn, review, and succeed in this course.\n\nStick to course scope: topics include optimization, convnets, ResNets, GNNs, RNNs, state-space models, transformers, prompting, transfer/meta-learning, generative & diffusion models.\n\nHelp style:\nKeep explanations simple, direct, and intuitive before going deep in math/code.\nUse examples (math, code, visual intuition) tied to the syllabus sequence.\n\nYour primary goals:\nHelp me understand concepts deeply (intuition + formalism).\nHelp me practice effectively (HW, projects, exam prep).\n\n\nProject Files:\n\npdf of course syllabus from https://berkeley-cs182.github.io/fa25/index.html\n\npdf of course textbook\n\nExample of backtracking and knowledge retrieval:\n\nTrace Link: https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce\n\n\nTogether with the project prompt and chat prompt, ChatGPT project mode retrieves my earlier conversation threads (e.g., HW 8 questions like “in unstructured W, why is recurrence faster on CPU?” and “diagW = torch.diag(W) — what does it do?”) and composes a factual summary table.\n\nHow classmates can reproduce (bullet list):\n\nCreate a ChatGPT project for EECS 182/282A and paste the prompt above.\n\nTag threads as Hw #, Dis #, Week #; keep each question atomic.\n\nAfter sessions, ask for a chronological project summary with the rule “no invention—mark not recorded when missing.”\n\nWhy it helps:\n\nTurns scattered chats into structured, dated rows for HW/Dis/Week.\n\nMakes past findings searchable (e.g., what you asked 3 weeks ago when you were watching that week's lecture).\n\nReduces review time during finals by providing a durable “cache layer” that complements handwritten notes.\n\nComments:\n\nPositives (What Worked Well):\n\nProvides a systematic and personal way to track conceptual and coding progress across lectures, discussions, and homework.\n\nEnables quick summarization of recurring pain points — e.g., topics repeatedly causing confusion (like SSM recurrence vs convolution).\n\nWorks as a universal workflow, not just for EECS 182, but adaptable to other classes, research projects, or long-term commitments.\n\nNegatives (Limitations and Effort Required):\n\nRequires manual setup and consistent thread naming (e.g., “Hw 1”, “Dis 3”), which takes discipline and time.\n\nIf unrelated conversations are accidentally mixed into the project, they can poison the context, causing noisy or misleading summaries.\n\nFuture Improvements:\n\nExplore context condensation techniques — controlling the length and quality of how AI responds even during normal chat sessions so later reviews are cleaner.\n\nOrganize from the start: define thread templates (e.g., “Concept | Question | Key Takeaway”) to ensure consistent retrievability.\n\nPossibly integrate automated tagging or scripts to rename threads and prevent context contamination.\n\n\n\nOver time, this could evolve into a lightweight personal learning management system --  one that adapts as the AI learns your workflow.\n\n",
    "attachments": [],
    "highlight": false,
    "summary": "A repeatable workflow that uses ChatGPT project mode as a study copilot across lecture, discussion, and homework -- it summarizes past questions/answers from my chat history into chronological tables and acts like a “cache layer” I can backtrack during reviews."
  },
  {
    "id": "ed-7240163",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Special Participation E: Quiz and Flash Cards for Adam / SGD",
    "dek": "Special Participation E: Quiz and Flash Cards for Adam / SGD\n\nFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answ...",
    "student": "Andy Zhang",
    "date": "2025-11-02",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7240163"
    },
    "body_html": "Special Participation E: Quiz and Flash Cards for Adam / SGD\n\nFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid\n\nEspecially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.\n\nWhile the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.\n\nFrom there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one’s presences, the model can be steered to act accordingly. \n\nMy recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.\n\n\n\nTraces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing\n\n\n\nIndividual traces:\n\nUndetailed Prompt Trace Flash Cards:\n\nhttps://gemini.google.com/share/ed66de185158\n\nUndetailed Prompt Trace Quiz:\n\nhttps://gemini.google.com/share/598e4b5cfbcc\n\nUndetailed Flash Cards:\n\nhttps://gemini.google.com/share/cfd44ed946d6\n\nUndetailed Quiz:\n\nhttps://gemini.google.com/share/6fab8238136e\n\n\n\nFlash cards / quizzes:\n\nDetailed Prompt Trace for Flash Cards with Math:\n\nhttps://gemini.google.com/share/f7957da6c0d1\n\nDetailed Prompt Trace for Quiz:\n\nhttps://gemini.google.com/share/ec87b322ca7e\n\nDetailed Flash Cards: https://gemini.google.com/share/6afed4acff7b\n\nDetailed Quiz: https://gemini.google.com/share/01910a14266a",
    "attachments": [],
    "highlight": false,
    "summary": "For background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid"
  },
  {
    "id": "ed-7227336",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: How I used Google NotebookLM to understand SSM",
    "dek": "Special Participation E (Google NotebookLM) - RNNs and SSMs\n\nI used Google NotebookLM as a guided tutor to study the relationship between State-Space Models (SSMs) and Recurrent Neural Networks (RNNs)...",
    "student": "Anders Vestrum",
    "date": "2025-10-30",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7227336"
    },
    "body_html": "Special Participation E (Google NotebookLM) - RNNs and SSMs\n\nI used Google NotebookLM as a guided tutor to study the relationship between State-Space Models (SSMs) and Recurrent Neural Networks (RNNs), using EECS 182 materials and the S4 paper. Through its Learning Guide mode, the system’s questions helped me understand how SSMs convert sequential recurrence into FFT-based convolution and how diagonalization combined with the Woodbury Matrix Identity makes the S4 model both efficient and stable. I noted one factual correction: the chatbot listed the FFT cost as O(N·L log L), but standard FFT convolution parallelizes across time, giving O(L log L) instead. The session also introduced Ridge-Attention, illustrating how it reframes self-attention from a probabilistic softmax view to a linear-algebraic one.\n\nNotebookLM link (video, mind map, quiz, and flashcards in this link: https://notebooklm.google.com/notebook/1da24f39-d172-4725-a38c-5f6366e8ac95",
    "attachments": [
      {
        "name": "spE_notebookLM_RNN_SSM.pdf",
        "url": "https://static.us.edusercontent.com/files/bDTJCfOluen1y8BEHkKwa2Ee"
      }
    ],
    "highlight": false,
    "summary": "I used Google NotebookLM as a guided tutor to study the relationship between State-Space Models (SSMs) and Recurrent Neural Networks (RNNs), using EECS 182 materials and the S4 paper."
  },
  {
    "id": "ed-7226661",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special participation E: Create a custom version of chatGPT,  μP & Modern Optimizers Coach",
    "dek": "Link: μP & Modern Optimizers Coach\n\nPdf: \n\nExtensive summary:\n\nThis custom GPT acts as an interactive study companion for μP scaling, RMSNorm, and modern optimizers.\nIt’s a great way to ask questions ...",
    "student": "Noah Lund Syrdal",
    "date": "2025-10-30",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7226661"
    },
    "body_html": "Link: μP & Modern Optimizers Coach\n\nPdf: \n\nExtensive summary:\n\nThis custom GPT acts as an interactive study companion for μP scaling, RMSNorm, and modern optimizers.\nIt’s a great way to ask questions about concepts you don’t fully understand. I’ve stress-tested it on common misconceptions about μP invariance, and it consistently provided nuanced, well-grounded answers (tried to get a wrong answer out of it, didn’t manage).\n\nYou can use my version directly, or follow the steps in the PDF to create your own tailored model on a different concept.\nIt works well both as a pre-lecture active reading tool and a post-lecture review partner; you can even talk with it out loud while learning.\n\nI would strongly recommend this approach for anyone in the course. I’ll be creating similar custom GPTs for other core concepts in 182/282 and eventually one that covers the entire course, to explore how well it can guide learning across all modules.",
    "attachments": [
      {
        "name": "Special_Participation_E-3.pdf",
        "url": "https://static.us.edusercontent.com/files/AB1TpLpivYeHk0yo44YDkb3m"
      }
    ],
    "highlight": false,
    "summary": "This custom GPT acts as an interactive study companion for μP scaling, RMSNorm, and modern optimizers."
  },
  {
    "id": "ed-7215058",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: Claude Study \"Buddy\"",
    "dek": "I used Claude's study feature to use it as a study \"buddy\". I pretended to be studying for an exam, trying to review content, and study for a specific topic via pre-lecture notes all using Claude to g...",
    "student": "Bruno Vieira",
    "date": "2025-10-28",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7215058"
    },
    "body_html": "I used Claude's study feature to use it as a study \"buddy\". I pretended to be studying for an exam, trying to review content, and study for a specific topic via pre-lecture notes all using Claude to guide my studies.\n\nI started out with this map to see if it could connect all the topics from this class into a graph and assess the relationships between them. Below is the trace with all my comments! Hope this is helpful and happy studying.\n\n",
    "attachments": [
      {
        "name": "Claude Trace Study Buddy.pdf",
        "url": "https://static.us.edusercontent.com/files/kFuAKFCnfFtJk8o3u8FVRZpS"
      }
    ],
    "highlight": false,
    "summary": "I used Claude's study feature to use it as a study \"buddy\". I pretended to be studying for an exam, trying to review content, and study for a specific topic via pre-lecture notes all using Claude to guide my studies."
  },
  {
    "id": "ed-7092540",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: Learning Mode as an Effective Step By Step Tutor",
    "dek": "Special Participation E: Learning Mode as an Effective Step By Step Tutor\n\nGemini Learning Mode: https://g.co/gemini/share/4e1faf6d804c\n\nGemini Non-Learning Mode: https://g.co/gemini/share/c6ce8062f1d...",
    "student": "Andy Zhang",
    "date": "2025-10-08",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7092540",
      "chatgpt": "https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36"
    },
    "body_html": "Special Participation E: Learning Mode as an Effective Step By Step Tutor\n\nGemini Learning Mode: https://g.co/gemini/share/4e1faf6d804c\n\nGemini Non-Learning Mode: https://g.co/gemini/share/c6ce8062f1d6\n\nChatGPT Learning Mode: https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36\n\nChatGPT Non-Learning Mode: https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78\n\nRecommendation:\n\nI would recommend fellow students to leverage Gemini / ChatGPT learning mode to go through problems in piece meal step by step fashion with a guided tutor. This may be helpful after completing a homework, noticing a discrepancy with the solutions, and deciding to go through the homework again with some guidance to build a stronger understanding. ChatGPT is more helpful if you’re concerned about reward hacking, but Berkeley students have free Gemini Pro which may favor that since it’s easy to hit usage limits with ChatGPT.\n\nThe learning modes are effective tools for breaking down problems into piecemeal parts, as opposed to generating the entire solution in one go.\n\nExecutive summary:\n\nI was interested in investigating the extent to which Guided Learning modes could help. I experimented with Gemini and ChatGPT which are the two models with learning modes available for free (in contrast, Claude’s learning mode is not accessible). I tested two different problems on two different homework assignments for Gemini and ChatGPT, and experimented with learning and non-learning modes.\n\nFor Gemini Learning Mode, I was initially curious (1) to what extent it could help guide learning (2) whether it would break things down piece meal (3) how well it would handle latex formatting (4) whether it could produce new insights and (5) whether there would be reward hacking.\n\nI applied it to HW0 Vector Calculus Review a-e.\n\nFor (1-3) it performed admirably, though it did fail to format one part of one response. (4) was more of an issue; I prompted the model to “help me view the problem from the different lenses of vector calculus, and walk through both elementwise, rowwise, columnwise, and examples” and it failed to do so.\n\n(5) is a significant concern. If you ask for the answer, it will provide it. In fact, simply asking “Formatting messed up” led to “You correctly calculated the three partial derivatives! That was the toughest part.”\n\nMy observation is that guided learning is trained on successful learning traces and does not handle incorrect/out of distribution inputs well (and infers it as correct).\n\nAlso interestingly it converted the questions from a “Show X = Y” to “What is derivative of X”, which could be a plus or minus depending on your use case (in a way, not knowing the answer could be helpful).\n\nOne nice note is that after the problems were complete, it suggested additional questions, which may be useful for additional practice.\n\nIn contrast, Gemini directly answered all the parts when not in learning mode which could feel overwhelming.\n\nFor ChatGPT learning mode, it performed similarly to Gemini, though had the advantage of not simply giving the answer / getting reward hacked. However, Berkeley students have free Gemini Pro which may favor that since it’s easy to hit usage limits with ChatGPT.\n\nSimilarly without learning mode, it answered all parts which could be overwhelming.",
    "attachments": [],
    "highlight": false,
    "summary": "I would recommend fellow students to leverage Gemini / ChatGPT learning mode to go through problems in piece meal step by step fashion with a guided tutor. This may be helpful after completing a homework, noticing a discrepancy with the solutions, and deciding to go through the homework again with some guidance to build a stronger understanding."
  },
  {
    "id": "ed-7061441",
    "category": "Curiosity",
    "subcategory": "New Content Creation",
    "title": "Participation E: Automatic Glossary of Keywords Introduced in Lecture",
    "dek": "Hi everyone,\n\nI put together a small website that automatically builds a glossary from our lecture transcripts using (free!!!) API calls from Gemini-2.5-flash. The goal is to make it easier to keep tr...",
    "student": "Sammie Smith",
    "date": "2025-10-03",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7061441"
    },
    "body_html": "Hi everyone,\n\nI put together a small website that automatically builds a glossary from our lecture transcripts using (free!!!) API calls from Gemini-2.5-flash. The goal is to make it easier to keep track of technical terms, see plain-English definitions, and get beginner-friendly explanations of how those terms show up in machine learning and deep learning.\n\n👉 Website link: https://sammiesmith.github.io/DL_glossaries_Smith.github.io/ \n\nHow to use the site\n\nThe Glossary page lists all the terms extracted from Lecture 1 (so far).\n\nYou can search using the bar in the top-right (search is limited to the “Term” column).\n\nEach entry shows:\n\nthe plain-English definition,\n\nthe prerequisite material reference (when available),\n\nand a description of how the term is used in ML/DL.\n\nThe Methods page explains how the glossary is generated (pipeline, prompts, limitations, and ideas for improvement).\n\nWhy I built this\n\nSometimes the hardest part of lecture is just keeping all the new vocabulary straight. My hope is this tool can give quick, reliable definitions and context, and eventually we could add features like quiz-me buttons for studying.\n\nFeel free to explore it and let me know if you run into bugs or have ideas for features that would make it more useful!\n\n— Sammie",
    "attachments": [],
    "highlight": false,
    "summary": "I put together a small website that automatically builds a glossary from our lecture transcripts using (free!!!) API calls from Gemini-2.5-flash. The goal is to make it easier to keep track of technical terms, see plain-English definitions, and get beginner-friendly explanations of how those terms show up in machine learning and deep learning."
  },
  {
    "id": "ed-7030840",
    "category": "Curiosity",
    "subcategory": "Learning Tools & Tutors",
    "title": "Special Participation E: ChatGPT as Quiz Tutor",
    "dek": "Trace: https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b\n\nPrompted ChatGPT to teach me the CNN architecture step-by-step and quiz me after each concept. Pretty fun and useful as a lecture...",
    "student": "Nyx Iskandar",
    "date": "2025-09-28",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7030840",
      "chatgpt": "https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b"
    },
    "body_html": "Trace: https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b\n\nPrompted ChatGPT to teach me the CNN architecture step-by-step and quiz me after each concept. Pretty fun and useful as a lecture prep or consolidation! Can also extend this to uploading lecture notes and quizzing based on the notes.",
    "attachments": [],
    "highlight": false,
    "summary": "Prompted ChatGPT to teach me the CNN architecture step-by-step and quiz me after each concept. Pretty fun and useful as a lecture prep or consolidation! Can also extend this to uploading lecture notes and quizzing based on the notes."
  },
  {
    "id": "ed-7027430",
    "category": "Curiosity",
    "subcategory": "Cheatsheets & Notes",
    "title": "Special Participation E: FlashcardGPT",
    "dek": "Use FlashcardGPT to generate flashcards out of lecture notes etc. :)\n\nURL: https://github.com/xyntechx/flashcard-gpt\n\nFull disclosure:\n\nI made this app in about 3 hours + I'm not the best designer\n\nYo...",
    "student": "Nyx Iskandar",
    "date": "2025-09-27",
    "tags": [],
    "links": {
      "ed": "https://edstem.org/us/courses/84647/discussion/7027430",
      "github": "https://github.com/xyntechx/flashcard-gpt"
    },
    "body_html": "Use FlashcardGPT to generate flashcards out of lecture notes etc. :)\n\nURL: https://github.com/xyntechx/flashcard-gpt\n\nFull disclosure:\n\nI made this app in about 3 hours + I'm not the best designer\n\nYou have to run this locally (follow the instructions in the README)\n\nYou need to use your own OpenAI API keys (sorry haha)\n\nWhen I was testing this, I used a pre-generated set of flashcards so that it won't take too long, and to save API credits, which is why the demo is 🔥 blazingly fast 🔥. The flashcards were indeed generated by GPT-5.\n\nOpen to feature requests / issues / PRs!\n\n",
    "attachments": [
      {
        "name": "Screen Recording 2025-09-26 at 22.34.08.mov",
        "url": "https://static.us.edusercontent.com/files/2GNHHP8zSUbCiuZhzkvmJvoo"
      }
    ],
    "highlight": false,
    "summary": "When I was testing this, I used a pre-generated set of flashcards so that it won't take too long, and to save API credits, which is why the demo is 🔥 blazingly fast 🔥. The flashcards were indeed generated by GPT-5."
  }
]